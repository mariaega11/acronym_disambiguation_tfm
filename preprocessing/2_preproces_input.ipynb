{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1056,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/egarcia/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import collections\n",
    "import unidecode\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import itertools \n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "from functools import reduce\n",
    "import ast\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1057,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1059,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_texts(path):\n",
    "    data = []\n",
    "    file_name = os.listdir(path)\n",
    "\n",
    "    for name in file_name:\n",
    "        if name.endswith('.txt'):\n",
    "            with open(path + name,encoding=\"utf8\") as f:\n",
    "                text = f.read()\n",
    "                data.append({'nombre':name.replace('.txt',''), 'texto':text})\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1060,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(string):\n",
    "    \"\"\"\n",
    "    A method to clean text \n",
    "    \"\"\"\n",
    "    \n",
    "    # Removing the punctuations\n",
    "    for x in string.lower(): \n",
    "        if x in punctuation:\n",
    "            if x != '/':\n",
    "                string = string.replace(x, \"\")\n",
    "            else:\n",
    "                string = string.replace(x, \" \")\n",
    "    \n",
    "    string = unidecode.unidecode(string)\n",
    "\n",
    "#     # Converting the text to lower\n",
    "#     string = string.lower()\n",
    "\n",
    "    # Removing stop words\n",
    "    string = ' '.join([word for word in string.split() if word not in swords])\n",
    "\n",
    "    # Cleaning the whitespaces\n",
    "    string = re.sub(r'\\s+', ' ', string).strip()\n",
    "\n",
    "    return string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1061,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/egarcia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "swords = list(set(stopwords.words('spanish')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1062,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep_num_text(data):\n",
    "\n",
    "    words = word_tokenize(data) \n",
    "    for w in words:\n",
    "        if re.search(r'\\d', w):\n",
    "            ind = words.index(w)\n",
    "            words[ind] = [''.join(g) for k, g in itertools.groupby(w, str.isalpha)]\n",
    "    data = ' '.join([x if type(x) is not list else ' '.join(x) for x in words])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1063,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f_b_context_text(data):\n",
    "    \n",
    "    '''Return context in a string format'''\n",
    "    \n",
    "    all_data = []\n",
    "    sf_not_found = []\n",
    "    \n",
    "    for instance in data:\n",
    "           \n",
    "        texto = instance['texto']    \n",
    "        #target_word = instance['short_form']\n",
    "        target_word = instance['Abbreviation']\n",
    "        doc_id = instance['# Document_ID']\n",
    "        \n",
    "        if target_word in texto:\n",
    "\n",
    "            stop_ini_idx = instance['StartOffset'] #índice del inicio de la target\n",
    "            stop_fin_idx = instance['EndOffset'] #índice del inicio de la target\n",
    "\n",
    "            _instance = []\n",
    "            xf = texto[:stop_ini_idx] + ' <start> ' +texto[stop_ini_idx:stop_fin_idx] + ' <end> ' #palabras anteriores a la target\n",
    "            #xf = texto[:stop_ini_idx] +texto[stop_ini_idx:stop_fin_idx]\n",
    "            xb = texto[stop_fin_idx+1:]   #palabras posteriores a la target            \n",
    "\n",
    "            instance_id = instance['Definition'] #id del significado\n",
    "            #instance_id = instance['long_form']\n",
    "            _instance.append(doc_id)\n",
    "            _instance.append(target_word)\n",
    "            _instance.append(xf)\n",
    "            _instance.append(xb)\n",
    "            _instance.append(instance_id)\n",
    "\n",
    "            all_data.append(_instance[:])\n",
    "        else:\n",
    "            sf_not_found.append(target_word)\n",
    "#             print(\"El acrónimo {} no aparece en el texto {}\".format(target_word, instance['doc_id']))\n",
    "        \n",
    "    return all_data, sf_not_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1064,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_context(data):\n",
    "\n",
    "    for doc in data:\n",
    "        \n",
    "        sf, xf, xb, lf = doc[1], doc[2], doc[3], doc[4]\n",
    "\n",
    "        xf_words = word_tokenize(xf)[-n_step_f-1:]\n",
    "        xb_words = word_tokenize(xb)[:n_step_b]\n",
    "\n",
    "        doc[2] = ' '.join(xf_words)\n",
    "        doc[3] = ' '.join(xb_words)   \n",
    "\n",
    "    return data        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1065,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict(data):\n",
    "    \n",
    "    data_dic = []\n",
    "    \n",
    "    for instance in data:\n",
    "            \n",
    "        dic = {}\n",
    "        \n",
    "        dic['doc_id'] = instance[0]\n",
    "        dic['short_form'] = instance[1]\n",
    "        dic['context'] = instance[2] + ' ' + instance[3]\n",
    "        dic['long_form'] = instance[4]\n",
    "    \n",
    "        data_dic.append(dic)\n",
    "        \n",
    "    return data_dic\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1066,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_levenshtein(str1, str2):\n",
    "    d=dict()\n",
    "    for i in range(len(str1)+1):\n",
    "        d[i]=dict()\n",
    "        d[i][0]=i\n",
    "    for i in range(len(str2)+1):\n",
    "        d[0][i] = i\n",
    "    for i in range(1, len(str1)+1):\n",
    "        for j in range(1, len(str2)+1):\n",
    "            d[i][j] = min(d[i][j-1]+1, d[i-1][j]+1, d[i-1][j-1]+(not str1[i-1] == str2[j-1]))\n",
    "    return d[len(str1)][len(str2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_lf(row):\n",
    "    leven2 = []\n",
    "    for i in row:\n",
    "        for j in row:\n",
    "            if i != j:\n",
    "                long = max(len(i),len(j))\n",
    "                ratio = distance_levenshtein(i,j)/long\n",
    "                if ratio < 0.2:\n",
    "                    leven2.append(j)\n",
    "    if leven2:\n",
    "        leven2 = set(leven2)\n",
    "        lista = []\n",
    "        for i in leven2:\n",
    "            #val = frec[frec['index'] == i]['long_form'].iloc[0]\n",
    "            val = frec[frec['index'] == i]['Definition'].iloc[0]\n",
    "            lista.append((i, val))\n",
    "        lista = set(lista)\n",
    "        most_freq = sorted(set(lista), key=lambda x: x[1], reverse = True)[0][0]\n",
    "        sust = {}\n",
    "        for i in set(leven2):\n",
    "            sust[i] = most_freq\n",
    "        \n",
    "        return sust\n",
    "    else:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1068,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(row):\n",
    "    if row['long_form_x'] == row['long_form_y']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1069,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offsetA(row):\n",
    "    return row['texto'].find(row['Mention_A'])\n",
    "    \n",
    "def offsetB(row):\n",
    "    return row['texto'].find(row['Mention_B'])\n",
    "\n",
    "def offsetB_end(row):\n",
    "    return row['texto'].find(row['Mention_B']) + len(row['Mention_B'])\n",
    "\n",
    "def offsetA_end(row):\n",
    "    return row['Mention_A_StartOffset'] + len(row['Mention_A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1070,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offset(row):\n",
    "    return row['texto'].find(row['abrev'])\n",
    "\n",
    "def offsetend(row):\n",
    "    return row['StartOffset']+len(row['abrev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defin_dictionary(row,dictionary):\n",
    "    if row['Definition'] == 'no_existe':\n",
    "        return dictionary.get(row['Abbreviation'])\n",
    "    else:\n",
    "        return row['Definition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1072,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defin_abremes_dictionary(row,dictionary):\n",
    "    return dictionary.get(row['Abbreviation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Testing\n",
    "\n",
    "220 clinical cases.\n",
    "\n",
    "No haría falta procesarlo pues crearemos el fichero directamente d elas notas clínicas de test. Luego lo pasaremos por el transformer y la salida la procesaremos para que sea como el gold standard. Aplicaremos el evaluador de IberEval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/ibereval_data/testing_set/clinical_cases.abbreviations.testing_set.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1073-403fbaf4d6dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtesting_abbr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/ibereval_data/testing_set/clinical_cases.abbreviations.testing_set.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#testing_met = pd.read_csv(\"../data/ibereval_data/clinical_cases.metadata.testing_set.tsv\", sep = '\\t')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtesting_rel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/ibereval_data/testing_set/clinical_cases.relations.testing_set.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfm/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfm/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfm/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfm/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfm/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfm/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m         )\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tfm/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m             )\n\u001b[1;32m    649\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/ibereval_data/testing_set/clinical_cases.abbreviations.testing_set.tsv'"
     ]
    }
   ],
   "source": [
    "testing_abbr = pd.read_csv(\"../data/ibereval_data/testing_set/clinical_cases.abbreviations.testing_set.tsv\", sep = '\\t')\n",
    "#testing_met = pd.read_csv(\"../data/ibereval_data/clinical_cases.metadata.testing_set.tsv\", sep = '\\t')\n",
    "testing_rel = pd.read_csv(\"../data/ibereval_data/testing_set/clinical_cases.relations.testing_set.tsv\", sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing_met.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_rel = testing_rel.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_rel.columns = ['# Document_ID', 'Mention_A_type', 'Mention_A_StartOffset',\n",
    "      'Mention_A', 'Relation_type', 'Mention_B_type',\n",
    "       'Mention_B_StartOffset', 'Mention_B_EndOffset', 'Mention_B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_rel = testing_rel.rename(columns = {'# Document_ID': 'doc_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_rel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_rel.Relation_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_abbr = testing_abbr.rename(columns = {'# Document_ID': 'doc_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_abbr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_raw = read_texts(\"../data/ibereval_data/testing_set/testing_set.raw_text/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TEST NEW DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing= pd.read_csv(\"../data/data_paper/test_subtrack2_parte1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Trainning\n",
    "\n",
    "318 clinical cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_abbr = pd.read_csv(\"../data/ibereval_data/trainning_set/clinical_cases.abbreviations.training_set.tsv\", sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_met = pd.read_csv(\"../data/ibereval_data/trainning_set/clinical_cases.metadata.training_set.tsv\", sep = '\\t')\n",
    "train_rel = pd.read_csv(\"../data/ibereval_data/trainning_set/clinical_cases.relations.training_set.tsv\", sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_met = train_met.rename(columns = {'# Document_ID': 'doc_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_met.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_rel = train_rel.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_rel.columns = ['# Document_ID', 'Mention_A_type', 'Mention_A_StartOffset',\n",
    "#      'Mention_A', 'Relation_type', 'Mention_B_type',\n",
    "#       'Mention_B_StartOffset', 'Mention_B_EndOffset', 'Mention_B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_rel = train_rel.rename(columns = {'# Document_ID': 'doc_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_rel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_abbr = train_abbr.rename(columns = {'# Document_ID': 'doc_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_abbr.Definition.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_abbr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = read_texts(\"../data/ibereval_data/trainning_set/training_set.raw_text/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = train_raw.rename(columns = {'nombre': 'doc_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAIN NEW DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/data_paper/train_subtrack2_parte1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_abbr = pd.read_csv(\"../../datasets/development_set/clinical_cases.abbreviations.development_set.tsv\", sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_met = pd.read_csv(\"../../datasets/development_set/clinical_cases.metadata.development_set.tsv\", sep = '\\t')\n",
    "dev_rel = pd.read_csv(\"../../datasets/development_set/clinical_cases.relations.development_set.tsv\", sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_met = train_met.rename(columns = {'# Document_ID': 'doc_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_met.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_rel = train_rel.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_rel.columns = ['index', '# Document_ID', 'Mention_A_type', 'Mention_A_StartOffset',\n",
    "      'Mention_A', 'Relation_type', 'Mention_B_type',\n",
    "       'Mention_B_StartOffset', 'Mention_B_EndOffset', 'Mention_B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_rel = dev_rel.rename(columns = {'# Document_ID': 'doc_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_rel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_abbr = dev_abbr.rename(columns = {'# Document_ID': 'doc_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_abbr.Definition.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_abbr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_raw = read_texts(\"../../datasets/development_set/development_set.raw_text/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_raw = dev_raw.rename(columns = {'nombre': 'doc_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DEV NEW DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_raw = pd.read_csv(\"../data/data_paper/train_subtrack2_parte1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Prepare Train Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.rename(columns = {'Abbreviation': 'short_form', 'Definition': 'long_form'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna(subset = ['short_form', 'long_form'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['StartOffset', 'EndOffset']] = train[['StartOffset', 'EndOffset']].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean long forms to delete acents, string punctuation etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['long_form'] = train['long_form'].map(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Normalize long forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_lf = train[['short_form', 'long_form']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_lf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_lf_list = sf_lf.groupby('short_form', as_index=False).agg({'long_form': list})\n",
    "sf_lf_list['len'] = sf_lf_list['long_form'].map(lambda x: len(x))\n",
    "sf_lf_list.sort_values('len', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table = pd.crosstab(sf_lf_list['len'], columns = 'Count')\n",
    "table.plot.bar(legend = None)\n",
    "plt.xlabel(\"Definiciones por acrónimo\")\n",
    "plt.ylabel(\"Count\")\n",
    "#plt.show()\n",
    "#plt.savefig('data/acron_count.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table = pd.crosstab(sf_lf_list['len'], columns = 'Count')\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Apply Levenshtein distance to normalize Long Forms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get more frequent lf per sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frec = train['long_form'].value_counts().reset_index()\n",
    "frec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary where keys are the lf to normalize and the values the normalized form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = []\n",
    "for i in sf_lf_list['long_form']:\n",
    "    norm.append(normalize_lf(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = [i for i in norm if i != None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "norm_dict = {}\n",
    "for i in norm:\n",
    "    norm_dict.update(i)\n",
    "#norm_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally normalize long forms over the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.replace({\"long_form\": norm_dict})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that deffinitions have been normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Get just ambigous acronyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute this code just in case only ambigous acronyms are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#amb = train.groupby('short_form')['long_form'].nunique().reset_index().sort_values('long_form', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#amb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table = pd.crosstab(amb['long_form'], columns = 'Count')\n",
    "#table.plot.bar()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defin = amb[amb['long_form'] != 1]['short_form'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = train[train['short_form'].isin(defin)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Add texts from Medline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some long forms are imbalanced. Texts from Medline are added to improve balance.\n",
    "\n",
    "Execute this code just in case we need to add more test. We won't do it al first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study imbalaced long forms. Number of rows for each different definition. We can see mostly long forms have just one row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frec2 = train['long_form'].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.long_form.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train[['doc_id','long_form']].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def_count = train[['doc_id','long_form']].drop_duplicates().groupby('long_form').agg({'doc_id':'count'}).reset_index()\n",
    "#def_count.sort_values('doc_id').tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#table = pd.crosstab(def_count['doc_id'], columns = 'Count')\n",
    "#table.plot.bar(legend = None, figsize=(15,8))\n",
    "#plt.xlabel(\"Cantidad de textos en los que aparece la definición\")\n",
    "#plt.ylabel(\"Count\")\n",
    "#plt.savefig('data/def_count.png')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frec2[frec2['long_form'] == 1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find more text for definitions with 3 or less rows in train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_lf = train.groupby('long_form').size().reset_index().rename(columns={0:'count'}).sort_values('count')\n",
    "#train_lf_list = train_lf[train_lf['count'] <= 3]['long_form'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(train_lf_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of deffinition to search in Medline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sorted(train_lf_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Medline texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#medline = pd.read_csv(\"../data/scrapping/textos_medline_scrapping2.csv\")\n",
    "#medline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#medline[medline['concept'].isin(train_lf_list)]['concept'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just 30 deffinition have been find in Medline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#medline[medline['concept'].isin(train_lf_list)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#medline[medline['concept'].isin(train_lf_list)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform Medline text with train structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#med_texts = medline[medline['concept'].isin(train_lf_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#med_texts = med_texts[['text', 'concept']].rename(columns = {'text':'texto', 'concept':'long_form'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sf_lf = train[train['long_form'].isin(train_lf_list)][['short_form', 'long_form']].set_index('long_form').to_dict()['short_form']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#med_texts['short_form'] = med_texts['long_form'].map(sf_lf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def replace_sf_lf(row):\n",
    "#    row['texto'] = row['texto'].replace(row['long_form'], row['short_form'])\n",
    "#    return row['texto']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#med_texts['texto'] = med_texts.apply(replace_sf_lf, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#med_texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def find_offset(row):\n",
    "#    start_i = row['texto'].find(row['short_form'])\n",
    "#    end_i = start_i + len(row['short_form'])\n",
    "    \n",
    "#    return start_i, end_i   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#med_texts['offsets'] = med_texts.apply(find_offset, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#med_texts[['StartOffset', 'EndOffset']] = pd.DataFrame(med_texts['offsets'].tolist(), index=med_texts.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#med_texts = med_texts[['texto', 'short_form', 'long_form','StartOffset', 'EndOffset']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#med_texts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concat train and Medline texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = pd.concat([train, med_texts], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.reset_index(inplace = True, drop = True)\n",
    "#train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how many deffinition have low texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frec3 = train['long_form'].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table = pd.crosstab(frec2['long_form'], columns = 'Count')\n",
    "#table.plot.bar()\n",
    "#plt.title('Number of deffinition records train')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table = pd.crosstab(frec3['long_form'], columns = 'Count')\n",
    "#table.plot.bar()\n",
    "#plt.title('Number of deffinition records after adding Medline texts to train')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lf_low = set(train_lf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lf_inmedline = set(medline[medline['concept'].isin(train_lf_list)]['concept'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#lf_low ^ lf_inmedline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Transform dataframe to a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train[['nombre', 'texto', 'short_form', 'long_form', 'StartOffset', 'EndOffset']].to_dict('records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Get the text before and after the SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ndata, sf_not_found = get_f_b_context_text(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if any SF is not founded in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_not_found_set = set(sf_not_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sf_not_found_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute this code just in case clean the texts are needed: remove string punctuation, accents, lower case, remove double spaces, separate numbers from sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_text_after(data):\n",
    "    \n",
    "#     for instance in data:\n",
    "#         instance[1] = clean_text(instance[1]).lower()\n",
    "#         instance[2] = clean_text(instance[2]).lower()\n",
    "#         instance[1] = re.sub(r'(\\d+)', r'\\g<1> ', instance[1]) #metemos espacio entre número y acrónimos que quedan pegados    \n",
    "#         instance[2] = re.sub(r'(\\d+)', r'\\g<1> ', instance[2])\n",
    "#         instance[1] = re.sub(r'\\s+', ' ', instance[1]).strip()\n",
    "#         instance[2] = re.sub(r'\\s+', ' ', instance[2]).strip()\n",
    "#     return data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ndata = clean_text_after(train_ndata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Get the contexts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the texts before and after the sf, we limit the number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_ends_tokens = 6 #number of tokens to add because <start> and <end> labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_step_f = 10 + star_ends_tokens #number of words to select from the forward context\n",
    "n_step_b = 10 #number of words to select from the backward context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ndata = limit_context(train_ndata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ndata[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Transform into df grouped by LF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic = create_dict(train_ndata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(data_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asign an id to each LF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.assign(id=(data_df['long_form']).astype('category').cat.codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will join each SF with all possible LFs, one for each record, so that later the model works in binary form assigning the probability that that is its LF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_lf_unique = data_df[['short_form', 'long_form']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_lf_unique.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_lf_unique.sort_values('short_form').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged = data_df.merge(sf_lf_unique, on = 'short_form', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.sort_values(['short_form', 'context']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged.sort_values(['short_form', 'context']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target must be 1 or 0. 1 if the corresponding LF is the one assigned to it, 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged['label'] = data_merged.apply(get_label, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged = data_merged[['short_form', 'context', 'long_form_y', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged = data_merged.rename(columns = {'long_form_y':'long_form'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged = data_merged.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged.to_csv('../data/marzo2023/train_data_beto_10_allacron_nomedline_nolevenstein_ownpreproces.csv', index = False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prueba = pd.read_csv('../data/marzo2023/subtrack2/train_data_beto_10_allacron_nomedline_nolevenstein_ownpreproces.csv', sep = '\\t')\n",
    "#prueba = prueba.head(10)\n",
    "#prueba.to_csv('../data/marzo2023/train_prueba.csv', index = False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Prepare Dev Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = dev_raw.merge(dev_abbr[['doc_id', 'Abbreviation', 'Definition']], on = 'doc_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = dev.merge(dev_abbr, on = ['doc_id', 'Abbreviation'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = dev.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = dev[['doc_id', 'texto', 'Abbreviation', 'Definition_x', 'StartOffset', 'EndOffset']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = dev.rename(columns = {'Definition_x':'Definition'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = dev.rename(columns = {'Abbreviation': 'short_form', 'Definition': 'long_form'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = dev.dropna(subset = ['short_form', 'long_form'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev[['StartOffset', 'EndOffset']] = dev[['StartOffset', 'EndOffset']].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean long forms to delete acents, string punctuation etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev['long_form'] = dev['long_form'].map(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize long forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_lf = dev[['short_form', 'long_form']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_lf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_lf_list = sf_lf.groupby('short_form', as_index=False).agg({'long_form': list})\n",
    "sf_lf_list['len'] = sf_lf_list['long_form'].map(lambda x: len(x))\n",
    "sf_lf_list.sort_values('len', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table = pd.crosstab(sf_lf_list['len'], columns = 'Count')\n",
    "table.plot.bar(legend = None)\n",
    "plt.xlabel(\"Definiciones por acrónimo\")\n",
    "plt.ylabel(\"Count\")\n",
    "#plt.show()\n",
    "#plt.savefig('data/acron_count.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.crosstab(sf_lf_list['len'], columns = 'Count')\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Levenshtein distance to normalize Long Forms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get more frequent lf per sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frec = dev['long_form'].value_counts().reset_index()\n",
    "frec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary where keys are the lf to normalize and the values the normalized form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = []\n",
    "for i in sf_lf_list['long_form']:\n",
    "    norm.append(normalize_lf(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = [i for i in norm if i != None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "norm_dict = {}\n",
    "for i in norm:\n",
    "    norm_dict.update(i)\n",
    "#norm_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally normalize long forms over the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = dev.replace({\"long_form\": norm_dict})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that deffinitions have been normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get just ambigous acronyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute this code just in case only ambigous acronyms are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#amb = train.groupby('short_form')['long_form'].nunique().reset_index().sort_values('long_form', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#amb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table = pd.crosstab(amb['long_form'], columns = 'Count')\n",
    "#table.plot.bar()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defin = amb[amb['long_form'] != 1]['short_form'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = train[train['short_form'].isin(defin)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Add texts from Medline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some long forms are imbalanced. Texts from Medline are added to improve balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study imbalaced long forms. Number of rows for each different definition. We can see mostly long forms have just one row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frec2 = dev['long_form'].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.long_form.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev[['doc_id','long_form']].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_count = dev[['doc_id','long_form']].drop_duplicates().groupby('long_form').agg({'doc_id':'count'}).reset_index()\n",
    "def_count.sort_values('doc_id').tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table = pd.crosstab(def_count['doc_id'], columns = 'Count')\n",
    "table.plot.bar(legend = None, figsize=(15,8))\n",
    "plt.xlabel(\"Cantidad de textos en los que aparece la definición\")\n",
    "plt.ylabel(\"Count\")\n",
    "#plt.savefig('data/def_count.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frec2[frec2['long_form'] == 1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find more text for definitions with 3 or less rows in train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_lf = dev.groupby('long_form').size().reset_index().rename(columns={0:'count'}).sort_values('count')\n",
    "dev_lf_list = dev_lf[dev_lf['count'] <= 3]['long_form'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dev_lf_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of deffinition to search in Medline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sorted(dev_lf_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Medline texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medline = pd.read_csv(\"../data/scrapping/textos_medline_scrapping2.csv\")\n",
    "medline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medline[medline['concept'].isin(dev_lf_list)]['concept'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just 8 deffinition have been find in Medline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medline[medline['concept'].isin(dev_lf_list)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medline[medline['concept'].isin(dev_lf_list)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform Medline text with train structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_texts = medline[medline['concept'].isin(dev_lf_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_texts = med_texts[['text', 'concept']].rename(columns = {'text':'texto', 'concept':'long_form'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_lf = dev[dev['long_form'].isin(dev_lf_list)][['short_form', 'long_form']].set_index('long_form').to_dict()['short_form']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_texts['short_form'] = med_texts['long_form'].map(sf_lf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_sf_lf(row):\n",
    "    row['texto'] = row['texto'].replace(row['long_form'], row['short_form'])\n",
    "    return row['texto']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_texts['texto'] = med_texts.apply(replace_sf_lf, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_offset(row):\n",
    "    start_i = row['texto'].find(row['short_form'])\n",
    "    end_i = start_i + len(row['short_form'])\n",
    "    \n",
    "    return start_i, end_i   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_texts['offsets'] = med_texts.apply(find_offset, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_texts[['StartOffset', 'EndOffset']] = pd.DataFrame(med_texts['offsets'].tolist(), index=med_texts.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_texts = med_texts[['texto', 'short_form', 'long_form','StartOffset', 'EndOffset']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_texts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concat train and Medline texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = pd.concat([dev, med_texts], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.reset_index(inplace = True, drop = True)\n",
    "dev.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how many deffinition have low texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frec3 = dev['long_form'].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.crosstab(frec2['long_form'], columns = 'Count')\n",
    "table.plot.bar()\n",
    "plt.title('Number of deffinition records train')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.crosstab(frec3['long_form'], columns = 'Count')\n",
    "table.plot.bar()\n",
    "plt.title('Number of deffinition records after adding Medline texts to train')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf_low = set(dev_lf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf_inmedline = set(medline[medline['concept'].isin(dev_lf_list)]['concept'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#lf_low ^ lf_inmedline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform dataframe to a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = dev[['doc_id', 'texto', 'short_form', 'long_form', 'StartOffset', 'EndOffset']].to_dict('records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the text before and after the SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_ndata, sf_not_found = get_f_b_context_text(dev_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if any SF is not founded in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_not_found_set = set(sf_not_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sf_not_found_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute this code just in case clean the texts are needed: remove string punctuation, accents, lower case, remove double spaces, separate numbers from sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_text_after(data):\n",
    "    \n",
    "#     for instance in data:\n",
    "#         instance[1] = clean_text(instance[1]).lower()\n",
    "#         instance[2] = clean_text(instance[2]).lower()\n",
    "#         instance[1] = re.sub(r'(\\d+)', r'\\g<1> ', instance[1]) #metemos espacio entre número y acrónimos que quedan pegados    \n",
    "#         instance[2] = re.sub(r'(\\d+)', r'\\g<1> ', instance[2])\n",
    "#         instance[1] = re.sub(r'\\s+', ' ', instance[1]).strip()\n",
    "#         instance[2] = re.sub(r'\\s+', ' ', instance[2]).strip()\n",
    "#     return data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ndata = clean_text_after(train_ndata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the contexts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the texts before and after the sf, we limit the number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_ends_tokens = 6 #number of tokens to add because <start> and <end> labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_step_f = 10 + star_ends_tokens #number of words to select from the forward context\n",
    "n_step_b = 10 #number of words to select from the backward context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_ndata = limit_context(dev_ndata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_ndata[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform into df grouped by LF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic = create_dict(dev_ndata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(data_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asign an id to each LF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.assign(id=(data_df['long_form']).astype('category').cat.codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will join each SF with all possible LFs, one for each record, so that later the model works in binary form assigning the probability that that is its LF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_lf_unique = data_df[['short_form', 'long_form']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_lf_unique.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_lf_unique.sort_values('short_form').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged = data_df.merge(sf_lf_unique, on = 'short_form', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.sort_values(['short_form', 'context']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged.sort_values(['short_form', 'context']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target must be 1 or 0. 1 if the corresponding LF is the one assigned to it, 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged['label'] = data_merged.apply(get_label, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged = data_merged[['short_form', 'context', 'long_form_y', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged = data_merged.rename(columns = {'long_form_y':'long_form'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged.to_csv('../data/data_train/dev_data_beto_10_allacron_lfnorm_medline.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Prepare Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing.rename(columns={'nombre':'doc_id'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = testing.rename(columns = {'Definition_lemmatized_x':'Definition'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.rename(columns = {'Abbreviation': 'short_form', 'Definition': 'long_form'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.dropna(subset = ['short_form', 'long_form'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['StartOffset', 'EndOffset']] = test[['StartOffset', 'EndOffset']].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean long forms to delete acents, string punctuation etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['long_form'] = test['long_form'].map(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Normalize long forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_lf_test = test[['short_form', 'long_form']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_lf_list_test = sf_lf_test.groupby('short_form', as_index=False).agg({'long_form': list})\n",
    "sf_lf_list_test['len'] = sf_lf_list_test['long_form'].map(lambda x: len(x))\n",
    "sf_lf_list_test.sort_values('len', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Levenshtein distance to normalize Long Forms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get more frequent lf per sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frec = test['long_form'].value_counts().reset_index()\n",
    "frec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary where keys are the lf to normalize and the values the normalized form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_test = []\n",
    "for i in sf_lf_list_test['long_form']:\n",
    "    norm_test.append(normalize_lf(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_test = [i for i in norm_test if i != None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "norm_dict_test = {}\n",
    "for i in norm_test:\n",
    "    norm_dict_test.update(i)\n",
    "#norm_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally normalize long forms over the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.replace({\"long_form\": norm_dict_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Get just ambigous acronyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute this code just in case only ambigous acronyms are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#amb_test = test.groupby('short_form')['long_form'].nunique().reset_index().sort_values('long_form', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#amb_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table = pd.crosstab(amb_test['long_form'], columns = 'Count')\n",
    "#table.plot.bar()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defin_test = amb_test[amb_test['long_form'] != 1]['short_form'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = test[test['short_form'].isin(defin_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Transform dataframe to a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test[['doc_id', 'texto', 'short_form', 'long_form', 'StartOffset', 'EndOffset']].to_dict('records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Get the text before and after the SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ndata, sf_not_found = get_f_b_context_text(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if any SF is not founded in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_not_found_set = set(sf_not_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sf_not_found_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute this code just in case clean the texts are needed: remove string punctuation, accents, lower case, remove double spaces, separate numbers from sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_text_after(data):\n",
    "    \n",
    "#     for instance in data:\n",
    "#         instance[1] = clean_text(instance[1]).lower()\n",
    "#         instance[2] = clean_text(instance[2]).lower()\n",
    "#         instance[1] = re.sub(r'(\\d+)', r'\\g<1> ', instance[1]) #metemos espacio entre número y acrónimos que quedan pegados    \n",
    "#         instance[2] = re.sub(r'(\\d+)', r'\\g<1> ', instance[2])\n",
    "#         instance[1] = re.sub(r'\\s+', ' ', instance[1]).strip()\n",
    "#         instance[2] = re.sub(r'\\s+', ' ', instance[2]).strip()\n",
    "#     return data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ndata = clean_text_after(train_ndata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Get the contexts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the texts before and after the sf, we limit the number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_ends_tokens = 6 #number of tokens to add because <start> and <end> labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_step_f = 10 + star_ends_tokens #number of words to select from the forward context\n",
    "n_step_b = 10 #number of words to select from the backward context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ndata = limit_context(test_ndata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ndata[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Transform into df grouped by LF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic = create_dict(test_ndata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(data_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asign an id to each LF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.assign(id=(data_df['long_form']).astype('category').cat.codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will join each SF with all possible LFs, one for each record, so that later the model works in binary form assigning the probability that that is its LF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_lf_unique = data_df[['short_form', 'long_form']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_lf_unique.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_lf_unique.sort_values('short_form').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged_test = data_df.merge(sf_lf_unique, on = 'short_form', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.sort_values(['short_form', 'context']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged_test.sort_values(['short_form', 'context']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target must be 1 or 0. 1 if the corresponding LF is the one assigned to it, 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged_test['label'] = data_merged_test.apply(get_label, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged_test = data_merged_test[['short_form', 'context', 'long_form_y', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged_test = data_merged_test.rename(columns = {'long_form_y':'long_form'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged_test.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged_test.to_csv('../data/data_train/test_data_beto_10_allacronim_ownprocess.csv', index = False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Analize acronyms included in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = data_merged_test.merge(data_merged, on = 'short_form', indicator = True, how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[merged['_merge'] == 'left_only'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sorted(merged[merged['_merge'] == 'left_only']['short_form'].unique().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Test Soto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1) Get the short-form from the text\n",
    "\n",
    "I already have it from Soto process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"../../data/marzo2023/test_subtrack2_marzo23soto_parte1.csv\", sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Document_ID</th>\n",
       "      <th>StartOffset</th>\n",
       "      <th>EndOffset</th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>Definition</th>\n",
       "      <th>Definition_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>300</td>\n",
       "      <td>302</td>\n",
       "      <td>mm</td>\n",
       "      <td>aminoacidos más abundantes</td>\n",
       "      <td>aminoacidos más abundantes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>649</td>\n",
       "      <td>651</td>\n",
       "      <td>TC</td>\n",
       "      <td>tomografías computarizadas</td>\n",
       "      <td>tomografías computarizadas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               # Document_ID  StartOffset  EndOffset Abbreviation  \\\n",
       "0  S1130-14732005000200003-1          300        302           mm   \n",
       "1  S1130-14732005000200003-1          649        651           TC   \n",
       "\n",
       "                   Definition       Definition_lemmatized  \n",
       "0  aminoacidos más abundantes  aminoacidos más abundantes  \n",
       "1  tomografías computarizadas  tomografías computarizadas  "
      ]
     },
     "execution_count": 1075,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = test.rename(columns = {'Abbreviation': 'short_form', 'Definition': 'long_form'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = test.dropna(subset = ['short_form', 'long_form'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['StartOffset', 'EndOffset']] = test[['StartOffset', 'EndOffset']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[['# Document_ID', 'StartOffset', 'EndOffset', 'Abbreviation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1080,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Document_ID</th>\n",
       "      <th>StartOffset</th>\n",
       "      <th>EndOffset</th>\n",
       "      <th>Abbreviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>300</td>\n",
       "      <td>302</td>\n",
       "      <td>mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>649</td>\n",
       "      <td>651</td>\n",
       "      <td>TC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               # Document_ID  StartOffset  EndOffset Abbreviation\n",
       "0  S1130-14732005000200003-1          300        302           mm\n",
       "1  S1130-14732005000200003-1          649        651           TC"
      ]
     },
     "execution_count": 1080,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the text from raw to Soto dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1081,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_raw = testing_raw.rename(columns = {'nombre': '# Document_ID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.merge(testing_raw, on = '# Document_ID', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1083,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Document_ID</th>\n",
       "      <th>StartOffset</th>\n",
       "      <th>EndOffset</th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>300</td>\n",
       "      <td>302</td>\n",
       "      <td>mm</td>\n",
       "      <td>Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>649</td>\n",
       "      <td>651</td>\n",
       "      <td>TC</td>\n",
       "      <td>Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               # Document_ID  StartOffset  EndOffset Abbreviation  \\\n",
       "0  S1130-14732005000200003-1          300        302           mm   \n",
       "1  S1130-14732005000200003-1          649        651           TC   \n",
       "\n",
       "                                                                                                 texto  \n",
       "0  Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...  \n",
       "1  Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...  "
      ]
     },
     "execution_count": 1083,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1084,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1561, 5)"
      ]
     },
     "execution_count": 1084,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test.drop_duplicates()\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Separate SF with LF in the text from the ones without explicit LF in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1085,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sflf = pd.read_csv(\"../../data/originales_soto/OutputApproach4Relations_testing.tsv\", sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1086,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Document_ID</th>\n",
       "      <th>Mention_A_type</th>\n",
       "      <th>Mention_A_StartOffset</th>\n",
       "      <th>Mention_A_EndOffset</th>\n",
       "      <th>Mention_A</th>\n",
       "      <th>Relation_type</th>\n",
       "      <th>Mention_B_type</th>\n",
       "      <th>Mention_B_StartOffset</th>\n",
       "      <th>Mention_B_EndOffset</th>\n",
       "      <th>Mention_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>SHORT_FORM</td>\n",
       "      <td>1683</td>\n",
       "      <td>1688</td>\n",
       "      <td>XOMED</td>\n",
       "      <td>SHORT-LONG</td>\n",
       "      <td>LONG_FORM</td>\n",
       "      <td>1672</td>\n",
       "      <td>1681</td>\n",
       "      <td>Medtronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0365-66912011001100006-1</td>\n",
       "      <td>SHORT_FORM</td>\n",
       "      <td>127</td>\n",
       "      <td>129</td>\n",
       "      <td>AV</td>\n",
       "      <td>SHORT-LONG</td>\n",
       "      <td>LONG_FORM</td>\n",
       "      <td>111</td>\n",
       "      <td>125</td>\n",
       "      <td>agudeza visual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0365-66912011001100006-1</td>\n",
       "      <td>SHORT_FORM</td>\n",
       "      <td>206</td>\n",
       "      <td>208</td>\n",
       "      <td>OD</td>\n",
       "      <td>SHORT-LONG</td>\n",
       "      <td>LONG_FORM</td>\n",
       "      <td>193</td>\n",
       "      <td>204</td>\n",
       "      <td>ojo derecho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0365-66912011001100006-1</td>\n",
       "      <td>SHORT_FORM</td>\n",
       "      <td>250</td>\n",
       "      <td>252</td>\n",
       "      <td>OI</td>\n",
       "      <td>SHORT-LONG</td>\n",
       "      <td>LONG_FORM</td>\n",
       "      <td>235</td>\n",
       "      <td>248</td>\n",
       "      <td>ojo izquierdo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0212-71992004000300009-1</td>\n",
       "      <td>SHORT_FORM</td>\n",
       "      <td>933</td>\n",
       "      <td>936</td>\n",
       "      <td>CEA</td>\n",
       "      <td>SHORT-LONG</td>\n",
       "      <td>LONG_FORM</td>\n",
       "      <td>907</td>\n",
       "      <td>931</td>\n",
       "      <td>con marcadores tumorales</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               # Document_ID Mention_A_type  Mention_A_StartOffset  \\\n",
       "0  S1130-14732005000200003-1     SHORT_FORM                   1683   \n",
       "1  S0365-66912011001100006-1     SHORT_FORM                    127   \n",
       "2  S0365-66912011001100006-1     SHORT_FORM                    206   \n",
       "3  S0365-66912011001100006-1     SHORT_FORM                    250   \n",
       "4  S0212-71992004000300009-1     SHORT_FORM                    933   \n",
       "\n",
       "   Mention_A_EndOffset Mention_A Relation_type Mention_B_type  \\\n",
       "0                 1688     XOMED    SHORT-LONG      LONG_FORM   \n",
       "1                  129        AV    SHORT-LONG      LONG_FORM   \n",
       "2                  208        OD    SHORT-LONG      LONG_FORM   \n",
       "3                  252        OI    SHORT-LONG      LONG_FORM   \n",
       "4                  936       CEA    SHORT-LONG      LONG_FORM   \n",
       "\n",
       "   Mention_B_StartOffset  Mention_B_EndOffset                 Mention_B  \n",
       "0                   1672                 1681                 Medtronic  \n",
       "1                    111                  125            agudeza visual  \n",
       "2                    193                  204               ojo derecho  \n",
       "3                    235                  248             ojo izquierdo  \n",
       "4                    907                  931  con marcadores tumorales  "
      ]
     },
     "execution_count": 1086,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sflf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1087,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1561, 5)\n",
      "(213, 10)\n",
      "208\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "print(test.shape)\n",
    "print(test_sflf.shape)\n",
    "print(test['# Document_ID'].nunique())\n",
    "print(test_sflf['# Document_ID'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1088,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_id_test = test['# Document_ID'].unique().tolist()\n",
    "doc_id_test_sflf = test_sflf['# Document_ID'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1089,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 1089,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(doc_id_test) ^ set(doc_id_test_sflf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We took the SF from the other dataset where the LF is explicit written on the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1090,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sflf2 = test_sflf[['# Document_ID', 'Mention_A_StartOffset','Mention_A_EndOffset', 'Mention_A', 'Mention_B']]\n",
    "test_sflf2 = test_sflf2.rename(columns = {'Mention_A_StartOffset':'StartOffset','Mention_A_EndOffset':'EndOffset', 'Mention_A':'Abbreviation', 'Mention_B':'Definition'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = test.merge(test_sflf2, how = 'left', on = ['# Document_ID', 'Abbreviation','StartOffset','EndOffset'], indicator = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1092,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_all.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Document_ID</th>\n",
       "      <th>StartOffset</th>\n",
       "      <th>EndOffset</th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>texto</th>\n",
       "      <th>Definition</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>300</td>\n",
       "      <td>302</td>\n",
       "      <td>mm</td>\n",
       "      <td>Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>649</td>\n",
       "      <td>651</td>\n",
       "      <td>TC</td>\n",
       "      <td>Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>741</td>\n",
       "      <td>743</td>\n",
       "      <td>mm</td>\n",
       "      <td>Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>819</td>\n",
       "      <td>821</td>\n",
       "      <td>RM</td>\n",
       "      <td>Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>1011</td>\n",
       "      <td>1013</td>\n",
       "      <td>IV</td>\n",
       "      <td>Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               # Document_ID  StartOffset  EndOffset Abbreviation  \\\n",
       "0  S1130-14732005000200003-1          300        302           mm   \n",
       "1  S1130-14732005000200003-1          649        651           TC   \n",
       "2  S1130-14732005000200003-1          741        743           mm   \n",
       "3  S1130-14732005000200003-1          819        821           RM   \n",
       "4  S1130-14732005000200003-1         1011       1013           IV   \n",
       "\n",
       "                                                                                                 texto  \\\n",
       "0  Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...   \n",
       "1  Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...   \n",
       "2  Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...   \n",
       "3  Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...   \n",
       "4  Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...   \n",
       "\n",
       "  Definition     _merge  \n",
       "0        NaN  left_only  \n",
       "1        NaN  left_only  \n",
       "2        NaN  left_only  \n",
       "3        NaN  left_only  \n",
       "4        NaN  left_only  "
      ]
     },
     "execution_count": 1093,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "left_only     1380\n",
       "both           181\n",
       "right_only       0\n",
       "Name: _merge, dtype: int64"
      ]
     },
     "execution_count": 1094,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all._merge.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1095,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Document_ID</th>\n",
       "      <th>StartOffset</th>\n",
       "      <th>EndOffset</th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>texto</th>\n",
       "      <th>Definition</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>S0365-66912011001100006-1</td>\n",
       "      <td>127</td>\n",
       "      <td>129</td>\n",
       "      <td>AV</td>\n",
       "      <td>Varón de 75 años, diagnosticado de queratopatía lipoidea bilateral primaria, que refería pérdida...</td>\n",
       "      <td>agudeza visual</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S0365-66912011001100006-1</td>\n",
       "      <td>206</td>\n",
       "      <td>208</td>\n",
       "      <td>OD</td>\n",
       "      <td>Varón de 75 años, diagnosticado de queratopatía lipoidea bilateral primaria, que refería pérdida...</td>\n",
       "      <td>ojo derecho</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>S0365-66912011001100006-1</td>\n",
       "      <td>250</td>\n",
       "      <td>252</td>\n",
       "      <td>OI</td>\n",
       "      <td>Varón de 75 años, diagnosticado de queratopatía lipoidea bilateral primaria, que refería pérdida...</td>\n",
       "      <td>ojo izquierdo</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>S0212-71992004000300009-1</td>\n",
       "      <td>933</td>\n",
       "      <td>936</td>\n",
       "      <td>CEA</td>\n",
       "      <td>Varón de 22 años de edad que acude a consultas por presentar desde hacía 4 meses una adenopatía ...</td>\n",
       "      <td>con marcadores tumorales</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>S0211-69952011000400013-1</td>\n",
       "      <td>1266</td>\n",
       "      <td>1268</td>\n",
       "      <td>TC</td>\n",
       "      <td>Mujer de 58 años con antecedentes personales de síndrome depresivo y estenosis del canal lumbar....</td>\n",
       "      <td>tomografía computarizada</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                # Document_ID  StartOffset  EndOffset Abbreviation  \\\n",
       "8   S0365-66912011001100006-1          127        129           AV   \n",
       "9   S0365-66912011001100006-1          206        208           OD   \n",
       "10  S0365-66912011001100006-1          250        252           OI   \n",
       "15  S0212-71992004000300009-1          933        936          CEA   \n",
       "37  S0211-69952011000400013-1         1266       1268           TC   \n",
       "\n",
       "                                                                                                  texto  \\\n",
       "8   Varón de 75 años, diagnosticado de queratopatía lipoidea bilateral primaria, que refería pérdida...   \n",
       "9   Varón de 75 años, diagnosticado de queratopatía lipoidea bilateral primaria, que refería pérdida...   \n",
       "10  Varón de 75 años, diagnosticado de queratopatía lipoidea bilateral primaria, que refería pérdida...   \n",
       "15  Varón de 22 años de edad que acude a consultas por presentar desde hacía 4 meses una adenopatía ...   \n",
       "37  Mujer de 58 años con antecedentes personales de síndrome depresivo y estenosis del canal lumbar....   \n",
       "\n",
       "                  Definition _merge  \n",
       "8             agudeza visual   both  \n",
       "9                ojo derecho   both  \n",
       "10             ojo izquierdo   both  \n",
       "15  con marcadores tumorales   both  \n",
       "37  tomografía computarizada   both  "
      ]
     },
     "execution_count": 1095,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[df_all._merge == 'both'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save separate SF with LF explicint in the text and SF without definition in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1096,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1561, 7)"
      ]
     },
     "execution_count": 1096,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1097,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[df_all._merge == 'both'].to_csv('../../data/abril23/test_sf_lftext_soto.tsv', sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1098,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_all[df_all._merge == 'left_only']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SF without definition on the text are added its definitions from dictionary and disambiguated with a transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1099,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[['# Document_ID', 'StartOffset', 'EndOffset', 'Abbreviation', 'texto']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Document_ID</th>\n",
       "      <th>StartOffset</th>\n",
       "      <th>EndOffset</th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>300</td>\n",
       "      <td>302</td>\n",
       "      <td>mm</td>\n",
       "      <td>Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>649</td>\n",
       "      <td>651</td>\n",
       "      <td>TC</td>\n",
       "      <td>Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>741</td>\n",
       "      <td>743</td>\n",
       "      <td>mm</td>\n",
       "      <td>Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>819</td>\n",
       "      <td>821</td>\n",
       "      <td>RM</td>\n",
       "      <td>Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>1011</td>\n",
       "      <td>1013</td>\n",
       "      <td>IV</td>\n",
       "      <td>Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               # Document_ID  StartOffset  EndOffset Abbreviation  \\\n",
       "0  S1130-14732005000200003-1          300        302           mm   \n",
       "1  S1130-14732005000200003-1          649        651           TC   \n",
       "2  S1130-14732005000200003-1          741        743           mm   \n",
       "3  S1130-14732005000200003-1          819        821           RM   \n",
       "4  S1130-14732005000200003-1         1011       1013           IV   \n",
       "\n",
       "                                                                                                 texto  \n",
       "0  Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...  \n",
       "1  Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...  \n",
       "2  Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...  \n",
       "3  Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...  \n",
       "4  Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...  "
      ]
     },
     "execution_count": 1100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1101,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['Abbreviation']].drop_duplicates().to_csv('../../data/abril23/test_abbreviation.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3) Give a long-form from AbreMES data base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1102,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "abremes = pd.read_csv(\"../../publicacion/AbreMES-DB/DB/test_abremes.tsv\", sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>Definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zn</td>\n",
       "      <td>zinc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zn</td>\n",
       "      <td>zonas 1 y 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WPW</td>\n",
       "      <td>wolff-parkinson-white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WPW</td>\n",
       "      <td>wolff-parkinson-white manifiesto y oculto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WAIS</td>\n",
       "      <td>wechsler adult intelligence scale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Abbreviation                                 Definition\n",
       "0           Zn                                       zinc\n",
       "1           Zn                                zonas 1 y 2\n",
       "2          WPW                      wolff-parkinson-white\n",
       "3          WPW  wolff-parkinson-white manifiesto y oculto\n",
       "4         WAIS          wechsler adult intelligence scale"
      ]
     },
     "execution_count": 1103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abremes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#abremes['Abbreviation'] = abremes['Abbreviation'].str.replace('[!\"#$%&*+,-./:;<=>?@^_`{|}~]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1106,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Abbreviation'] = test['Abbreviation'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>Definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Abbreviation, Definition]\n",
       "Index: []"
      ]
     },
     "execution_count": 1107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abremes[abremes.Abbreviation == 'mm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1036,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1380, 5)\n",
      "281\n",
      "(1979, 2)\n",
      "232\n"
     ]
    }
   ],
   "source": [
    "print(test.shape)\n",
    "print(test.Abbreviation.nunique())\n",
    "print(abremes.shape)\n",
    "print(abremes.Abbreviation.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1037,
   "metadata": {},
   "outputs": [],
   "source": [
    "abremes = pd.read_csv(\"../../publicacion/AbreMES-DB/DB/pairs.tsv\", sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1038,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>Definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZVTN</td>\n",
       "      <td>Zonas Veredales Transitorias de Normalización</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZUA</td>\n",
       "      <td>Zona de Última Acción</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZU</td>\n",
       "      <td>zona de salud urbana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZU</td>\n",
       "      <td>zonas urbanas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZTPI</td>\n",
       "      <td>Zimbardo Time Perspective Inventory</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Abbreviation                                     Definition\n",
       "0         ZVTN  Zonas Veredales Transitorias de Normalización\n",
       "1          ZUA                          Zona de Última Acción\n",
       "2           ZU                           zona de salud urbana\n",
       "3           ZU                                  zonas urbanas\n",
       "4         ZTPI            Zimbardo Time Perspective Inventory"
      ]
     },
     "execution_count": 1038,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abremes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1039,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/egarcia/anaconda3/envs/tfm/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "abremes['Abbreviation'] = abremes['Abbreviation'].str.replace('[!\"#$%&*+,-./:;<=>?@^_`{|}~]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1040,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.rename(columns = {'abrev':'Abbreviation'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Abbreviation'] = test['Abbreviation'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1380, 5)\n",
      "281\n",
      "(55302, 2)\n",
      "20852\n"
     ]
    }
   ],
   "source": [
    "print(test.shape)\n",
    "print(test.Abbreviation.nunique())\n",
    "print(abremes.shape)\n",
    "print(abremes.Abbreviation.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Document_ID</th>\n",
       "      <th>StartOffset</th>\n",
       "      <th>EndOffset</th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>300</td>\n",
       "      <td>302</td>\n",
       "      <td>mm</td>\n",
       "      <td>Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>649</td>\n",
       "      <td>651</td>\n",
       "      <td>TC</td>\n",
       "      <td>Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               # Document_ID  StartOffset  EndOffset Abbreviation  \\\n",
       "0  S1130-14732005000200003-1          300        302           mm   \n",
       "1  S1130-14732005000200003-1          649        651           TC   \n",
       "\n",
       "                                                                                                 texto  \n",
       "0  Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...  \n",
       "1  Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...  "
      ]
     },
     "execution_count": 1108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1109,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_def = test.merge(abremes, how = 'left', on = 'Abbreviation', indicator = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Document_ID</th>\n",
       "      <th>StartOffset</th>\n",
       "      <th>EndOffset</th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>texto</th>\n",
       "      <th>Definition</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>300</td>\n",
       "      <td>302</td>\n",
       "      <td>mm</td>\n",
       "      <td>Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>649</td>\n",
       "      <td>651</td>\n",
       "      <td>TC</td>\n",
       "      <td>Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...</td>\n",
       "      <td>tomografaa computerizada</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               # Document_ID  StartOffset  EndOffset Abbreviation  \\\n",
       "0  S1130-14732005000200003-1          300        302           mm   \n",
       "1  S1130-14732005000200003-1          649        651           TC   \n",
       "\n",
       "                                                                                                 texto  \\\n",
       "0  Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...   \n",
       "1  Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...   \n",
       "\n",
       "                 Definition     _merge  \n",
       "0                       NaN  left_only  \n",
       "1  tomografaa computerizada       both  "
      ]
     },
     "execution_count": 1110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_def.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1111,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_def['Definition'] = test_def['Definition'].fillna('no_existe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9580, 7)"
      ]
     },
     "execution_count": 1112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_def.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Document_ID</th>\n",
       "      <th>StartOffset</th>\n",
       "      <th>EndOffset</th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>texto</th>\n",
       "      <th>Definition</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>300</td>\n",
       "      <td>302</td>\n",
       "      <td>mm</td>\n",
       "      <td>Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...</td>\n",
       "      <td>no_existe</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>649</td>\n",
       "      <td>651</td>\n",
       "      <td>TC</td>\n",
       "      <td>Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...</td>\n",
       "      <td>tomografaa computerizada</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               # Document_ID  StartOffset  EndOffset Abbreviation  \\\n",
       "0  S1130-14732005000200003-1          300        302           mm   \n",
       "1  S1130-14732005000200003-1          649        651           TC   \n",
       "\n",
       "                                                                                                 texto  \\\n",
       "0  Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...   \n",
       "1  Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...   \n",
       "\n",
       "                 Definition     _merge  \n",
       "0                 no_existe  left_only  \n",
       "1  tomografaa computerizada       both  "
      ]
     },
     "execution_count": 1113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_def.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4) Add dictionary with measure units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1114,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dictionary_measureunits.txt\", \"r\") as data:\n",
    "    dictionary = ast.literal_eval(data.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign definitions from AbreMES DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1115,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_def['Definition'] = test_def.apply(lambda x: defin_dictionary(x, dictionary), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Document_ID</th>\n",
       "      <th>StartOffset</th>\n",
       "      <th>EndOffset</th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>texto</th>\n",
       "      <th>Definition</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>300</td>\n",
       "      <td>302</td>\n",
       "      <td>mm</td>\n",
       "      <td>Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...</td>\n",
       "      <td>milimetro</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>649</td>\n",
       "      <td>651</td>\n",
       "      <td>TC</td>\n",
       "      <td>Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...</td>\n",
       "      <td>tomografaa computerizada</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               # Document_ID  StartOffset  EndOffset Abbreviation  \\\n",
       "0  S1130-14732005000200003-1          300        302           mm   \n",
       "1  S1130-14732005000200003-1          649        651           TC   \n",
       "\n",
       "                                                                                                 texto  \\\n",
       "0  Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...   \n",
       "1  Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...   \n",
       "\n",
       "                 Definition     _merge  \n",
       "0                 milimetro  left_only  \n",
       "1  tomografaa computerizada       both  "
      ]
     },
     "execution_count": 1116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_def.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1117,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_notfind= test_def[test_def['Definition'].isna()]['Abbreviation'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1118,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 1118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sf_notfind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1119,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_def= test_def.dropna(subset = ['Definition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246\n"
     ]
    }
   ],
   "source": [
    "#En test real hay 600 y pico\n",
    "print(test_def.Abbreviation.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1121,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_def = test_def.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Document_ID</th>\n",
       "      <th>StartOffset</th>\n",
       "      <th>EndOffset</th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>texto</th>\n",
       "      <th>Definition</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>300</td>\n",
       "      <td>302</td>\n",
       "      <td>mm</td>\n",
       "      <td>Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...</td>\n",
       "      <td>milimetro</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>649</td>\n",
       "      <td>651</td>\n",
       "      <td>TC</td>\n",
       "      <td>Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...</td>\n",
       "      <td>tomografaa computerizada</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>649</td>\n",
       "      <td>651</td>\n",
       "      <td>TC</td>\n",
       "      <td>Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...</td>\n",
       "      <td>trayectorias clanicas</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>649</td>\n",
       "      <td>651</td>\n",
       "      <td>TC</td>\n",
       "      <td>Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...</td>\n",
       "      <td>trastornos cra3nicos</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>649</td>\n",
       "      <td>651</td>\n",
       "      <td>TC</td>\n",
       "      <td>Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...</td>\n",
       "      <td>taninos condensados</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               # Document_ID  StartOffset  EndOffset Abbreviation  \\\n",
       "0  S1130-14732005000200003-1          300        302           mm   \n",
       "1  S1130-14732005000200003-1          649        651           TC   \n",
       "2  S1130-14732005000200003-1          649        651           TC   \n",
       "3  S1130-14732005000200003-1          649        651           TC   \n",
       "4  S1130-14732005000200003-1          649        651           TC   \n",
       "\n",
       "                                                                                                 texto  \\\n",
       "0  Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...   \n",
       "1  Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...   \n",
       "2  Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...   \n",
       "3  Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...   \n",
       "4  Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...   \n",
       "\n",
       "                 Definition     _merge  \n",
       "0                 milimetro  left_only  \n",
       "1  tomografaa computerizada       both  \n",
       "2     trayectorias clanicas       both  \n",
       "3      trastornos cra3nicos       both  \n",
       "4       taninos condensados       both  "
      ]
     },
     "execution_count": 1122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_def.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9407, 7)\n",
      "246\n"
     ]
    }
   ],
   "source": [
    "print(test_def.shape)\n",
    "print(test_def.Abbreviation.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Normalize long forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Document_ID</th>\n",
       "      <th>StartOffset</th>\n",
       "      <th>EndOffset</th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>texto</th>\n",
       "      <th>Definition</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>S0365-66912007001100010-1</td>\n",
       "      <td>262</td>\n",
       "      <td>264</td>\n",
       "      <td>II</td>\n",
       "      <td>Paciente de 63 años que refería déficit de agudeza visual (AV) en el ojo derecho (OD) de varios ...</td>\n",
       "      <td>infrahepa!tica</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>S0365-66912007001100010-1</td>\n",
       "      <td>262</td>\n",
       "      <td>264</td>\n",
       "      <td>II</td>\n",
       "      <td>Paciente de 63 años que refería déficit de agudeza visual (AV) en el ojo derecho (OD) de varios ...</td>\n",
       "      <td>inguinales directas</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>S0365-66912007001100010-1</td>\n",
       "      <td>262</td>\n",
       "      <td>264</td>\n",
       "      <td>II</td>\n",
       "      <td>Paciente de 63 años que refería déficit de agudeza visual (AV) en el ojo derecho (OD) de varios ...</td>\n",
       "      <td>intraoperatoria en urologaa</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>S0365-66912007001100010-1</td>\n",
       "      <td>262</td>\n",
       "      <td>264</td>\n",
       "      <td>II</td>\n",
       "      <td>Paciente de 63 años que refería déficit de agudeza visual (AV) en el ojo derecho (OD) de varios ...</td>\n",
       "      <td>informacia3n</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>S0365-66912007001100010-1</td>\n",
       "      <td>262</td>\n",
       "      <td>264</td>\n",
       "      <td>II</td>\n",
       "      <td>Paciente de 63 años que refería déficit de agudeza visual (AV) en el ojo derecho (OD) de varios ...</td>\n",
       "      <td>intestinal</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8019</th>\n",
       "      <td>S1137-66272014000300015-1</td>\n",
       "      <td>732</td>\n",
       "      <td>734</td>\n",
       "      <td>II</td>\n",
       "      <td>Paciente mujer de 57 años, sin antecedentes médicos de interés, exfumadora desde hace 15 años, r...</td>\n",
       "      <td>insuficiencia cardaaca</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8020</th>\n",
       "      <td>S1137-66272014000300015-1</td>\n",
       "      <td>732</td>\n",
       "      <td>734</td>\n",
       "      <td>II</td>\n",
       "      <td>Paciente mujer de 57 años, sin antecedentes médicos de interés, exfumadora desde hace 15 años, r...</td>\n",
       "      <td>investigacia3n urola3gica</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8021</th>\n",
       "      <td>S1137-66272014000300015-1</td>\n",
       "      <td>732</td>\n",
       "      <td>734</td>\n",
       "      <td>II</td>\n",
       "      <td>Paciente mujer de 57 años, sin antecedentes médicos de interés, exfumadora desde hace 15 años, r...</td>\n",
       "      <td>italia</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8022</th>\n",
       "      <td>S1137-66272014000300015-1</td>\n",
       "      <td>732</td>\n",
       "      <td>734</td>\n",
       "      <td>II</td>\n",
       "      <td>Paciente mujer de 57 años, sin antecedentes médicos de interés, exfumadora desde hace 15 años, r...</td>\n",
       "      <td>investigacia3n</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8023</th>\n",
       "      <td>S1137-66272014000300015-1</td>\n",
       "      <td>732</td>\n",
       "      <td>734</td>\n",
       "      <td>II</td>\n",
       "      <td>Paciente mujer de 57 años, sin antecedentes médicos de interés, exfumadora desde hace 15 años, r...</td>\n",
       "      <td>interauricular</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>574 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  # Document_ID  StartOffset  EndOffset Abbreviation  \\\n",
       "558   S0365-66912007001100010-1          262        264           II   \n",
       "559   S0365-66912007001100010-1          262        264           II   \n",
       "560   S0365-66912007001100010-1          262        264           II   \n",
       "561   S0365-66912007001100010-1          262        264           II   \n",
       "562   S0365-66912007001100010-1          262        264           II   \n",
       "...                         ...          ...        ...          ...   \n",
       "8019  S1137-66272014000300015-1          732        734           II   \n",
       "8020  S1137-66272014000300015-1          732        734           II   \n",
       "8021  S1137-66272014000300015-1          732        734           II   \n",
       "8022  S1137-66272014000300015-1          732        734           II   \n",
       "8023  S1137-66272014000300015-1          732        734           II   \n",
       "\n",
       "                                                                                                    texto  \\\n",
       "558   Paciente de 63 años que refería déficit de agudeza visual (AV) en el ojo derecho (OD) de varios ...   \n",
       "559   Paciente de 63 años que refería déficit de agudeza visual (AV) en el ojo derecho (OD) de varios ...   \n",
       "560   Paciente de 63 años que refería déficit de agudeza visual (AV) en el ojo derecho (OD) de varios ...   \n",
       "561   Paciente de 63 años que refería déficit de agudeza visual (AV) en el ojo derecho (OD) de varios ...   \n",
       "562   Paciente de 63 años que refería déficit de agudeza visual (AV) en el ojo derecho (OD) de varios ...   \n",
       "...                                                                                                   ...   \n",
       "8019  Paciente mujer de 57 años, sin antecedentes médicos de interés, exfumadora desde hace 15 años, r...   \n",
       "8020  Paciente mujer de 57 años, sin antecedentes médicos de interés, exfumadora desde hace 15 años, r...   \n",
       "8021  Paciente mujer de 57 años, sin antecedentes médicos de interés, exfumadora desde hace 15 años, r...   \n",
       "8022  Paciente mujer de 57 años, sin antecedentes médicos de interés, exfumadora desde hace 15 años, r...   \n",
       "8023  Paciente mujer de 57 años, sin antecedentes médicos de interés, exfumadora desde hace 15 años, r...   \n",
       "\n",
       "                       Definition _merge  \n",
       "558                infrahepa!tica   both  \n",
       "559           inguinales directas   both  \n",
       "560   intraoperatoria en urologaa   both  \n",
       "561                  informacia3n   both  \n",
       "562                    intestinal   both  \n",
       "...                           ...    ...  \n",
       "8019       insuficiencia cardaaca   both  \n",
       "8020    investigacia3n urola3gica   both  \n",
       "8021                       italia   both  \n",
       "8022               investigacia3n   both  \n",
       "8023               interauricular   both  \n",
       "\n",
       "[574 rows x 7 columns]"
      ]
     },
     "execution_count": 1124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_def[test_def['Abbreviation'] == 'II']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1125,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_lf_test = test_def[['Abbreviation', 'Definition']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>Definition</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AP</td>\n",
       "      <td>[andadores de puntillas, atencia3n primaria, a!reas protegidas, alcohol peralico, angioplastia p...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>DC</td>\n",
       "      <td>[desnutricia3n cra3nica, de cabeza, dermatosis cenicienta, dendraticas, doppler color, distorsio...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>CA</td>\n",
       "      <td>[control absoluto, comportamiento alimentario, calcio en la sangre, crioterapia, ca!mara anterio...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA</td>\n",
       "      <td>[avena, agudizados, aguda, aminoa!cidos, adenoamigdalectomaa, avanzados, a!cido asca3rbico, abdo...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>CI</td>\n",
       "      <td>[ciento, calorimetraa indirecta, cardiaca, concentracia3n del inocula3, cuidadores informales, c...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Mg</td>\n",
       "      <td>[magnesia]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Mc</td>\n",
       "      <td>[metacognicia3n]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>LSI</td>\n",
       "      <td>[lineal invariante a desplazamiento]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>LDH</td>\n",
       "      <td>[la!ctico deshidrogenasa]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>ui</td>\n",
       "      <td>[Unidades Internacionales]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Abbreviation  \\\n",
       "15            AP   \n",
       "40            DC   \n",
       "28            CA   \n",
       "0             AA   \n",
       "33            CI   \n",
       "..           ...   \n",
       "143           Mg   \n",
       "142           Mc   \n",
       "129          LSI   \n",
       "120          LDH   \n",
       "245           ui   \n",
       "\n",
       "                                                                                              Definition  \\\n",
       "15   [andadores de puntillas, atencia3n primaria, a!reas protegidas, alcohol peralico, angioplastia p...   \n",
       "40   [desnutricia3n cra3nica, de cabeza, dermatosis cenicienta, dendraticas, doppler color, distorsio...   \n",
       "28   [control absoluto, comportamiento alimentario, calcio en la sangre, crioterapia, ca!mara anterio...   \n",
       "0    [avena, agudizados, aguda, aminoa!cidos, adenoamigdalectomaa, avanzados, a!cido asca3rbico, abdo...   \n",
       "33   [ciento, calorimetraa indirecta, cardiaca, concentracia3n del inocula3, cuidadores informales, c...   \n",
       "..                                                                                                   ...   \n",
       "143                                                                                           [magnesia]   \n",
       "142                                                                                     [metacognicia3n]   \n",
       "129                                                                 [lineal invariante a desplazamiento]   \n",
       "120                                                                            [la!ctico deshidrogenasa]   \n",
       "245                                                                           [Unidades Internacionales]   \n",
       "\n",
       "     len  \n",
       "15    58  \n",
       "40    57  \n",
       "28    53  \n",
       "0     53  \n",
       "33    49  \n",
       "..   ...  \n",
       "143    1  \n",
       "142    1  \n",
       "129    1  \n",
       "120    1  \n",
       "245    1  \n",
       "\n",
       "[246 rows x 3 columns]"
      ]
     },
     "execution_count": 1126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf_lf_list_test = sf_lf_test.groupby('Abbreviation', as_index=False).agg({'Definition': list})\n",
    "sf_lf_list_test['len'] = sf_lf_list_test['Definition'].map(lambda x: len(x))\n",
    "sf_lf_list_test.sort_values('len', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply Levenshtein distance to normalize Long Forms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get more frequent lf per sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>centimetro</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tomografaa computerizada</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tomografaa computada de abdomen</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tomografaa axial computarizada de ta3rax</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tratamiento asertivo comunitario</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>aceite residual automotriz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>infarto agudo del miocardio</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>trasplante de pa!ncreas</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>tiempo programado</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>low density lipoproteins</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1975 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         index  Definition\n",
       "0                                   centimetro         143\n",
       "1                     tomografaa computerizada         126\n",
       "2              tomografaa computada de abdomen          79\n",
       "3     tomografaa axial computarizada de ta3rax          79\n",
       "4             tratamiento asertivo comunitario          79\n",
       "...                                        ...         ...\n",
       "1970                aceite residual automotriz           1\n",
       "1971               infarto agudo del miocardio           1\n",
       "1972                   trasplante de pa!ncreas           1\n",
       "1973                         tiempo programado           1\n",
       "1974                  low density lipoproteins           1\n",
       "\n",
       "[1975 rows x 2 columns]"
      ]
     },
     "execution_count": 1127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frec = test_def['Definition'].value_counts().reset_index()\n",
    "frec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary where keys are the lf to normalize and the values the normalized form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1128,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_test = []\n",
    "for i in sf_lf_list_test['Definition']:\n",
    "    norm_test.append(normalize_lf(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1129,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_test = [i for i in norm_test if i != None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1130,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "norm_dict_test = {}\n",
    "for i in norm_test:\n",
    "    norm_dict_test.update(i)\n",
    "#norm_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally normalize long forms over the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Document_ID</th>\n",
       "      <th>StartOffset</th>\n",
       "      <th>EndOffset</th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>texto</th>\n",
       "      <th>Definition</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>300</td>\n",
       "      <td>302</td>\n",
       "      <td>mm</td>\n",
       "      <td>Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...</td>\n",
       "      <td>milimetro</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>649</td>\n",
       "      <td>651</td>\n",
       "      <td>TC</td>\n",
       "      <td>Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...</td>\n",
       "      <td>tomografaa computerizada</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>649</td>\n",
       "      <td>651</td>\n",
       "      <td>TC</td>\n",
       "      <td>Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...</td>\n",
       "      <td>trayectorias clanicas</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>649</td>\n",
       "      <td>651</td>\n",
       "      <td>TC</td>\n",
       "      <td>Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...</td>\n",
       "      <td>trastornos cra3nicos</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>649</td>\n",
       "      <td>651</td>\n",
       "      <td>TC</td>\n",
       "      <td>Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...</td>\n",
       "      <td>taninos condensados</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               # Document_ID  StartOffset  EndOffset Abbreviation  \\\n",
       "0  S1130-14732005000200003-1          300        302           mm   \n",
       "1  S1130-14732005000200003-1          649        651           TC   \n",
       "2  S1130-14732005000200003-1          649        651           TC   \n",
       "3  S1130-14732005000200003-1          649        651           TC   \n",
       "4  S1130-14732005000200003-1          649        651           TC   \n",
       "\n",
       "                                                                                                 texto  \\\n",
       "0  Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...   \n",
       "1  Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...   \n",
       "2  Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...   \n",
       "3  Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...   \n",
       "4  Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...   \n",
       "\n",
       "                 Definition     _merge  \n",
       "0                 milimetro  left_only  \n",
       "1  tomografaa computerizada       both  \n",
       "2     trayectorias clanicas       both  \n",
       "3      trastornos cra3nicos       both  \n",
       "4       taninos condensados       both  "
      ]
     },
     "execution_count": 1131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_def.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1132,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_def = test_def.replace({\"Definition\": norm_dict_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Document_ID</th>\n",
       "      <th>StartOffset</th>\n",
       "      <th>EndOffset</th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>texto</th>\n",
       "      <th>Definition</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>300</td>\n",
       "      <td>302</td>\n",
       "      <td>mm</td>\n",
       "      <td>Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...</td>\n",
       "      <td>milimetro</td>\n",
       "      <td>left_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>649</td>\n",
       "      <td>651</td>\n",
       "      <td>TC</td>\n",
       "      <td>Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...</td>\n",
       "      <td>tomografaa computerizada</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>649</td>\n",
       "      <td>651</td>\n",
       "      <td>TC</td>\n",
       "      <td>Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...</td>\n",
       "      <td>trayectorias clanicas</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>649</td>\n",
       "      <td>651</td>\n",
       "      <td>TC</td>\n",
       "      <td>Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...</td>\n",
       "      <td>trastornos cra3nicos</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>649</td>\n",
       "      <td>651</td>\n",
       "      <td>TC</td>\n",
       "      <td>Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...</td>\n",
       "      <td>taninos condensados</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               # Document_ID  StartOffset  EndOffset Abbreviation  \\\n",
       "0  S1130-14732005000200003-1          300        302           mm   \n",
       "1  S1130-14732005000200003-1          649        651           TC   \n",
       "2  S1130-14732005000200003-1          649        651           TC   \n",
       "3  S1130-14732005000200003-1          649        651           TC   \n",
       "4  S1130-14732005000200003-1          649        651           TC   \n",
       "\n",
       "                                                                                                 texto  \\\n",
       "0  Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...   \n",
       "1  Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...   \n",
       "2  Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...   \n",
       "3  Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...   \n",
       "4  Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue interven...   \n",
       "\n",
       "                 Definition     _merge  \n",
       "0                 milimetro  left_only  \n",
       "1  tomografaa computerizada       both  \n",
       "2     trayectorias clanicas       both  \n",
       "3      trastornos cra3nicos       both  \n",
       "4       taninos condensados       both  "
      ]
     },
     "execution_count": 1133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_def.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9407, 7)"
      ]
     },
     "execution_count": 1134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_def.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1135,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_def = test_def.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9392, 7)"
      ]
     },
     "execution_count": 1136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_def.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Transform dataframe to a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data = test[['doc_id', 'texto', 'short_form', 'long_form', 'StartOffset', 'EndOffset']].to_dict('records')\n",
    "test_data = test_def.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9392"
      ]
     },
     "execution_count": 1138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Get the text before and after the SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1139,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_ndata, sf_not_found = get_f_b_context_text(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9009"
      ]
     },
     "execution_count": 1140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ndata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if any SF is not founded in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1141,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_not_found_set = set(sf_not_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 1142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sf_not_found_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1143,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S1130-14732005000200003-1',\n",
       " 'mm',\n",
       " 'Mujer de 29 años de edad, diagnosticada de cavernomas múltiples en 1996, año en que fue intervenida tras hemorragia frontal de angioma cavernoso frontal derecho, con evacuación del hematoma y resección de la lesión vascular. Ese mismo año se objetivó un pequeño angioma protuberancial izquierdo de 3  <start> mm <end> ',\n",
       " 'de diámetro. La paciente permaneció asintomática hasta enero de 2004, cuando ingresa por presentar cefalea y vómitos asociados a hemihipoestesia con parestesias de hemicuerpo derecho y hemiparesia 4/5 derecha. En la exploración destacaba un nistagmo vertical, una hemiparesia derecha 4/5 y una hemihipoestesia derecha con extinción sensitiva.\\nLa TC craneal realizada al ingreso mostraba un hematoma protuberancial posterior derecho de 20 mm de diámetro, relacionado con la localización ya conocida del cavernoma.\\nLa RM cerebral confirmaba le presencia de un angioma cavernoso protuberancial con la presencia de hemosiderina perilesional que definían crecimiento y sangrado de la lesión, la cual deformaba el IV ventrículo en la fosa romboidea a la altura del colículo facial izquierdo sin aflorar al ventrículo ni a ninguna otra parte de la superficie del tronco del encéfalo.\\nDada la progresión clínica y radiológica de la lesión se decidió intervenir quirúrgicamente, usando monitorización intraoperatoria que consistió en estimulación de la superficie de la fosa romboidea, para determinar la localización de los núcleos de los pares craneales VII X y XII izquierdos. También se realizaron potenciales auditivos intraoperatorios. Para estimular los núcleos localizados en la fosa romboidea hemos utilizado el sistema de monitorización nerviosa NIM-Response® System (Medtronic, XOMED) aplicando un estímulo monopolar a voltaje constante con pulso monofásico rectangular. La intensidad máxima aplicada fue de 2 mA. La duración del estímulo fue de 100 µsegundos y la frecuencia de 10 Hz. La lectura electromiográfica se realizó con electrodos colocados con una separación de 5 mm en disposición bipolar para cubrir el área muscular representativa. Los electrodos para monitorizar el nervio facial se colocaron en los músculos orbiculares de la boca y ojo. Para registrar el XII par craneal los electrodos se colocaron en el músculo geniogloso. El registro del X par se realizó con sensores de las cuerdas vocales localizados en el tubo de anestesia.\\nLa paciente fue colocada en decúbito prono realizándose una craniectomía suboccipital y exéresis del arco posterior de C1. Tras apertura dural y aracnoidea y bajo control microscópico se apreciaba asimetría a la altura del colículo facial izquierdo. Tras identificar anatómicamente los núcleos X y XII, se confirmó su funcionalidad con estimulación intraoperatoria con respuesta electromiográfica positiva. Se localizó el núcleo facial sólo mediante estimulación, encontrándose muy lateral, en el borde entre el ángulo de la fosa romboidea y el pedúnculo cerebeloso medio. El núcleo probablemente se encontraba desplazado lateralmente por el efecto de masa del hematoma que no se visualizaba en superficie. Se realizó incisión pial, se localizó el hematoma que se evacuó, así como el cavernoma causante del mismo. Al finalizar la resección se repitió la monitorización de los núcleos involucrados, obteniendo respuesta electromiográfica en todos, si bien la intensidad del facial, sobre todo de orbicular de los labios, había descendido. Los potenciales auditivos se mantuvieron con la misma respuesta que en el preoperatorio.\\nEn el postoperatorio la paciente presentó paresia transitoria de X y XII, que recuperó íntegramente a las 48 horas y que sospechamos se debió al bloqueo producido por el estímulo eléctrico repetido. También presentó una oftalmoplejía internuclear con síndrome del uno y medio que ha recuperado de manera parcial, persistiendo una paresia nuclear del VI par izquierdo, así como una paresia facial nuclear que ha mejorado progresivamente. En cuanto a vías largas no se observa déficit motor, si bien presenta inestabilidad a la marcha, aunque deambula sin ayuda, de manera autónoma. El nivel de conciencia es bueno, con funciones superiores cognitivas conservadas.\\n',\n",
       " 'milimetro']"
      ]
     },
     "execution_count": 1143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ndata[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Get the contexts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the texts before and after the sf, we limit the number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1144,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_ends_tokens = 6 #number of tokens to add because <start> and <end> labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1145,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_step_f = 10 + star_ends_tokens #number of words to select from the forward context\n",
    "n_step_b = 10 #number of words to select from the backward context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1146,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ndata = limit_context(test_ndata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9009"
      ]
     },
     "execution_count": 1147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ndata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1148,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S1130-14732005000200003-1',\n",
       " 'mm',\n",
       " 'año se objetivó un pequeño angioma protuberancial izquierdo de 3 < start > mm < end >',\n",
       " 'de diámetro . La paciente permaneció asintomática hasta enero de',\n",
       " 'milimetro']"
      ]
     },
     "execution_count": 1148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ndata[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Asign an LF to each SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1149,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic = create_dict(test_ndata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9009"
      ]
     },
     "execution_count": 1150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1151,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(data_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_df['label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1158,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['long_form'] = data_df['long_form'].str.replace('milimetro','milímetro')\n",
    "data_df['long_form'] = data_df['long_form'].str.replace('centimetro','centímetro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1162,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['long_form'] = data_df['long_form'].str.replace('Kilogramo','kilogramo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>short_form</th>\n",
       "      <th>context</th>\n",
       "      <th>long_form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>mm</td>\n",
       "      <td>año se objetivó un pequeño angioma protuberancial izquierdo de 3 &lt; start &gt; mm &lt; end &gt; de diámetr...</td>\n",
       "      <td>milímetro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>TC</td>\n",
       "      <td>4/5 y una hemihipoestesia derecha con extinción sensitiva . La &lt; start &gt; TC &lt; end &gt; craneal real...</td>\n",
       "      <td>tomografaa computerizada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>TC</td>\n",
       "      <td>4/5 y una hemihipoestesia derecha con extinción sensitiva . La &lt; start &gt; TC &lt; end &gt; craneal real...</td>\n",
       "      <td>trayectorias clanicas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>TC</td>\n",
       "      <td>4/5 y una hemihipoestesia derecha con extinción sensitiva . La &lt; start &gt; TC &lt; end &gt; craneal real...</td>\n",
       "      <td>trastornos cra3nicos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>TC</td>\n",
       "      <td>4/5 y una hemihipoestesia derecha con extinción sensitiva . La &lt; start &gt; TC &lt; end &gt; craneal real...</td>\n",
       "      <td>taninos condensados</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      doc_id short_form  \\\n",
       "0  S1130-14732005000200003-1         mm   \n",
       "1  S1130-14732005000200003-1         TC   \n",
       "2  S1130-14732005000200003-1         TC   \n",
       "3  S1130-14732005000200003-1         TC   \n",
       "4  S1130-14732005000200003-1         TC   \n",
       "\n",
       "                                                                                               context  \\\n",
       "0  año se objetivó un pequeño angioma protuberancial izquierdo de 3 < start > mm < end > de diámetr...   \n",
       "1  4/5 y una hemihipoestesia derecha con extinción sensitiva . La < start > TC < end > craneal real...   \n",
       "2  4/5 y una hemihipoestesia derecha con extinción sensitiva . La < start > TC < end > craneal real...   \n",
       "3  4/5 y una hemihipoestesia derecha con extinción sensitiva . La < start > TC < end > craneal real...   \n",
       "4  4/5 y una hemihipoestesia derecha con extinción sensitiva . La < start > TC < end > craneal real...   \n",
       "\n",
       "                  long_form  \n",
       "0                 milímetro  \n",
       "1  tomografaa computerizada  \n",
       "2     trayectorias clanicas  \n",
       "3      trastornos cra3nicos  \n",
       "4       taninos condensados  "
      ]
     },
     "execution_count": 1163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9009, 4)"
      ]
     },
     "execution_count": 1164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1165,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df[['doc_id', 'short_form', 'long_form']].to_csv('../../data/abril23/test_prueba.csv', sep = '\\t',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove doc_id for the model but save to join it after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1166,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df2 = data_df[['short_form', 'context', 'long_form']]\n",
    "data_doc_ids = data_df[['doc_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1167,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_doc_ids.to_csv('../../data/julio23/test_data_beto_10_allacronim_normalizedlf_abremesprocessed_julio23_IDS.csv', index = False, sep = '\\t')\n",
    "data_df2.to_csv('../../data/julio23/test_data_beto_10_allacronim_normalizedlf_abremesprocessed_julio23.csv', index = False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Datasets for model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prueba = pd.read_csv('../data/marzo2023/subtrack2/train_data_beto_10_allacron_nomedline_nolevenstein_ownpreproces.csv', sep = '\\t')\n",
    "#prueba = data_df2.head(10)\n",
    "#prueba.to_csv('../data/marzo2023/subtrack2/test_prueba_input.csv', index = False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate train in train and validation to check if over train data the model predicts right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../../data/data_train/train_data_beto_10_NOamb_lfnorm_medline.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_form</th>\n",
       "      <th>context</th>\n",
       "      <th>long_form</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dl</td>\n",
       "      <td>del líquido una glucorraquia normal , proteinorraquia de 102 mg/ &lt; start &gt; dl &lt; end &gt; 960 célula...</td>\n",
       "      <td>decilitro</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  short_form  \\\n",
       "0         dl   \n",
       "\n",
       "                                                                                               context  \\\n",
       "0  del líquido una glucorraquia normal , proteinorraquia de 102 mg/ < start > dl < end > 960 célula...   \n",
       "\n",
       "   long_form  label  \n",
       "0  decilitro      1  "
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split, val = train_test_split(train, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "del val['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split.to_csv('../../data/abril23/train_splited_for_test.csv', index = False)\n",
    "val.to_csv('../../data/abril23/validation_from_train_splited_for_test.csv', index = False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5768, 4)\n",
      "(1442, 4)\n"
     ]
    }
   ],
   "source": [
    "print(train_split.shape)\n",
    "print(val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_output = pd.read_csv('../../data/abril23/train_validation_split_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "del val_output['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_form</th>\n",
       "      <th>context</th>\n",
       "      <th>long_form</th>\n",
       "      <th>sentences</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>en este caso 15 litros de solución salina a 37º &lt; start &gt; C &lt; end &gt; para obtener un drenaje clar...</td>\n",
       "      <td>peak c</td>\n",
       "      <td>[CLS] peak c [SEP] en este caso 15 litros de solución salina a 37º &lt; start &gt; C &lt; end &gt; para obte...</td>\n",
       "      <td>0.003280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GGT</td>\n",
       "      <td>del perfil hepático de predominio colestásico ( fosfatasa alcalina y &lt; start &gt; GGT &lt; end &gt; más d...</td>\n",
       "      <td>gama glutamil transferasa</td>\n",
       "      <td>[CLS] gama glutamil transferasa [SEP] del perfil hepático de predominio colestásico ( fosfatasa ...</td>\n",
       "      <td>0.005237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UI</td>\n",
       "      <td>GPT 96 UI/l , GGT 182 UI/l , FA 148 &lt; start &gt; UI &lt; end &gt; l ) . Valorada por Neurología , indican...</td>\n",
       "      <td>unidad internacional</td>\n",
       "      <td>[CLS] unidad internacional [SEP] GPT 96 UI/l , GGT 182 UI/l , FA 148 &lt; start &gt; UI &lt; end &gt; l ) . ...</td>\n",
       "      <td>0.999654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anti-CCP</td>\n",
       "      <td>altos de factor reumatoide y anticuerpos antipéptido cíclico citrulinado ( &lt; start &gt; anti-CCP &lt; ...</td>\n",
       "      <td>anticuerpos antipeptido ciclico citrulinado</td>\n",
       "      <td>[CLS] anticuerpos antipeptido ciclico citrulinado [SEP] altos de factor reumatoide y anticuerpos...</td>\n",
       "      <td>0.999379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GRE</td>\n",
       "      <td>Fast Spin Eco , potenciadas en T1 , T2 , &lt; start &gt; GRE &lt; end &gt; y T1 con gadolinio , encontrando ...</td>\n",
       "      <td>gradientecho</td>\n",
       "      <td>[CLS] gradientecho [SEP] Fast Spin Eco , potenciadas en T1 , T2 , &lt; start &gt; GRE &lt; end &gt; y T1 con...</td>\n",
       "      <td>0.658944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  short_form  \\\n",
       "0          C   \n",
       "1        GGT   \n",
       "2         UI   \n",
       "3   anti-CCP   \n",
       "4        GRE   \n",
       "\n",
       "                                                                                               context  \\\n",
       "0  en este caso 15 litros de solución salina a 37º < start > C < end > para obtener un drenaje clar...   \n",
       "1  del perfil hepático de predominio colestásico ( fosfatasa alcalina y < start > GGT < end > más d...   \n",
       "2  GPT 96 UI/l , GGT 182 UI/l , FA 148 < start > UI < end > l ) . Valorada por Neurología , indican...   \n",
       "3  altos de factor reumatoide y anticuerpos antipéptido cíclico citrulinado ( < start > anti-CCP < ...   \n",
       "4  Fast Spin Eco , potenciadas en T1 , T2 , < start > GRE < end > y T1 con gadolinio , encontrando ...   \n",
       "\n",
       "                                     long_form  \\\n",
       "0                                       peak c   \n",
       "1                    gama glutamil transferasa   \n",
       "2                         unidad internacional   \n",
       "3  anticuerpos antipeptido ciclico citrulinado   \n",
       "4                                 gradientecho   \n",
       "\n",
       "                                                                                             sentences  \\\n",
       "0  [CLS] peak c [SEP] en este caso 15 litros de solución salina a 37º < start > C < end > para obte...   \n",
       "1  [CLS] gama glutamil transferasa [SEP] del perfil hepático de predominio colestásico ( fosfatasa ...   \n",
       "2  [CLS] unidad internacional [SEP] GPT 96 UI/l , GGT 182 UI/l , FA 148 < start > UI < end > l ) . ...   \n",
       "3  [CLS] anticuerpos antipeptido ciclico citrulinado [SEP] altos de factor reumatoide y anticuerpos...   \n",
       "4  [CLS] gradientecho [SEP] Fast Spin Eco , potenciadas en T1 , T2 , < start > GRE < end > y T1 con...   \n",
       "\n",
       "   Prediction  \n",
       "0    0.003280  \n",
       "1    0.005237  \n",
       "2    0.999654  \n",
       "3    0.999379  \n",
       "4    0.658944  "
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1442.000000\n",
       "mean        0.716069\n",
       "std         0.426520\n",
       "min         0.000776\n",
       "25%         0.186323\n",
       "50%         0.998313\n",
       "75%         0.999427\n",
       "max         0.999700\n",
       "Name: Prediction, dtype: float64"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_output.Prediction.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_form</th>\n",
       "      <th>context</th>\n",
       "      <th>long_form</th>\n",
       "      <th>sentences</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UI</td>\n",
       "      <td>GPT 96 UI/l , GGT 182 UI/l , FA 148 &lt; start &gt; UI &lt; end &gt; l ) . Valorada por Neurología , indican...</td>\n",
       "      <td>unidad internacional</td>\n",
       "      <td>[CLS] unidad internacional [SEP] GPT 96 UI/l , GGT 182 UI/l , FA 148 &lt; start &gt; UI &lt; end &gt; l ) . ...</td>\n",
       "      <td>0.999654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anti-CCP</td>\n",
       "      <td>altos de factor reumatoide y anticuerpos antipéptido cíclico citrulinado ( &lt; start &gt; anti-CCP &lt; ...</td>\n",
       "      <td>anticuerpos antipeptido ciclico citrulinado</td>\n",
       "      <td>[CLS] anticuerpos antipeptido ciclico citrulinado [SEP] altos de factor reumatoide y anticuerpos...</td>\n",
       "      <td>0.999379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UCI</td>\n",
       "      <td>, 7/10 y 1/10 durante su estancia en Urgencias , &lt; start &gt; UCI &lt; end &gt; Sala de Hospitalización y...</td>\n",
       "      <td>unidad cuidados intensivos</td>\n",
       "      <td>[CLS] unidad cuidados intensivos [SEP] , 7/10 y 1/10 durante su estancia en Urgencias , &lt; start ...</td>\n",
       "      <td>0.998991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B</td>\n",
       "      <td>El metoprolol pertenece a una clase de medicamentos llamados bloqueadores &lt; start &gt; B &lt; end &gt; Fu...</td>\n",
       "      <td>beta</td>\n",
       "      <td>[CLS] beta [SEP] El metoprolol pertenece a una clase de medicamentos llamados bloqueadores &lt; sta...</td>\n",
       "      <td>0.998262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PIO</td>\n",
       "      <td>una exploración rutinaria , se descubrió una presión intraocular ( &lt; start &gt; PIO &lt; end &gt; de 34 m...</td>\n",
       "      <td>presion intraocular</td>\n",
       "      <td>[CLS] presion intraocular [SEP] una exploración rutinaria , se descubrió una presión intraocular...</td>\n",
       "      <td>0.999333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>LDH</td>\n",
       "      <td>81 % neutrófilos ) , PCR = 15,93 mg/mL y &lt; start &gt; LDH &lt; end &gt; = 1,154 UI/L . Se realizaron los ...</td>\n",
       "      <td>lactatodeshidrogenasa</td>\n",
       "      <td>[CLS] lactatodeshidrogenasa [SEP] 81 % neutrófilos ) , PCR = 15,93 mg/mL y &lt; start &gt; LDH &lt; end &gt;...</td>\n",
       "      <td>0.995825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>RMN</td>\n",
       "      <td>Ascitis . Se amplía el estudio mediante TC y angio- &lt; start &gt; RMN &lt; end &gt; abdominales : cava int...</td>\n",
       "      <td>resonancia magnetica nuclear</td>\n",
       "      <td>[CLS] resonancia magnetica nuclear [SEP] Ascitis . Se amplía el estudio mediante TC y angio- &lt; s...</td>\n",
       "      <td>0.999469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>mmHg</td>\n",
       "      <td>se descubrió una presión intraocular ( PIO ) de 34 &lt; start &gt; mmHg &lt; end &gt; en el ojo derecho ( OD...</td>\n",
       "      <td>milimetro mercurio</td>\n",
       "      <td>[CLS] milimetro mercurio [SEP] se descubrió una presión intraocular ( PIO ) de 34 &lt; start &gt; mmHg...</td>\n",
       "      <td>0.999344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>dl</td>\n",
       "      <td>134 U/l , GPT 91 U/l , BT 1,2 mg/ &lt; start &gt; dl &lt; end &gt; BD 0,5 mg/dl ) que fue diagnosticado por ...</td>\n",
       "      <td>decilitro</td>\n",
       "      <td>[CLS] decilitro [SEP] 134 U/l , GPT 91 U/l , BT 1,2 mg/ &lt; start &gt; dl &lt; end &gt; BD 0,5 mg/dl ) que ...</td>\n",
       "      <td>0.999632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>g</td>\n",
       "      <td>progresivamente ( BQ : TG 3 mg/dl , proteínas 2,2 &lt; start &gt; g &lt; end &gt; dl ) , cediendo a los 5 dí...</td>\n",
       "      <td>gramo</td>\n",
       "      <td>[CLS] gramo [SEP] progresivamente ( BQ : TG 3 mg/dl , proteínas 2,2 &lt; start &gt; g &lt; end &gt; dl ) , c...</td>\n",
       "      <td>0.999556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>995 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     short_form  \\\n",
       "2            UI   \n",
       "3      anti-CCP   \n",
       "5           UCI   \n",
       "6             B   \n",
       "9           PIO   \n",
       "...         ...   \n",
       "1433        LDH   \n",
       "1435        RMN   \n",
       "1437       mmHg   \n",
       "1438         dl   \n",
       "1439          g   \n",
       "\n",
       "                                                                                                  context  \\\n",
       "2     GPT 96 UI/l , GGT 182 UI/l , FA 148 < start > UI < end > l ) . Valorada por Neurología , indican...   \n",
       "3     altos de factor reumatoide y anticuerpos antipéptido cíclico citrulinado ( < start > anti-CCP < ...   \n",
       "5     , 7/10 y 1/10 durante su estancia en Urgencias , < start > UCI < end > Sala de Hospitalización y...   \n",
       "6     El metoprolol pertenece a una clase de medicamentos llamados bloqueadores < start > B < end > Fu...   \n",
       "9     una exploración rutinaria , se descubrió una presión intraocular ( < start > PIO < end > de 34 m...   \n",
       "...                                                                                                   ...   \n",
       "1433  81 % neutrófilos ) , PCR = 15,93 mg/mL y < start > LDH < end > = 1,154 UI/L . Se realizaron los ...   \n",
       "1435  Ascitis . Se amplía el estudio mediante TC y angio- < start > RMN < end > abdominales : cava int...   \n",
       "1437  se descubrió una presión intraocular ( PIO ) de 34 < start > mmHg < end > en el ojo derecho ( OD...   \n",
       "1438  134 U/l , GPT 91 U/l , BT 1,2 mg/ < start > dl < end > BD 0,5 mg/dl ) que fue diagnosticado por ...   \n",
       "1439  progresivamente ( BQ : TG 3 mg/dl , proteínas 2,2 < start > g < end > dl ) , cediendo a los 5 dí...   \n",
       "\n",
       "                                        long_form  \\\n",
       "2                            unidad internacional   \n",
       "3     anticuerpos antipeptido ciclico citrulinado   \n",
       "5                      unidad cuidados intensivos   \n",
       "6                                            beta   \n",
       "9                             presion intraocular   \n",
       "...                                           ...   \n",
       "1433                        lactatodeshidrogenasa   \n",
       "1435                 resonancia magnetica nuclear   \n",
       "1437                           milimetro mercurio   \n",
       "1438                                    decilitro   \n",
       "1439                                        gramo   \n",
       "\n",
       "                                                                                                sentences  \\\n",
       "2     [CLS] unidad internacional [SEP] GPT 96 UI/l , GGT 182 UI/l , FA 148 < start > UI < end > l ) . ...   \n",
       "3     [CLS] anticuerpos antipeptido ciclico citrulinado [SEP] altos de factor reumatoide y anticuerpos...   \n",
       "5     [CLS] unidad cuidados intensivos [SEP] , 7/10 y 1/10 durante su estancia en Urgencias , < start ...   \n",
       "6     [CLS] beta [SEP] El metoprolol pertenece a una clase de medicamentos llamados bloqueadores < sta...   \n",
       "9     [CLS] presion intraocular [SEP] una exploración rutinaria , se descubrió una presión intraocular...   \n",
       "...                                                                                                   ...   \n",
       "1433  [CLS] lactatodeshidrogenasa [SEP] 81 % neutrófilos ) , PCR = 15,93 mg/mL y < start > LDH < end >...   \n",
       "1435  [CLS] resonancia magnetica nuclear [SEP] Ascitis . Se amplía el estudio mediante TC y angio- < s...   \n",
       "1437  [CLS] milimetro mercurio [SEP] se descubrió una presión intraocular ( PIO ) de 34 < start > mmHg...   \n",
       "1438  [CLS] decilitro [SEP] 134 U/l , GPT 91 U/l , BT 1,2 mg/ < start > dl < end > BD 0,5 mg/dl ) que ...   \n",
       "1439  [CLS] gramo [SEP] progresivamente ( BQ : TG 3 mg/dl , proteínas 2,2 < start > g < end > dl ) , c...   \n",
       "\n",
       "      Prediction  \n",
       "2       0.999654  \n",
       "3       0.999379  \n",
       "5       0.998991  \n",
       "6       0.998262  \n",
       "9       0.999333  \n",
       "...          ...  \n",
       "1433    0.995825  \n",
       "1435    0.999469  \n",
       "1437    0.999344  \n",
       "1438    0.999632  \n",
       "1439    0.999556  \n",
       "\n",
       "[995 rows x 5 columns]"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_output[val_output['Prediction'] >= 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_form</th>\n",
       "      <th>context</th>\n",
       "      <th>long_form</th>\n",
       "      <th>sentences</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>en este caso 15 litros de solución salina a 37º &lt; start &gt; C &lt; end &gt; para obtener un drenaje clar...</td>\n",
       "      <td>peak c</td>\n",
       "      <td>[CLS] peak c [SEP] en este caso 15 litros de solución salina a 37º &lt; start &gt; C &lt; end &gt; para obte...</td>\n",
       "      <td>0.003280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GGT</td>\n",
       "      <td>del perfil hepático de predominio colestásico ( fosfatasa alcalina y &lt; start &gt; GGT &lt; end &gt; más d...</td>\n",
       "      <td>gama glutamil transferasa</td>\n",
       "      <td>[CLS] gama glutamil transferasa [SEP] del perfil hepático de predominio colestásico ( fosfatasa ...</td>\n",
       "      <td>0.005237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>VSG</td>\n",
       "      <td>rutina demuestran una hemoglobina de 90mg/lt y una eritosedimentación ( &lt; start &gt; VSG &lt; end &gt; de...</td>\n",
       "      <td>velocidad eritrosedimentacion</td>\n",
       "      <td>[CLS] velocidad eritrosedimentacion [SEP] rutina demuestran una hemoglobina de 90mg/lt y una eri...</td>\n",
       "      <td>0.050198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>kg</td>\n",
       "      <td>kg de masa magra ( 88.4 % ) y 10,1 &lt; start &gt; kg &lt; end &gt; de masa grasa ( 11,6 % ) . El paciente</td>\n",
       "      <td>centimetro</td>\n",
       "      <td>[CLS] centimetro [SEP] kg de masa magra ( 88.4 % ) y 10,1 &lt; start &gt; kg &lt; end &gt; de masa grasa ( 1...</td>\n",
       "      <td>0.038794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>L</td>\n",
       "      <td>. En el análisis bioquímico destacaban una GGT 220 U/ &lt; start &gt; L &lt; end &gt; GPT 45 U/L , GOT 44 U/...</td>\n",
       "      <td>leucocito</td>\n",
       "      <td>[CLS] leucocito [SEP] . En el análisis bioquímico destacaban una GGT 220 U/ &lt; start &gt; L &lt; end &gt; ...</td>\n",
       "      <td>0.002517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>ALT</td>\n",
       "      <td>y GGT más de 10 veces el valor normal y &lt; start &gt; ALT &lt; end &gt; y AST menos de 3 veces el valor no...</td>\n",
       "      <td>alanine transferase</td>\n",
       "      <td>[CLS] alanine transferase [SEP] y GGT más de 10 veces el valor normal y &lt; start &gt; ALT &lt; end &gt; y ...</td>\n",
       "      <td>0.354852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>FA</td>\n",
       "      <td>: Fibrilación auricular - alta ; Fib-A - alta ; &lt; start &gt; FA &lt; end &gt; - alta ; FibA - altaJanuary...</td>\n",
       "      <td>fosfatasa alcalina</td>\n",
       "      <td>[CLS] fosfatasa alcalina [SEP] : Fibrilación auricular - alta ; Fib-A - alta ; &lt; start &gt; FA &lt; en...</td>\n",
       "      <td>0.062370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>C</td>\n",
       "      <td>factor V de Leiden , la resistencia a la proteína &lt; start &gt; C &lt; end &gt; activada , el anticoagulan...</td>\n",
       "      <td>cysteine</td>\n",
       "      <td>[CLS] cysteine [SEP] factor V de Leiden , la resistencia a la proteína &lt; start &gt; C &lt; end &gt; activ...</td>\n",
       "      <td>0.004386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>PCR</td>\n",
       "      <td>asintomática y siendo la hemoglobina , la VSG y la &lt; start &gt; PCR &lt; end &gt; normales . Consultó por...</td>\n",
       "      <td>polymerase chain reaction</td>\n",
       "      <td>[CLS] polymerase chain reaction [SEP] asintomática y siendo la hemoglobina , la VSG y la &lt; start...</td>\n",
       "      <td>0.002410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>h</td>\n",
       "      <td>Dr. José Gregorio Hernández '' ( CBMF-HGO ) ; 24 &lt; start &gt; h &lt; end &gt; después , dadas las condici...</td>\n",
       "      <td>microgramo</td>\n",
       "      <td>[CLS] microgramo [SEP] Dr. José Gregorio Hernández '' ( CBMF-HGO ) ; 24 &lt; start &gt; h &lt; end &gt; desp...</td>\n",
       "      <td>0.011205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>393 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     short_form  \\\n",
       "0             C   \n",
       "1           GGT   \n",
       "8           VSG   \n",
       "10           kg   \n",
       "13            L   \n",
       "...         ...   \n",
       "1432        ALT   \n",
       "1434         FA   \n",
       "1436          C   \n",
       "1440        PCR   \n",
       "1441          h   \n",
       "\n",
       "                                                                                                  context  \\\n",
       "0     en este caso 15 litros de solución salina a 37º < start > C < end > para obtener un drenaje clar...   \n",
       "1     del perfil hepático de predominio colestásico ( fosfatasa alcalina y < start > GGT < end > más d...   \n",
       "8     rutina demuestran una hemoglobina de 90mg/lt y una eritosedimentación ( < start > VSG < end > de...   \n",
       "10         kg de masa magra ( 88.4 % ) y 10,1 < start > kg < end > de masa grasa ( 11,6 % ) . El paciente   \n",
       "13    . En el análisis bioquímico destacaban una GGT 220 U/ < start > L < end > GPT 45 U/L , GOT 44 U/...   \n",
       "...                                                                                                   ...   \n",
       "1432  y GGT más de 10 veces el valor normal y < start > ALT < end > y AST menos de 3 veces el valor no...   \n",
       "1434  : Fibrilación auricular - alta ; Fib-A - alta ; < start > FA < end > - alta ; FibA - altaJanuary...   \n",
       "1436  factor V de Leiden , la resistencia a la proteína < start > C < end > activada , el anticoagulan...   \n",
       "1440  asintomática y siendo la hemoglobina , la VSG y la < start > PCR < end > normales . Consultó por...   \n",
       "1441  Dr. José Gregorio Hernández '' ( CBMF-HGO ) ; 24 < start > h < end > después , dadas las condici...   \n",
       "\n",
       "                          long_form  \\\n",
       "0                            peak c   \n",
       "1         gama glutamil transferasa   \n",
       "8     velocidad eritrosedimentacion   \n",
       "10                       centimetro   \n",
       "13                        leucocito   \n",
       "...                             ...   \n",
       "1432            alanine transferase   \n",
       "1434             fosfatasa alcalina   \n",
       "1436                       cysteine   \n",
       "1440      polymerase chain reaction   \n",
       "1441                     microgramo   \n",
       "\n",
       "                                                                                                sentences  \\\n",
       "0     [CLS] peak c [SEP] en este caso 15 litros de solución salina a 37º < start > C < end > para obte...   \n",
       "1     [CLS] gama glutamil transferasa [SEP] del perfil hepático de predominio colestásico ( fosfatasa ...   \n",
       "8     [CLS] velocidad eritrosedimentacion [SEP] rutina demuestran una hemoglobina de 90mg/lt y una eri...   \n",
       "10    [CLS] centimetro [SEP] kg de masa magra ( 88.4 % ) y 10,1 < start > kg < end > de masa grasa ( 1...   \n",
       "13    [CLS] leucocito [SEP] . En el análisis bioquímico destacaban una GGT 220 U/ < start > L < end > ...   \n",
       "...                                                                                                   ...   \n",
       "1432  [CLS] alanine transferase [SEP] y GGT más de 10 veces el valor normal y < start > ALT < end > y ...   \n",
       "1434  [CLS] fosfatasa alcalina [SEP] : Fibrilación auricular - alta ; Fib-A - alta ; < start > FA < en...   \n",
       "1436  [CLS] cysteine [SEP] factor V de Leiden , la resistencia a la proteína < start > C < end > activ...   \n",
       "1440  [CLS] polymerase chain reaction [SEP] asintomática y siendo la hemoglobina , la VSG y la < start...   \n",
       "1441  [CLS] microgramo [SEP] Dr. José Gregorio Hernández '' ( CBMF-HGO ) ; 24 < start > h < end > desp...   \n",
       "\n",
       "      Prediction  \n",
       "0       0.003280  \n",
       "1       0.005237  \n",
       "8       0.050198  \n",
       "10      0.038794  \n",
       "13      0.002517  \n",
       "...          ...  \n",
       "1432    0.354852  \n",
       "1434    0.062370  \n",
       "1436    0.004386  \n",
       "1440    0.002410  \n",
       "1441    0.011205  \n",
       "\n",
       "[393 rows x 5 columns]"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_output[val_output['Prediction'] < 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfm]",
   "language": "python",
   "name": "conda-env-tfm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
