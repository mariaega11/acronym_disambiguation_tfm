{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/egarcia/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import collections\n",
    "import unidecode\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import itertools \n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "from functools import reduce\n",
    "import ast\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_texts(path):\n",
    "    data = []\n",
    "    file_name = os.listdir(path)\n",
    "\n",
    "    for name in file_name:\n",
    "        if name.endswith('.txt'):\n",
    "            with open(path + name,encoding=\"utf8\") as f:\n",
    "                text = f.read()\n",
    "                data.append({'nombre':name.replace('.txt',''), 'texto':text})\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(string):\n",
    "    \"\"\"\n",
    "    A method to clean text \n",
    "    \"\"\"\n",
    "    \n",
    "    # Removing the punctuations\n",
    "    for x in string.lower(): \n",
    "        if x in punctuation:\n",
    "            if x != '/':\n",
    "                string = string.replace(x, \"\")\n",
    "            else:\n",
    "                string = string.replace(x, \" \")\n",
    "    \n",
    "    string = unidecode.unidecode(string)\n",
    "\n",
    "#     # Converting the text to lower\n",
    "#     string = string.lower()\n",
    "\n",
    "    # Removing stop words\n",
    "    string = ' '.join([word for word in string.split() if word not in swords])\n",
    "\n",
    "    # Cleaning the whitespaces\n",
    "    string = re.sub(r'\\s+', ' ', string).strip()\n",
    "\n",
    "    return string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/egarcia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "swords = list(set(stopwords.words('spanish')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep_num_text(data):\n",
    "\n",
    "    words = word_tokenize(data) \n",
    "    for w in words:\n",
    "        if re.search(r'\\d', w):\n",
    "            ind = words.index(w)\n",
    "            words[ind] = [''.join(g) for k, g in itertools.groupby(w, str.isalpha)]\n",
    "    data = ' '.join([x if type(x) is not list else ' '.join(x) for x in words])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f_b_context_text(data):\n",
    "    \n",
    "    '''Return context in a string format'''\n",
    "    \n",
    "    all_data = []\n",
    "    sf_not_found = []\n",
    "    \n",
    "    for instance in data:\n",
    "           \n",
    "        texto = instance['texto']    \n",
    "        #target_word = instance['short_form']\n",
    "        target_word = instance['Abbreviation']\n",
    "        \n",
    "        if target_word in texto:\n",
    "\n",
    "            stop_ini_idx = instance['StartOffset'] #índice del inicio de la target\n",
    "            stop_fin_idx = instance['EndOffset'] #índice del inicio de la target\n",
    "\n",
    "            _instance = []\n",
    "            xf = texto[:stop_ini_idx] + ' <start> ' +texto[stop_ini_idx:stop_fin_idx] + ' <end> ' #palabras anteriores a la target\n",
    "            #xf = texto[:stop_ini_idx] +texto[stop_ini_idx:stop_fin_idx]\n",
    "            xb = texto[stop_fin_idx+1:]   #palabras posteriores a la target            \n",
    "\n",
    "            instance_id = instance['Definition'] #id del significado\n",
    "            #instance_id = instance['long_form']\n",
    "\n",
    "            _instance.append(target_word)\n",
    "            _instance.append(xf)\n",
    "            _instance.append(xb)\n",
    "            _instance.append(instance_id)\n",
    "\n",
    "            all_data.append(_instance[:])\n",
    "        else:\n",
    "            sf_not_found.append(target_word)\n",
    "#             print(\"El acrónimo {} no aparece en el texto {}\".format(target_word, instance['doc_id']))\n",
    "        \n",
    "    return all_data, sf_not_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_context(data):\n",
    "\n",
    "    for doc in data:\n",
    "        \n",
    "        sf, xf, xb, lf = doc[0], doc[1], doc[2], doc[3]\n",
    "\n",
    "        xf_words = word_tokenize(xf)[-n_step_f-1:]\n",
    "        xb_words = word_tokenize(xb)[:n_step_b]\n",
    "\n",
    "        doc[1] = ' '.join(xf_words)\n",
    "        doc[2] = ' '.join(xb_words)   \n",
    "\n",
    "    return data        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict(data):\n",
    "    \n",
    "    data_dic = []\n",
    "    \n",
    "    for instance in data:\n",
    "            \n",
    "        dic = {}\n",
    "\n",
    "        dic['short_form'] = instance[0]\n",
    "        dic['context'] = instance[1] + ' ' + instance[2]\n",
    "        dic['long_form'] = instance[3]\n",
    "    \n",
    "        data_dic.append(dic)\n",
    "        \n",
    "    return data_dic\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_levenshtein(str1, str2):\n",
    "    d=dict()\n",
    "    for i in range(len(str1)+1):\n",
    "        d[i]=dict()\n",
    "        d[i][0]=i\n",
    "    for i in range(len(str2)+1):\n",
    "        d[0][i] = i\n",
    "    for i in range(1, len(str1)+1):\n",
    "        for j in range(1, len(str2)+1):\n",
    "            d[i][j] = min(d[i][j-1]+1, d[i-1][j]+1, d[i-1][j-1]+(not str1[i-1] == str2[j-1]))\n",
    "    return d[len(str1)][len(str2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_lf(row):\n",
    "    leven2 = []\n",
    "    for i in row:\n",
    "        for j in row:\n",
    "            if i != j:\n",
    "                long = max(len(i),len(j))\n",
    "                ratio = distance_levenshtein(i,j)/long\n",
    "                if ratio < 0.2:\n",
    "                    leven2.append(j)\n",
    "    if leven2:\n",
    "        leven2 = set(leven2)\n",
    "        lista = []\n",
    "        for i in leven2:\n",
    "            #val = frec[frec['index'] == i]['long_form'].iloc[0]\n",
    "            val = frec[frec['index'] == i]['Definition'].iloc[0]\n",
    "            lista.append((i, val))\n",
    "        lista = set(lista)\n",
    "        most_freq = sorted(set(lista), key=lambda x: x[1], reverse = True)[0][0]\n",
    "        sust = {}\n",
    "        for i in set(leven2):\n",
    "            sust[i] = most_freq\n",
    "        \n",
    "        return sust\n",
    "    else:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(row):\n",
    "    if row['long_form_x'] == row['long_form_y']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offsetA(row):\n",
    "    return row['texto'].find(row['Mention_A'])\n",
    "    \n",
    "def offsetB(row):\n",
    "    return row['texto'].find(row['Mention_B'])\n",
    "\n",
    "def offsetB_end(row):\n",
    "    return row['texto'].find(row['Mention_B']) + len(row['Mention_B'])\n",
    "\n",
    "def offsetA_end(row):\n",
    "    return row['Mention_A_StartOffset'] + len(row['Mention_A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offset(row):\n",
    "    return row['texto'].find(row['abrev'])\n",
    "\n",
    "def offsetend(row):\n",
    "    return row['StartOffset']+len(row['abrev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defin_dictionary(row,dictionary):\n",
    "    if row['Definition'] == 'no_existe':\n",
    "        return dictionary.get(row['Abbreviation'])\n",
    "    else:\n",
    "        return row['Definition']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Testing model output\n",
    "\n",
    "220 clinical cases.\n",
    "\n",
    "No haría falta procesarlo pues crearemos el fichero directamente d elas notas clínicas de test. Luego lo pasaremos por el transformer y la salida la procesaremos para que sea como el gold standard. Aplicaremos el evaluador de IberEval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out = pd.read_csv(\"../../data/julio23/test_data_beto_10_allacronim_normalizedlf_abremesprocessed_julio23_OUTPUT.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>short_form</th>\n",
       "      <th>context</th>\n",
       "      <th>long_form</th>\n",
       "      <th>sentences</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>mm</td>\n",
       "      <td>año se objetivó un pequeño angioma protuberancial izquierdo de 3 &lt; start &gt; mm &lt; end &gt; de diámetr...</td>\n",
       "      <td>milímetro</td>\n",
       "      <td>[CLS] milímetro [SEP] año se objetivó un pequeño angioma protuberancial izquierdo de 3 &lt; start &gt;...</td>\n",
       "      <td>0.999042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>TC</td>\n",
       "      <td>4/5 y una hemihipoestesia derecha con extinción sensitiva . La &lt; start &gt; TC &lt; end &gt; craneal real...</td>\n",
       "      <td>tomografaa computerizada</td>\n",
       "      <td>[CLS] tomografaa computerizada [SEP] 4/5 y una hemihipoestesia derecha con extinción sensitiva ....</td>\n",
       "      <td>0.998629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>TC</td>\n",
       "      <td>4/5 y una hemihipoestesia derecha con extinción sensitiva . La &lt; start &gt; TC &lt; end &gt; craneal real...</td>\n",
       "      <td>trayectorias clanicas</td>\n",
       "      <td>[CLS] trayectorias clanicas [SEP] 4/5 y una hemihipoestesia derecha con extinción sensitiva . La...</td>\n",
       "      <td>0.969132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>TC</td>\n",
       "      <td>4/5 y una hemihipoestesia derecha con extinción sensitiva . La &lt; start &gt; TC &lt; end &gt; craneal real...</td>\n",
       "      <td>trastornos cra3nicos</td>\n",
       "      <td>[CLS] trastornos cra3nicos [SEP] 4/5 y una hemihipoestesia derecha con extinción sensitiva . La ...</td>\n",
       "      <td>0.991494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>TC</td>\n",
       "      <td>4/5 y una hemihipoestesia derecha con extinción sensitiva . La &lt; start &gt; TC &lt; end &gt; craneal real...</td>\n",
       "      <td>taninos condensados</td>\n",
       "      <td>[CLS] taninos condensados [SEP] 4/5 y una hemihipoestesia derecha con extinción sensitiva . La &lt;...</td>\n",
       "      <td>0.994472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 short_form  \\\n",
       "0           0         mm   \n",
       "1           1         TC   \n",
       "2           2         TC   \n",
       "3           3         TC   \n",
       "4           4         TC   \n",
       "\n",
       "                                                                                               context  \\\n",
       "0  año se objetivó un pequeño angioma protuberancial izquierdo de 3 < start > mm < end > de diámetr...   \n",
       "1  4/5 y una hemihipoestesia derecha con extinción sensitiva . La < start > TC < end > craneal real...   \n",
       "2  4/5 y una hemihipoestesia derecha con extinción sensitiva . La < start > TC < end > craneal real...   \n",
       "3  4/5 y una hemihipoestesia derecha con extinción sensitiva . La < start > TC < end > craneal real...   \n",
       "4  4/5 y una hemihipoestesia derecha con extinción sensitiva . La < start > TC < end > craneal real...   \n",
       "\n",
       "                  long_form  \\\n",
       "0                 milímetro   \n",
       "1  tomografaa computerizada   \n",
       "2     trayectorias clanicas   \n",
       "3      trastornos cra3nicos   \n",
       "4       taninos condensados   \n",
       "\n",
       "                                                                                             sentences  \\\n",
       "0  [CLS] milímetro [SEP] año se objetivó un pequeño angioma protuberancial izquierdo de 3 < start >...   \n",
       "1  [CLS] tomografaa computerizada [SEP] 4/5 y una hemihipoestesia derecha con extinción sensitiva ....   \n",
       "2  [CLS] trayectorias clanicas [SEP] 4/5 y una hemihipoestesia derecha con extinción sensitiva . La...   \n",
       "3  [CLS] trastornos cra3nicos [SEP] 4/5 y una hemihipoestesia derecha con extinción sensitiva . La ...   \n",
       "4  [CLS] taninos condensados [SEP] 4/5 y una hemihipoestesia derecha con extinción sensitiva . La <...   \n",
       "\n",
       "   Prediction  \n",
       "0    0.999042  \n",
       "1    0.998629  \n",
       "2    0.969132  \n",
       "3    0.991494  \n",
       "4    0.994472  "
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99904233, 0.99862933, 0.969132  , ..., 0.9663539 , 0.79747665,\n",
       "       0.99821174])"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_out.Prediction.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0044755517"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_out.Prediction.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9009.000000\n",
       "mean        0.916268\n",
       "std         0.198598\n",
       "min         0.004476\n",
       "25%         0.963787\n",
       "50%         0.994676\n",
       "75%         0.998046\n",
       "max         0.999572\n",
       "Name: Prediction, dtype: float64"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_out.Prediction.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9009"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join doc_ids by dataframe index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ids = pd.read_csv('../../data/julio23/test_data_beto_10_allacronim_normalizedlf_abremesprocessed_julio23_IDS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9009"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = test_out.join(df_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.rename(columns = {'doc_id':'# Document_ID', 'short_form':'Abbreviation'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>context</th>\n",
       "      <th>long_form</th>\n",
       "      <th>sentences</th>\n",
       "      <th>Prediction</th>\n",
       "      <th># Document_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>mm</td>\n",
       "      <td>año se objetivó un pequeño angioma protuberancial izquierdo de 3 &lt; start &gt; mm &lt; end &gt; de diámetr...</td>\n",
       "      <td>milímetro</td>\n",
       "      <td>[CLS] milímetro [SEP] año se objetivó un pequeño angioma protuberancial izquierdo de 3 &lt; start &gt;...</td>\n",
       "      <td>0.999042</td>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>TC</td>\n",
       "      <td>4/5 y una hemihipoestesia derecha con extinción sensitiva . La &lt; start &gt; TC &lt; end &gt; craneal real...</td>\n",
       "      <td>tomografaa computerizada</td>\n",
       "      <td>[CLS] tomografaa computerizada [SEP] 4/5 y una hemihipoestesia derecha con extinción sensitiva ....</td>\n",
       "      <td>0.998629</td>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>TC</td>\n",
       "      <td>4/5 y una hemihipoestesia derecha con extinción sensitiva . La &lt; start &gt; TC &lt; end &gt; craneal real...</td>\n",
       "      <td>trayectorias clanicas</td>\n",
       "      <td>[CLS] trayectorias clanicas [SEP] 4/5 y una hemihipoestesia derecha con extinción sensitiva . La...</td>\n",
       "      <td>0.969132</td>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>TC</td>\n",
       "      <td>4/5 y una hemihipoestesia derecha con extinción sensitiva . La &lt; start &gt; TC &lt; end &gt; craneal real...</td>\n",
       "      <td>trastornos cra3nicos</td>\n",
       "      <td>[CLS] trastornos cra3nicos [SEP] 4/5 y una hemihipoestesia derecha con extinción sensitiva . La ...</td>\n",
       "      <td>0.991494</td>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>TC</td>\n",
       "      <td>4/5 y una hemihipoestesia derecha con extinción sensitiva . La &lt; start &gt; TC &lt; end &gt; craneal real...</td>\n",
       "      <td>taninos condensados</td>\n",
       "      <td>[CLS] taninos condensados [SEP] 4/5 y una hemihipoestesia derecha con extinción sensitiva . La &lt;...</td>\n",
       "      <td>0.994472</td>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Abbreviation  \\\n",
       "0           0           mm   \n",
       "1           1           TC   \n",
       "2           2           TC   \n",
       "3           3           TC   \n",
       "4           4           TC   \n",
       "\n",
       "                                                                                               context  \\\n",
       "0  año se objetivó un pequeño angioma protuberancial izquierdo de 3 < start > mm < end > de diámetr...   \n",
       "1  4/5 y una hemihipoestesia derecha con extinción sensitiva . La < start > TC < end > craneal real...   \n",
       "2  4/5 y una hemihipoestesia derecha con extinción sensitiva . La < start > TC < end > craneal real...   \n",
       "3  4/5 y una hemihipoestesia derecha con extinción sensitiva . La < start > TC < end > craneal real...   \n",
       "4  4/5 y una hemihipoestesia derecha con extinción sensitiva . La < start > TC < end > craneal real...   \n",
       "\n",
       "                  long_form  \\\n",
       "0                 milímetro   \n",
       "1  tomografaa computerizada   \n",
       "2     trayectorias clanicas   \n",
       "3      trastornos cra3nicos   \n",
       "4       taninos condensados   \n",
       "\n",
       "                                                                                             sentences  \\\n",
       "0  [CLS] milímetro [SEP] año se objetivó un pequeño angioma protuberancial izquierdo de 3 < start >...   \n",
       "1  [CLS] tomografaa computerizada [SEP] 4/5 y una hemihipoestesia derecha con extinción sensitiva ....   \n",
       "2  [CLS] trayectorias clanicas [SEP] 4/5 y una hemihipoestesia derecha con extinción sensitiva . La...   \n",
       "3  [CLS] trastornos cra3nicos [SEP] 4/5 y una hemihipoestesia derecha con extinción sensitiva . La ...   \n",
       "4  [CLS] taninos condensados [SEP] 4/5 y una hemihipoestesia derecha con extinción sensitiva . La <...   \n",
       "\n",
       "   Prediction              # Document_ID  \n",
       "0    0.999042  S1130-14732005000200003-1  \n",
       "1    0.998629  S1130-14732005000200003-1  \n",
       "2    0.969132  S1130-14732005000200003-1  \n",
       "3    0.991494  S1130-14732005000200003-1  \n",
       "4    0.994472  S1130-14732005000200003-1  "
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9009, 7)"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Soto original df to add the SF offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_soto = pd.read_csv(\"../../data/marzo2023/subtrack2/test_subtrack2_marzo23soto_parte1.csv\", sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_soto = test_soto[['# Document_ID', 'StartOffset', 'EndOffset', 'Abbreviation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_soto = test_soto.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Document_ID</th>\n",
       "      <th>StartOffset</th>\n",
       "      <th>EndOffset</th>\n",
       "      <th>Abbreviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9156</th>\n",
       "      <td>S1889-836X2015000200005-2</td>\n",
       "      <td>433</td>\n",
       "      <td>436</td>\n",
       "      <td>IMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9239</th>\n",
       "      <td>S1889-836X2015000200005-2</td>\n",
       "      <td>1913</td>\n",
       "      <td>1916</td>\n",
       "      <td>MTT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9153</th>\n",
       "      <td>S1889-836X2015000200005-2</td>\n",
       "      <td>141</td>\n",
       "      <td>142</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9207</th>\n",
       "      <td>S1889-836X2015000200005-2</td>\n",
       "      <td>812</td>\n",
       "      <td>814</td>\n",
       "      <td>Rx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9208</th>\n",
       "      <td>S1889-836X2015000200005-2</td>\n",
       "      <td>878</td>\n",
       "      <td>881</td>\n",
       "      <td>RMN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9216</th>\n",
       "      <td>S1889-836X2015000200005-2</td>\n",
       "      <td>943</td>\n",
       "      <td>946</td>\n",
       "      <td>MTT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9221</th>\n",
       "      <td>S1889-836X2015000200005-2</td>\n",
       "      <td>1061</td>\n",
       "      <td>1064</td>\n",
       "      <td>PTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9229</th>\n",
       "      <td>S1889-836X2015000200005-2</td>\n",
       "      <td>1076</td>\n",
       "      <td>1077</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9232</th>\n",
       "      <td>S1889-836X2015000200005-2</td>\n",
       "      <td>1297</td>\n",
       "      <td>1298</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9238</th>\n",
       "      <td>S1889-836X2015000200005-2</td>\n",
       "      <td>1867</td>\n",
       "      <td>1869</td>\n",
       "      <td>Rx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  # Document_ID  StartOffset  EndOffset Abbreviation\n",
       "9156  S1889-836X2015000200005-2          433        436          IMC\n",
       "9239  S1889-836X2015000200005-2         1913       1916          MTT\n",
       "9153  S1889-836X2015000200005-2          141        142            D\n",
       "9207  S1889-836X2015000200005-2          812        814           Rx\n",
       "9208  S1889-836X2015000200005-2          878        881          RMN\n",
       "9216  S1889-836X2015000200005-2          943        946          MTT\n",
       "9221  S1889-836X2015000200005-2         1061       1064          PTH\n",
       "9229  S1889-836X2015000200005-2         1076       1077            D\n",
       "9232  S1889-836X2015000200005-2         1297       1298            D\n",
       "9238  S1889-836X2015000200005-2         1867       1869           Rx"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_soto.sort_values(by = ['# Document_ID','Abbreviation'],ascending = False).head()\n",
    "test_soto.sort_values(by = '# Document_ID', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1561, 4)"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_soto.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_soto[(test_soto['# Document_ID'] == 'S1130-14732005000200003-1') & (test_soto['Abbreviation'] == 'mm')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test[(df_test['# Document_ID'] == 'S1130-14732005000200003-1') & (df_test['Abbreviation'] == 'mm')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test2 = df_test.merge(test_soto, on = ['# Document_ID','Abbreviation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>context</th>\n",
       "      <th>long_form</th>\n",
       "      <th>sentences</th>\n",
       "      <th>Prediction</th>\n",
       "      <th># Document_ID</th>\n",
       "      <th>StartOffset</th>\n",
       "      <th>EndOffset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4207</th>\n",
       "      <td>2146</td>\n",
       "      <td>MTT</td>\n",
       "      <td>una Rx que mostró callo de fractura antiguo en 2o &lt; start &gt; MTT &lt; end &gt; por fractura de estrés p...</td>\n",
       "      <td>modelo transtea3rico</td>\n",
       "      <td>[CLS] modelo transtea3rico [SEP] una Rx que mostró callo de fractura antiguo en 2o &lt; start &gt; MTT...</td>\n",
       "      <td>0.982404</td>\n",
       "      <td>S1889-836X2015000200005-2</td>\n",
       "      <td>1913</td>\n",
       "      <td>1916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4204</th>\n",
       "      <td>2142</td>\n",
       "      <td>MTT</td>\n",
       "      <td>, que reveló una fractura de estrés en el 2o &lt; start &gt; MTT &lt; end &gt; con callo perióstico y edema ...</td>\n",
       "      <td>metil tiazol tetrazolium</td>\n",
       "      <td>[CLS] metil tiazol tetrazolium [SEP] , que reveló una fractura de estrés en el 2o &lt; start &gt; MTT ...</td>\n",
       "      <td>0.997818</td>\n",
       "      <td>S1889-836X2015000200005-2</td>\n",
       "      <td>1913</td>\n",
       "      <td>1916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4220</th>\n",
       "      <td>2145</td>\n",
       "      <td>PTH</td>\n",
       "      <td>. Se realizó estudio analítico destacando incremento de niveles de &lt; start &gt; PTH &lt; end &gt; y vitam...</td>\n",
       "      <td>parathyroid hormone</td>\n",
       "      <td>[CLS] parathyroid hormone [SEP] . Se realizó estudio analítico destacando incremento de niveles ...</td>\n",
       "      <td>0.931628</td>\n",
       "      <td>S1889-836X2015000200005-2</td>\n",
       "      <td>1061</td>\n",
       "      <td>1064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4219</th>\n",
       "      <td>2144</td>\n",
       "      <td>PTH</td>\n",
       "      <td>. Se realizó estudio analítico destacando incremento de niveles de &lt; start &gt; PTH &lt; end &gt; y vitam...</td>\n",
       "      <td>parathormona intacta</td>\n",
       "      <td>[CLS] parathormona intacta [SEP] . Se realizó estudio analítico destacando incremento de niveles...</td>\n",
       "      <td>0.984401</td>\n",
       "      <td>S1889-836X2015000200005-2</td>\n",
       "      <td>1061</td>\n",
       "      <td>1064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4217</th>\n",
       "      <td>2151</td>\n",
       "      <td>MTT</td>\n",
       "      <td>para completar estudio que mostró edema de 1er y 3er &lt; start &gt; MTT &lt; end &gt; de huesos cuneiforme ...</td>\n",
       "      <td>metil tiazol tetrazolium</td>\n",
       "      <td>[CLS] metil tiazol tetrazolium [SEP] para completar estudio que mostró edema de 1er y 3er &lt; star...</td>\n",
       "      <td>0.982785</td>\n",
       "      <td>S1889-836X2015000200005-2</td>\n",
       "      <td>2054</td>\n",
       "      <td>2057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 Abbreviation  \\\n",
       "4207        2146          MTT   \n",
       "4204        2142          MTT   \n",
       "4220        2145          PTH   \n",
       "4219        2144          PTH   \n",
       "4217        2151          MTT   \n",
       "\n",
       "                                                                                                  context  \\\n",
       "4207  una Rx que mostró callo de fractura antiguo en 2o < start > MTT < end > por fractura de estrés p...   \n",
       "4204  , que reveló una fractura de estrés en el 2o < start > MTT < end > con callo perióstico y edema ...   \n",
       "4220  . Se realizó estudio analítico destacando incremento de niveles de < start > PTH < end > y vitam...   \n",
       "4219  . Se realizó estudio analítico destacando incremento de niveles de < start > PTH < end > y vitam...   \n",
       "4217  para completar estudio que mostró edema de 1er y 3er < start > MTT < end > de huesos cuneiforme ...   \n",
       "\n",
       "                     long_form  \\\n",
       "4207      modelo transtea3rico   \n",
       "4204  metil tiazol tetrazolium   \n",
       "4220       parathyroid hormone   \n",
       "4219      parathormona intacta   \n",
       "4217  metil tiazol tetrazolium   \n",
       "\n",
       "                                                                                                sentences  \\\n",
       "4207  [CLS] modelo transtea3rico [SEP] una Rx que mostró callo de fractura antiguo en 2o < start > MTT...   \n",
       "4204  [CLS] metil tiazol tetrazolium [SEP] , que reveló una fractura de estrés en el 2o < start > MTT ...   \n",
       "4220  [CLS] parathyroid hormone [SEP] . Se realizó estudio analítico destacando incremento de niveles ...   \n",
       "4219  [CLS] parathormona intacta [SEP] . Se realizó estudio analítico destacando incremento de niveles...   \n",
       "4217  [CLS] metil tiazol tetrazolium [SEP] para completar estudio que mostró edema de 1er y 3er < star...   \n",
       "\n",
       "      Prediction              # Document_ID  StartOffset  EndOffset  \n",
       "4207    0.982404  S1889-836X2015000200005-2         1913       1916  \n",
       "4204    0.997818  S1889-836X2015000200005-2         1913       1916  \n",
       "4220    0.931628  S1889-836X2015000200005-2         1061       1064  \n",
       "4219    0.984401  S1889-836X2015000200005-2         1061       1064  \n",
       "4217    0.982785  S1889-836X2015000200005-2         2054       2057  "
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test2.sort_values(by = '# Document_ID', ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19227"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select just the predictions higher than 0.75 as the correct LF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test2 = df_test2[df_test2.Prediction >= 0.75] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17428"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99904233, 0.9988949 , 0.9990246 , ..., 0.9663539 , 0.79747665,\n",
       "       0.99821174])"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test2.Prediction.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test2 = df_test2[['# Document_ID', 'StartOffset', 'EndOffset','Abbreviation','long_form']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test2 = df_test2.rename(columns = {'long_form':'Definition'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get lemmatized long forms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do that after the output from Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test2['Definition_lemmatized'] = df_test2['Definition'].map(lambda x: lemmatizer.lemmatize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Document_ID</th>\n",
       "      <th>StartOffset</th>\n",
       "      <th>EndOffset</th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>Definition</th>\n",
       "      <th>Definition_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>300</td>\n",
       "      <td>302</td>\n",
       "      <td>mm</td>\n",
       "      <td>milímetro</td>\n",
       "      <td>milímetro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>741</td>\n",
       "      <td>743</td>\n",
       "      <td>mm</td>\n",
       "      <td>milímetro</td>\n",
       "      <td>milímetro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>1980</td>\n",
       "      <td>1982</td>\n",
       "      <td>mm</td>\n",
       "      <td>milímetro</td>\n",
       "      <td>milímetro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>300</td>\n",
       "      <td>302</td>\n",
       "      <td>mm</td>\n",
       "      <td>milímetro</td>\n",
       "      <td>milímetro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>741</td>\n",
       "      <td>743</td>\n",
       "      <td>mm</td>\n",
       "      <td>milímetro</td>\n",
       "      <td>milímetro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               # Document_ID  StartOffset  EndOffset Abbreviation Definition  \\\n",
       "0  S1130-14732005000200003-1          300        302           mm  milímetro   \n",
       "1  S1130-14732005000200003-1          741        743           mm  milímetro   \n",
       "2  S1130-14732005000200003-1         1980       1982           mm  milímetro   \n",
       "3  S1130-14732005000200003-1          300        302           mm  milímetro   \n",
       "4  S1130-14732005000200003-1          741        743           mm  milímetro   \n",
       "\n",
       "  Definition_lemmatized  \n",
       "0             milímetro  \n",
       "1             milímetro  \n",
       "2             milímetro  \n",
       "3             milímetro  \n",
       "4             milímetro  "
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17428, 6)"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test2 = df_test2.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8626, 6)"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test2.to_csv(\"../../data/julio23/test_data_beto_10_NOamb_normalizedlf_medline_julio23_output_processed.tsv\", sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare gold standard and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold = pd.read_csv(\"../../data/marzo2023/subtrack2/clinical_cases.abbreviations.testing_set.tsv\", sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Document_ID</th>\n",
       "      <th>StartOffset</th>\n",
       "      <th>EndOffset</th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>Definition</th>\n",
       "      <th>Definition_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>533</td>\n",
       "      <td>537</td>\n",
       "      <td>/mm3</td>\n",
       "      <td>milímetro cúbico</td>\n",
       "      <td>milímetro cúbico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>1857</td>\n",
       "      <td>1858</td>\n",
       "      <td>µ</td>\n",
       "      <td>micro</td>\n",
       "      <td>micro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0211-69952013000200018-1</td>\n",
       "      <td>2512</td>\n",
       "      <td>2514</td>\n",
       "      <td>µg</td>\n",
       "      <td>microgramo</td>\n",
       "      <td>microgramo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0212-16112004000400007-1</td>\n",
       "      <td>4558</td>\n",
       "      <td>4560</td>\n",
       "      <td>µg</td>\n",
       "      <td>microgramo</td>\n",
       "      <td>microgramo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S1137-66272014000300016-1</td>\n",
       "      <td>1112</td>\n",
       "      <td>1114</td>\n",
       "      <td>µg</td>\n",
       "      <td>microgramo</td>\n",
       "      <td>microgramo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               # Document_ID  StartOffset  EndOffset Abbreviation  \\\n",
       "0  S0212-71992005000500009-1          533        537         /mm3   \n",
       "1  S1130-14732005000200003-1         1857       1858            µ   \n",
       "2  S0211-69952013000200018-1         2512       2514           µg   \n",
       "3  S0212-16112004000400007-1         4558       4560           µg   \n",
       "4  S1137-66272014000300016-1         1112       1114           µg   \n",
       "\n",
       "         Definition Definition_lemmatized  \n",
       "0  milímetro cúbico      milímetro cúbico  \n",
       "1             micro                 micro  \n",
       "2        microgramo            microgramo  \n",
       "3        microgramo            microgramo  \n",
       "4        microgramo            microgramo  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Document_ID</th>\n",
       "      <th>StartOffset</th>\n",
       "      <th>EndOffset</th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>Definition</th>\n",
       "      <th>Definition_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>300</td>\n",
       "      <td>302</td>\n",
       "      <td>mm</td>\n",
       "      <td>aminoacidos más abundantes</td>\n",
       "      <td>aminoacidos más abundantes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>741</td>\n",
       "      <td>743</td>\n",
       "      <td>mm</td>\n",
       "      <td>aminoacidos más abundantes</td>\n",
       "      <td>aminoacidos más abundantes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>1980</td>\n",
       "      <td>1982</td>\n",
       "      <td>mm</td>\n",
       "      <td>aminoacidos más abundantes</td>\n",
       "      <td>aminoacidos más abundantes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>649</td>\n",
       "      <td>651</td>\n",
       "      <td>TC</td>\n",
       "      <td>tomografía computerizada</td>\n",
       "      <td>tomografía computerizada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>S1130-14732005000200003-1</td>\n",
       "      <td>649</td>\n",
       "      <td>651</td>\n",
       "      <td>TC</td>\n",
       "      <td>trayectorias clínicas</td>\n",
       "      <td>trayectorias clínicas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                # Document_ID  StartOffset  EndOffset Abbreviation  \\\n",
       "0   S1130-14732005000200003-1          300        302           mm   \n",
       "1   S1130-14732005000200003-1          741        743           mm   \n",
       "2   S1130-14732005000200003-1         1980       1982           mm   \n",
       "9   S1130-14732005000200003-1          649        651           TC   \n",
       "10  S1130-14732005000200003-1          649        651           TC   \n",
       "\n",
       "                    Definition       Definition_lemmatized  \n",
       "0   aminoacidos más abundantes  aminoacidos más abundantes  \n",
       "1   aminoacidos más abundantes  aminoacidos más abundantes  \n",
       "2   aminoacidos más abundantes  aminoacidos más abundantes  \n",
       "9     tomografía computerizada    tomografía computerizada  \n",
       "10       trayectorias clínicas       trayectorias clínicas  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Document_ID</th>\n",
       "      <th>StartOffset</th>\n",
       "      <th>EndOffset</th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>Definition</th>\n",
       "      <th>Definition_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>533</td>\n",
       "      <td>537</td>\n",
       "      <td>/mm3</td>\n",
       "      <td>milímetro cúbico</td>\n",
       "      <td>milímetro cúbico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>598</td>\n",
       "      <td>600</td>\n",
       "      <td>gr</td>\n",
       "      <td>gramo</td>\n",
       "      <td>gramo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>601</td>\n",
       "      <td>602</td>\n",
       "      <td>L</td>\n",
       "      <td>litro</td>\n",
       "      <td>litro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>638</td>\n",
       "      <td>641</td>\n",
       "      <td>LDH</td>\n",
       "      <td>lactato-deshidrogenasa</td>\n",
       "      <td>lactato-deshidrogenasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3200</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>646</td>\n",
       "      <td>647</td>\n",
       "      <td>U</td>\n",
       "      <td>unidad</td>\n",
       "      <td>unidad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>648</td>\n",
       "      <td>649</td>\n",
       "      <td>L</td>\n",
       "      <td>litro</td>\n",
       "      <td>litro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2443</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>698</td>\n",
       "      <td>702</td>\n",
       "      <td>mmol</td>\n",
       "      <td>milimol</td>\n",
       "      <td>milimol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>703</td>\n",
       "      <td>704</td>\n",
       "      <td>L</td>\n",
       "      <td>litro</td>\n",
       "      <td>litro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>706</td>\n",
       "      <td>709</td>\n",
       "      <td>ADA</td>\n",
       "      <td>adenosín de aminasa</td>\n",
       "      <td>adenosín de aminasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>713</td>\n",
       "      <td>714</td>\n",
       "      <td>U</td>\n",
       "      <td>unidad</td>\n",
       "      <td>unidad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>715</td>\n",
       "      <td>716</td>\n",
       "      <td>L</td>\n",
       "      <td>litro</td>\n",
       "      <td>litro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>734</td>\n",
       "      <td>738</td>\n",
       "      <td>mmol</td>\n",
       "      <td>milimol</td>\n",
       "      <td>milimol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>739</td>\n",
       "      <td>740</td>\n",
       "      <td>L</td>\n",
       "      <td>litro</td>\n",
       "      <td>litro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>762</td>\n",
       "      <td>766</td>\n",
       "      <td>mmol</td>\n",
       "      <td>milimol</td>\n",
       "      <td>milimol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>767</td>\n",
       "      <td>768</td>\n",
       "      <td>L</td>\n",
       "      <td>litro</td>\n",
       "      <td>litro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3119</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>1050</td>\n",
       "      <td>1052</td>\n",
       "      <td>TC</td>\n",
       "      <td>tomografía computarizada</td>\n",
       "      <td>tomografía computarizado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3118</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>1233</td>\n",
       "      <td>1235</td>\n",
       "      <td>TC</td>\n",
       "      <td>tomografía computarizada</td>\n",
       "      <td>tomografía computarizado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2708</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>1549</td>\n",
       "      <td>1552</td>\n",
       "      <td>PCR</td>\n",
       "      <td>polimerase chain reaction</td>\n",
       "      <td>polimerase chain reaction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2042</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>1684</td>\n",
       "      <td>1686</td>\n",
       "      <td>mg</td>\n",
       "      <td>miligramo</td>\n",
       "      <td>miligramo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>1708</td>\n",
       "      <td>1710</td>\n",
       "      <td>mg</td>\n",
       "      <td>miligramo</td>\n",
       "      <td>miligramo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>1735</td>\n",
       "      <td>1737</td>\n",
       "      <td>mg</td>\n",
       "      <td>miligramo</td>\n",
       "      <td>miligramo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  # Document_ID  StartOffset  EndOffset Abbreviation  \\\n",
       "0     S0212-71992005000500009-1          533        537         /mm3   \n",
       "1146  S0212-71992005000500009-1          598        600           gr   \n",
       "1611  S0212-71992005000500009-1          601        602            L   \n",
       "1686  S0212-71992005000500009-1          638        641          LDH   \n",
       "3200  S0212-71992005000500009-1          646        647            U   \n",
       "1610  S0212-71992005000500009-1          648        649            L   \n",
       "2443  S0212-71992005000500009-1          698        702         mmol   \n",
       "1608  S0212-71992005000500009-1          703        704            L   \n",
       "48    S0212-71992005000500009-1          706        709          ADA   \n",
       "3199  S0212-71992005000500009-1          713        714            U   \n",
       "1607  S0212-71992005000500009-1          715        716            L   \n",
       "2442  S0212-71992005000500009-1          734        738         mmol   \n",
       "1606  S0212-71992005000500009-1          739        740            L   \n",
       "2441  S0212-71992005000500009-1          762        766         mmol   \n",
       "1609  S0212-71992005000500009-1          767        768            L   \n",
       "3119  S0212-71992005000500009-1         1050       1052           TC   \n",
       "3118  S0212-71992005000500009-1         1233       1235           TC   \n",
       "2708  S0212-71992005000500009-1         1549       1552          PCR   \n",
       "2042  S0212-71992005000500009-1         1684       1686           mg   \n",
       "2044  S0212-71992005000500009-1         1708       1710           mg   \n",
       "2043  S0212-71992005000500009-1         1735       1737           mg   \n",
       "\n",
       "                     Definition      Definition_lemmatized  \n",
       "0              milímetro cúbico           milímetro cúbico  \n",
       "1146                      gramo                      gramo  \n",
       "1611                      litro                      litro  \n",
       "1686     lactato-deshidrogenasa     lactato-deshidrogenasa  \n",
       "3200                     unidad                     unidad  \n",
       "1610                      litro                      litro  \n",
       "2443                    milimol                    milimol  \n",
       "1608                      litro                      litro  \n",
       "48          adenosín de aminasa        adenosín de aminasa  \n",
       "3199                     unidad                     unidad  \n",
       "1607                      litro                      litro  \n",
       "2442                    milimol                    milimol  \n",
       "1606                      litro                      litro  \n",
       "2441                    milimol                    milimol  \n",
       "1609                      litro                      litro  \n",
       "3119   tomografía computarizada   tomografía computarizado  \n",
       "3118   tomografía computarizada   tomografía computarizado  \n",
       "2708  polimerase chain reaction  polimerase chain reaction  \n",
       "2042                  miligramo                  miligramo  \n",
       "2044                  miligramo                  miligramo  \n",
       "2043                  miligramo                  miligramo  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold[gold['# Document_ID'] == 'S0212-71992005000500009-1'].sort_values(by = 'StartOffset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Document_ID</th>\n",
       "      <th>StartOffset</th>\n",
       "      <th>EndOffset</th>\n",
       "      <th>Abbreviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39746</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>452</td>\n",
       "      <td>453</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39733</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>638</td>\n",
       "      <td>641</td>\n",
       "      <td>LDH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39745</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>646</td>\n",
       "      <td>647</td>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39812</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>706</td>\n",
       "      <td>709</td>\n",
       "      <td>ADA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39833</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>1050</td>\n",
       "      <td>1052</td>\n",
       "      <td>TC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39949</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>1233</td>\n",
       "      <td>1235</td>\n",
       "      <td>TC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40065</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>1549</td>\n",
       "      <td>1552</td>\n",
       "      <td>PCR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   # Document_ID  StartOffset  EndOffset Abbreviation\n",
       "39746  S0212-71992005000500009-1          452        453            L\n",
       "39733  S0212-71992005000500009-1          638        641          LDH\n",
       "39745  S0212-71992005000500009-1          646        647            U\n",
       "39812  S0212-71992005000500009-1          706        709          ADA\n",
       "39833  S0212-71992005000500009-1         1050       1052           TC\n",
       "39949  S0212-71992005000500009-1         1233       1235           TC\n",
       "40065  S0212-71992005000500009-1         1549       1552          PCR"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_soto[test_soto['# Document_ID'] == 'S0212-71992005000500009-1'].sort_values(by = 'StartOffset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Document_ID</th>\n",
       "      <th>StartOffset</th>\n",
       "      <th>EndOffset</th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>Definition</th>\n",
       "      <th>Definition_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41542</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>638</td>\n",
       "      <td>641</td>\n",
       "      <td>LDH</td>\n",
       "      <td>Lactato Deshidrogenasa</td>\n",
       "      <td>Lactato Deshidrogenasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41543</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>638</td>\n",
       "      <td>641</td>\n",
       "      <td>LDH</td>\n",
       "      <td>LA DESHIDROGENASA L'ACTICA</td>\n",
       "      <td>LA DESHIDROGENASA L'ACTICA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   # Document_ID  StartOffset  EndOffset Abbreviation  \\\n",
       "41542  S0212-71992005000500009-1          638        641          LDH   \n",
       "41543  S0212-71992005000500009-1          638        641          LDH   \n",
       "\n",
       "                       Definition       Definition_lemmatized  \n",
       "41542      Lactato Deshidrogenasa      Lactato Deshidrogenasa  \n",
       "41543  LA DESHIDROGENASA L'ACTICA  LA DESHIDROGENASA L'ACTICA  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test2[(df_test2['# Document_ID'] == 'S0212-71992005000500009-1') & (df_test2.Abbreviation == 'LDH')].sort_values(by = 'StartOffset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Document_ID</th>\n",
       "      <th>StartOffset</th>\n",
       "      <th>EndOffset</th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>Definition</th>\n",
       "      <th>Definition_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41885</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>1549</td>\n",
       "      <td>1552</td>\n",
       "      <td>PCR</td>\n",
       "      <td>especificidad del 100 por ciento</td>\n",
       "      <td>especificidad del 100 por ciento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41886</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>1549</td>\n",
       "      <td>1552</td>\n",
       "      <td>PCR</td>\n",
       "      <td>Amplicor®-MT Roche Diagnostic</td>\n",
       "      <td>Amplicor®-MT Roche Diagnostic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41888</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>1549</td>\n",
       "      <td>1552</td>\n",
       "      <td>PCR</td>\n",
       "      <td>primeramente un diagnóstico molecular</td>\n",
       "      <td>primeramente un diagnóstico molecular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41889</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>1549</td>\n",
       "      <td>1552</td>\n",
       "      <td>PCR</td>\n",
       "      <td>programa de cirugía robótica</td>\n",
       "      <td>programa de cirugía robótica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41890</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>1549</td>\n",
       "      <td>1552</td>\n",
       "      <td>PCR</td>\n",
       "      <td>Parotiditis crónica recidivante en niños</td>\n",
       "      <td>Parotiditis crónica recidivante en niños</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41891</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>1549</td>\n",
       "      <td>1552</td>\n",
       "      <td>PCR</td>\n",
       "      <td>hepatitis C y DNA viral</td>\n",
       "      <td>hepatitis C y DNA viral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41892</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>1549</td>\n",
       "      <td>1552</td>\n",
       "      <td>PCR</td>\n",
       "      <td>Programa de Comunicación de Riesgos</td>\n",
       "      <td>Programa de Comunicación de Riesgos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41893</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>1549</td>\n",
       "      <td>1552</td>\n",
       "      <td>PCR</td>\n",
       "      <td>PROTEÍNA C REACTIVA</td>\n",
       "      <td>PROTEÍNA C REACTIVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41896</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>1549</td>\n",
       "      <td>1552</td>\n",
       "      <td>PCR</td>\n",
       "      <td>macroangiopatía y citocinas proinflamatorias</td>\n",
       "      <td>macroangiopatía y citocinas proinflamatorias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41897</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>1549</td>\n",
       "      <td>1552</td>\n",
       "      <td>PCR</td>\n",
       "      <td>punto de corte 1mg/dl</td>\n",
       "      <td>punto de corte 1mg/dl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41898</th>\n",
       "      <td>S0212-71992005000500009-1</td>\n",
       "      <td>1549</td>\n",
       "      <td>1552</td>\n",
       "      <td>PCR</td>\n",
       "      <td>por ciento vs 10 por ciento</td>\n",
       "      <td>por ciento vs 10 por ciento</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   # Document_ID  StartOffset  EndOffset Abbreviation  \\\n",
       "41885  S0212-71992005000500009-1         1549       1552          PCR   \n",
       "41886  S0212-71992005000500009-1         1549       1552          PCR   \n",
       "41888  S0212-71992005000500009-1         1549       1552          PCR   \n",
       "41889  S0212-71992005000500009-1         1549       1552          PCR   \n",
       "41890  S0212-71992005000500009-1         1549       1552          PCR   \n",
       "41891  S0212-71992005000500009-1         1549       1552          PCR   \n",
       "41892  S0212-71992005000500009-1         1549       1552          PCR   \n",
       "41893  S0212-71992005000500009-1         1549       1552          PCR   \n",
       "41896  S0212-71992005000500009-1         1549       1552          PCR   \n",
       "41897  S0212-71992005000500009-1         1549       1552          PCR   \n",
       "41898  S0212-71992005000500009-1         1549       1552          PCR   \n",
       "\n",
       "                                         Definition  \\\n",
       "41885              especificidad del 100 por ciento   \n",
       "41886                 Amplicor®-MT Roche Diagnostic   \n",
       "41888         primeramente un diagnóstico molecular   \n",
       "41889                  programa de cirugía robótica   \n",
       "41890      Parotiditis crónica recidivante en niños   \n",
       "41891                       hepatitis C y DNA viral   \n",
       "41892           Programa de Comunicación de Riesgos   \n",
       "41893                           PROTEÍNA C REACTIVA   \n",
       "41896  macroangiopatía y citocinas proinflamatorias   \n",
       "41897                         punto de corte 1mg/dl   \n",
       "41898                   por ciento vs 10 por ciento   \n",
       "\n",
       "                              Definition_lemmatized  \n",
       "41885              especificidad del 100 por ciento  \n",
       "41886                 Amplicor®-MT Roche Diagnostic  \n",
       "41888         primeramente un diagnóstico molecular  \n",
       "41889                  programa de cirugía robótica  \n",
       "41890      Parotiditis crónica recidivante en niños  \n",
       "41891                       hepatitis C y DNA viral  \n",
       "41892           Programa de Comunicación de Riesgos  \n",
       "41893                           PROTEÍNA C REACTIVA  \n",
       "41896  macroangiopatía y citocinas proinflamatorias  \n",
       "41897                         punto de corte 1mg/dl  \n",
       "41898                   por ciento vs 10 por ciento  "
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test2[(df_test2['# Document_ID'] == 'S0212-71992005000500009-1') & (df_test2.Abbreviation == 'PCR')].sort_values(by = 'StartOffset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cm     144\n",
       "TAC     85\n",
       "mg      63\n",
       "TC      58\n",
       "mm      42\n",
       "      ... \n",
       "TGO      1\n",
       "ETE      1\n",
       "MEN      1\n",
       "ENA      1\n",
       "ERG      1\n",
       "Name: Abbreviation, Length: 319, dtype: int64"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_soto.Abbreviation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfm]",
   "language": "python",
   "name": "conda-env-tfm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
