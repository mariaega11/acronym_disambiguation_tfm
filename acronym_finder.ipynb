{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import collections\n",
    "#from gensim.parsing.preprocessing import remove_stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import itertools \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag.stanford import StanfordPOSTagger\n",
    "from string import punctuation\n",
    "from textblob import TextBlob\n",
    "\n",
    "from nltk import ngrams\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#java path for standford tagger\n",
    "java_path = \"C:\\Program Files (x86)\\Java\\jre1.8.0_201\"\n",
    "os.environ['JAVAHOME'] = java_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Standford Spanish POS tagger\n",
    "_model_filename = r'C:/Users/cx02274/Documents/master/stanford-postagger/models/spanish-ud.tagger'\n",
    "_path_to_jar = r'C:/Users/cx02274/Documents/master/stanford-postagger/stanford-postagger-4.1.0.jar'\n",
    "st = StanfordPOSTagger(model_filename=_model_filename, path_to_jar=_path_to_jar,encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_texts(path):\n",
    "    data = []\n",
    "    file_name = os.listdir(path)\n",
    "\n",
    "    for name in file_name:\n",
    "        if name.endswith('.txt'):\n",
    "            with open(path + name,encoding=\"utf8\") as f:\n",
    "                text = f.read()\n",
    "                data.append({'nombre':name.replace('.txt',''), 'texto':text})\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainning\n",
    "\n",
    "318 clinical cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_abbr = pd.read_csv(\"../datasets/trainning_set/clinical_cases.abbreviations.training_set.tsv\", sep = '\\t')\n",
    "train_met = pd.read_csv(\"../datasets/trainning_set/clinical_cases.metadata.training_set.tsv\", sep = '\\t')\n",
    "train_rel = pd.read_csv(\"../datasets/trainning_set/clinical_cases.relations.training_set.tsv\", sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_met = train_met.rename(columns = {'# Document_ID': 'doc_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>Case_ID</th>\n",
       "      <th>ISSN</th>\n",
       "      <th>Date</th>\n",
       "      <th>Source</th>\n",
       "      <th>Full_Text_Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1139-76322015000500009-1.txt</td>\n",
       "      <td>1.txt</td>\n",
       "      <td>1139-7632</td>\n",
       "      <td>2015-12-01</td>\n",
       "      <td>Pediatría Atención Primaria  v.17 n.68 2015</td>\n",
       "      <td>http://scielo.isciii.es/scielo.php?script=sci_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1130-05582008000400007-2.txt</td>\n",
       "      <td>2.txt</td>\n",
       "      <td>1130-0558</td>\n",
       "      <td>2008-08-01</td>\n",
       "      <td>Revista Española de Cirugía Oral y Maxilofacia...</td>\n",
       "      <td>http://scielo.isciii.es/scielo.php?script=sci_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0210-48062006000100012-1.txt</td>\n",
       "      <td>1.txt</td>\n",
       "      <td>0210-4806</td>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>Actas Urológicas Españolas  v.30 n.1 2006</td>\n",
       "      <td>http://scielo.isciii.es/scielo.php?script=sci_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0213-12852003000500002-1.txt</td>\n",
       "      <td>1.txt</td>\n",
       "      <td>0213-1285</td>\n",
       "      <td>2003-10-01</td>\n",
       "      <td>Avances en Odontoestomatología  v.19 n.5 2003</td>\n",
       "      <td>http://scielo.isciii.es/scielo.php?script=sci_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0212-71992005000400007-1.txt</td>\n",
       "      <td>1.txt</td>\n",
       "      <td>0212-7199</td>\n",
       "      <td>2005-04-01</td>\n",
       "      <td>Anales de Medicina Interna  v.22 n.4 2005</td>\n",
       "      <td>http://scielo.isciii.es/scielo.php?script=sci_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          doc_id Case_ID       ISSN        Date  \\\n",
       "0  S1139-76322015000500009-1.txt   1.txt  1139-7632  2015-12-01   \n",
       "1  S1130-05582008000400007-2.txt   2.txt  1130-0558  2008-08-01   \n",
       "2  S0210-48062006000100012-1.txt   1.txt  0210-4806  2006-01-01   \n",
       "3  S0213-12852003000500002-1.txt   1.txt  0213-1285  2003-10-01   \n",
       "4  S0212-71992005000400007-1.txt   1.txt  0212-7199  2005-04-01   \n",
       "\n",
       "                                              Source  \\\n",
       "0        Pediatría Atención Primaria  v.17 n.68 2015   \n",
       "1  Revista Española de Cirugía Oral y Maxilofacia...   \n",
       "2          Actas Urológicas Españolas  v.30 n.1 2006   \n",
       "3      Avances en Odontoestomatología  v.19 n.5 2003   \n",
       "4          Anales de Medicina Interna  v.22 n.4 2005   \n",
       "\n",
       "                                      Full_Text_Link  \n",
       "0  http://scielo.isciii.es/scielo.php?script=sci_...  \n",
       "1  http://scielo.isciii.es/scielo.php?script=sci_...  \n",
       "2  http://scielo.isciii.es/scielo.php?script=sci_...  \n",
       "3  http://scielo.isciii.es/scielo.php?script=sci_...  \n",
       "4  http://scielo.isciii.es/scielo.php?script=sci_...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_met.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rel = train_rel.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rel.columns = ['# Document_ID', 'Mention_A_type', 'Mention_A_StartOffset',\n",
    "      'Mention_A', 'Relation_type', 'Mention_B_type',\n",
    "       'Mention_B_StartOffset', 'Mention_B_EndOffset', 'Mention_B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rel = train_rel.rename(columns = {'# Document_ID': 'doc_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>Mention_A_type</th>\n",
       "      <th>Mention_A_StartOffset</th>\n",
       "      <th>Mention_A</th>\n",
       "      <th>Relation_type</th>\n",
       "      <th>Mention_B_type</th>\n",
       "      <th>Mention_B_StartOffset</th>\n",
       "      <th>Mention_B_EndOffset</th>\n",
       "      <th>Mention_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1130-01082009000400014-1</td>\n",
       "      <td>SHORT_FORM</td>\n",
       "      <td>476</td>\n",
       "      <td>NPT</td>\n",
       "      <td>SHORT-LONG</td>\n",
       "      <td>LONG_FORM</td>\n",
       "      <td>454.0</td>\n",
       "      <td>474.0</td>\n",
       "      <td>nutrición parenteral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1130-63432016000100009-1</td>\n",
       "      <td>SHORT_FORM</td>\n",
       "      <td>614</td>\n",
       "      <td>NIHSS</td>\n",
       "      <td>SHORT-LONG</td>\n",
       "      <td>LONG_FORM</td>\n",
       "      <td>621.0</td>\n",
       "      <td>662.0</td>\n",
       "      <td>National Institute of Health Stroke Scale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S1139-76322017000200007-1</td>\n",
       "      <td>SHORT_FORM</td>\n",
       "      <td>1145</td>\n",
       "      <td>CMV</td>\n",
       "      <td>SHORT-LONG</td>\n",
       "      <td>LONG_FORM</td>\n",
       "      <td>1128.0</td>\n",
       "      <td>1143.0</td>\n",
       "      <td>citomegalovirus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S1139-76322017000200007-1</td>\n",
       "      <td>SHORT_FORM</td>\n",
       "      <td>1243</td>\n",
       "      <td>VSG</td>\n",
       "      <td>SHORT-LONG</td>\n",
       "      <td>LONG_FORM</td>\n",
       "      <td>1206.0</td>\n",
       "      <td>1241.0</td>\n",
       "      <td>velocidad de sedimentación globular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S1139-76322017000200007-1</td>\n",
       "      <td>SHORT_FORM</td>\n",
       "      <td>1300</td>\n",
       "      <td>IGRA</td>\n",
       "      <td>SHORT-LONG</td>\n",
       "      <td>LONG_FORM</td>\n",
       "      <td>1267.0</td>\n",
       "      <td>1298.0</td>\n",
       "      <td>interferon-gamma release assays</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      doc_id Mention_A_type Mention_A_StartOffset Mention_A  \\\n",
       "0  S1130-01082009000400014-1     SHORT_FORM                   476       NPT   \n",
       "1  S1130-63432016000100009-1     SHORT_FORM                   614     NIHSS   \n",
       "2  S1139-76322017000200007-1     SHORT_FORM                  1145       CMV   \n",
       "3  S1139-76322017000200007-1     SHORT_FORM                  1243       VSG   \n",
       "4  S1139-76322017000200007-1     SHORT_FORM                  1300      IGRA   \n",
       "\n",
       "  Relation_type Mention_B_type  Mention_B_StartOffset  Mention_B_EndOffset  \\\n",
       "0    SHORT-LONG      LONG_FORM                  454.0                474.0   \n",
       "1    SHORT-LONG      LONG_FORM                  621.0                662.0   \n",
       "2    SHORT-LONG      LONG_FORM                 1128.0               1143.0   \n",
       "3    SHORT-LONG      LONG_FORM                 1206.0               1241.0   \n",
       "4    SHORT-LONG      LONG_FORM                 1267.0               1298.0   \n",
       "\n",
       "                                   Mention_B  \n",
       "0                       nutrición parenteral  \n",
       "1  National Institute of Health Stroke Scale  \n",
       "2                            citomegalovirus  \n",
       "3        velocidad de sedimentación globular  \n",
       "4            interferon-gamma release assays  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_abbr = train_abbr.rename(columns = {'# Document_ID': 'doc_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = read_texts(\"../datasets/trainning_set/training_set.raw_text/txt/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = train_raw.rename(columns = {'nombre': 'doc_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0004-06142005000900013-1</td>\n",
       "      <td>Se trata de una mujer de 29 años sometida a un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0004-06142005000900015-1</td>\n",
       "      <td>Varón de 36 años, sin antecedentes de interés,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0004-06142005000900016-1</td>\n",
       "      <td>Mujer de 29 años con antecedentes de ulcus duo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0004-06142005001000011-1</td>\n",
       "      <td>Varón de 58 años de edad en el momento del tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0004-06142005001000011-3</td>\n",
       "      <td>Mujer de 42 años en el momento de someterse a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      doc_id  \\\n",
       "0  S0004-06142005000900013-1   \n",
       "1  S0004-06142005000900015-1   \n",
       "2  S0004-06142005000900016-1   \n",
       "3  S0004-06142005001000011-1   \n",
       "4  S0004-06142005001000011-3   \n",
       "\n",
       "                                               texto  \n",
       "0  Se trata de una mujer de 29 años sometida a un...  \n",
       "1  Varón de 36 años, sin antecedentes de interés,...  \n",
       "2  Mujer de 29 años con antecedentes de ulcus duo...  \n",
       "3  Varón de 58 años de edad en el momento del tra...  \n",
       "4  Mujer de 42 años en el momento de someterse a ...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sub-track 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Found abbreviations (Short Forms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize text\n",
    "train_raw['tokens'] = train_raw['texto'].map(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove stop words\n",
    "#nltk.download('stopwords')\n",
    "swords = list(set(stopwords.words('spanish')))\n",
    "train_raw['texto_clean'] = train_raw['tokens'].map(lambda x: ' '.join([w for w in x if w not in swords]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove white spaces\n",
    "train_raw['texto_clean'] = train_raw['texto_clean'].map(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split text in sentences\n",
    "train_raw['texto_sentences'] = train_raw['texto_clean'].map(lambda x: re.split(r\"\\.|\\?|\\!\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#POS tagging\n",
    "train_raw['texto_POS'] = train_raw['texto_clean'].map(lambda x: st.tag(nltk.word_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>texto</th>\n",
       "      <th>tokens</th>\n",
       "      <th>texto_clean</th>\n",
       "      <th>texto_sentences</th>\n",
       "      <th>texto_POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0004-06142005000900013-1</td>\n",
       "      <td>Se trata de una mujer de 29 años sometida a un...</td>\n",
       "      <td>[Se, trata, de, una, mujer, de, 29, años, some...</td>\n",
       "      <td>Se trata mujer 29 años sometida estudio ecográ...</td>\n",
       "      <td>[Se trata mujer 29 años sometida estudio ecogr...</td>\n",
       "      <td>[(Se, PRON), (trata, VERB), (mujer, NOUN), (29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0004-06142005000900015-1</td>\n",
       "      <td>Varón de 36 años, sin antecedentes de interés,...</td>\n",
       "      <td>[Varón, de, 36, años, ,, sin, antecedentes, de...</td>\n",
       "      <td>Varón 36 años , antecedentes interés , estudia...</td>\n",
       "      <td>[Varón 36 años , antecedentes interés , estudi...</td>\n",
       "      <td>[(Varón, PROPN), (36, NUM), (años, NOUN), (,, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0004-06142005000900016-1</td>\n",
       "      <td>Mujer de 29 años con antecedentes de ulcus duo...</td>\n",
       "      <td>[Mujer, de, 29, años, con, antecedentes, de, u...</td>\n",
       "      <td>Mujer 29 años antecedentes ulcus duodenal estr...</td>\n",
       "      <td>[Mujer 29 años antecedentes ulcus duodenal est...</td>\n",
       "      <td>[(Mujer, NOUN), (29, NUM), (años, NOUN), (ante...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0004-06142005001000011-1</td>\n",
       "      <td>Varón de 58 años de edad en el momento del tra...</td>\n",
       "      <td>[Varón, de, 58, años, de, edad, en, el, moment...</td>\n",
       "      <td>Varón 58 años edad momento trasplante , 5 octu...</td>\n",
       "      <td>[Varón 58 años edad momento trasplante , 5 oct...</td>\n",
       "      <td>[(Varón, PROPN), (58, NUM), (años, NOUN), (eda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0004-06142005001000011-3</td>\n",
       "      <td>Mujer de 42 años en el momento de someterse a ...</td>\n",
       "      <td>[Mujer, de, 42, años, en, el, momento, de, som...</td>\n",
       "      <td>Mujer 42 años momento someterse trasplante hep...</td>\n",
       "      <td>[Mujer 42 años momento someterse trasplante he...</td>\n",
       "      <td>[(Mujer, NOUN), (42, NUM), (años, NOUN), (mome...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      doc_id  \\\n",
       "0  S0004-06142005000900013-1   \n",
       "1  S0004-06142005000900015-1   \n",
       "2  S0004-06142005000900016-1   \n",
       "3  S0004-06142005001000011-1   \n",
       "4  S0004-06142005001000011-3   \n",
       "\n",
       "                                               texto  \\\n",
       "0  Se trata de una mujer de 29 años sometida a un...   \n",
       "1  Varón de 36 años, sin antecedentes de interés,...   \n",
       "2  Mujer de 29 años con antecedentes de ulcus duo...   \n",
       "3  Varón de 58 años de edad en el momento del tra...   \n",
       "4  Mujer de 42 años en el momento de someterse a ...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Se, trata, de, una, mujer, de, 29, años, some...   \n",
       "1  [Varón, de, 36, años, ,, sin, antecedentes, de...   \n",
       "2  [Mujer, de, 29, años, con, antecedentes, de, u...   \n",
       "3  [Varón, de, 58, años, de, edad, en, el, moment...   \n",
       "4  [Mujer, de, 42, años, en, el, momento, de, som...   \n",
       "\n",
       "                                         texto_clean  \\\n",
       "0  Se trata mujer 29 años sometida estudio ecográ...   \n",
       "1  Varón 36 años , antecedentes interés , estudia...   \n",
       "2  Mujer 29 años antecedentes ulcus duodenal estr...   \n",
       "3  Varón 58 años edad momento trasplante , 5 octu...   \n",
       "4  Mujer 42 años momento someterse trasplante hep...   \n",
       "\n",
       "                                     texto_sentences  \\\n",
       "0  [Se trata mujer 29 años sometida estudio ecogr...   \n",
       "1  [Varón 36 años , antecedentes interés , estudi...   \n",
       "2  [Mujer 29 años antecedentes ulcus duodenal est...   \n",
       "3  [Varón 58 años edad momento trasplante , 5 oct...   \n",
       "4  [Mujer 42 años momento someterse trasplante he...   \n",
       "\n",
       "                                           texto_POS  \n",
       "0  [(Se, PRON), (trata, VERB), (mujer, NOUN), (29...  \n",
       "1  [(Varón, PROPN), (36, NUM), (años, NOUN), (,, ...  \n",
       "2  [(Mujer, NOUN), (29, NUM), (años, NOUN), (ante...  \n",
       "3  [(Varón, PROPN), (58, NUM), (años, NOUN), (eda...  \n",
       "4  [(Mujer, NOUN), (42, NUM), (años, NOUN), (mome...  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Se trata mujer 66 años diabética antecedentes hepatitis virus C etiología postransfusional . En Enero 2006 presentaba síndrome miccional pertinaz respondía tratamiento realizó cistoscopia posterior RTU . Fue diagnosticada carcinoma vesical pTa G3 tras inició tratamiento BCG intravesical . La RTU control tras finalizar tratamiento BCG detectó presencia múltiples focos carcinoma vejiga confirmándose diagnóstico carcinoma urotelial invadía capa muscular ( pT2 G3 ) . En Julio 2006 sometida cistectomía radical derivación urinaria mediante ureterosigmoidostomía tipo Mainz II . La anatomía patológica demostró carcinoma urotelial alto grado invasión capa muscular afectación ganglios linfáticos resecados , trataba pT2a N1 . No detectaron metástasis distancia . Dos semanas después intervención , acudió desorientación tendencia sueño contexto cuadro compatible infección vías urinarias . Tras 24 horas observación , hidratación intravenosa antibioterapia recuperó pudo ser dada alta antibiótico oral . Diez días después acudió nuevo hospital aparición dispraxia , tendencia sueño , lenguaje incoherente obnubilación . Durante episodio presenta además pico febril 38,5ºC . La bioquímica hemograma normales ( leucocitosis neutrofilia ) . Se realizó ecografía abdominal identificó hidronefrosis bilateral moderada TAC cerebral normal . Durante ingreso , tras inicio tratamiento antibiótico amplio espectro fluidoterapia , cuadro confusional solucionándose recuperación completa . A pocos días , paciente volvió presentar deterioro cognitivo . En ocasión inicio síntomas centrales sido similar , dispraxia , dificultad repentina realizar tareas cotidianas , somnolencia obnubilación , embargo ocasión acudió hospital situación coma , Glasgow 8 . Estaba afebril . En analítica destacaba únicamente moderada hiperglucemia ligera elevación transaminasas . Se realizó electroencefalograma observaban unas ondas lentas áreas ambos hemisferios , hallazgos característicos encefalopatía metabólica . Un TAC cerebral mostró anomalías estructurales . De forma similar ingreso previo , tras varios días hospitalizada fluidoterapia soporte dieta absoluta , paciente experimenta progresiva mejoría recuperación completa clínica . Tres semanas después , paciente vuelve notar síntomas dispraxia tendencia sueño instauración progresiva . Acude urgencias evaluada encontrarse alteraciones exploración pruebas analíticas imagen remite domicilio , existía fiebre ninguna clínica sugestiva infección . A 24 horas acude alteración severa nivel conciencia Glasgow 6 . En ocasión paciente acudía tras haber iniciado 15 días , primer ciclo quimioterapia adyuvante esquema taxol 175 mg/m2 carboplatino AUC 5 . Por ello , presentaba leucopenia neutropenia atribuible mielotoxicidad postquimioterapia . Todos demás parámetros electrolíticos , incluyendo calcemia , rigurosamente normales . La gasometría venosa demostraba pH 7.44 . El TAC cerebral radiografía tórax normales . Ante presencia episodios repetidos síndrome confusional probable causa metabólica , 3 meses cistectomía , consideró podría ser complicación metabólica derivación . Tras haberse descartado tratara acidosis metabólica decidió solicitar niveles amonio sangre , demostraron amonemia 400 microgramos/dl ( normal 17-80 ) . Ante diagnóstico encefalopatía hiperamonémica causa no-hepática inició fluidoterapia , dieta absoluta , enemas lactulosa gravedad clínica inició hemodiálisis . Tras 3 sesiones hemodiálisis paciente experimentó recuperación neurológica paralela corrección niveles amonio disminuyeron normalizarse . Posteriormente realizó reconversión quirúrgica ureterosigmoidostomía conducto ileal . Actualmente paciente continúa tratamiento quimioterápico adyuvante vuelto presentar nuevos episodios confusionales .'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prueba = train_raw.iloc[50]['texto_clean']\n",
    "prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Se', 'PRON'), ('trata', 'VERB'), ('mujer', 'NOUN'), ('66', 'NUM'), ('años', 'NOUN'), ('diabética', 'VERB'), ('antecedentes', 'NOUN'), ('hepatitis', 'NOUN'), ('virus', 'NOUN'), ('C', 'PROPN'), ('etiología', 'VERB'), ('postransfusional', 'ADJ'), ('.', 'PUNCT'), ('En', 'ADP'), ('Enero', 'PROPN'), ('2006', 'NUM'), ('presentaba', 'VERB'), ('síndrome', 'NOUN'), ('miccional', 'ADJ'), ('pertinaz', 'ADJ'), ('respondía', 'VERB'), ('tratamiento', 'NOUN'), ('realizó', 'VERB'), ('cistoscopia', 'NOUN'), ('posterior', 'ADJ'), ('RTU', 'PROPN'), ('.', 'PUNCT'), ('Fue', 'AUX'), ('diagnosticada', 'VERB'), ('carcinoma', 'NOUN'), ('vesical', 'ADJ'), ('pTa', 'PROPN'), ('G3', 'PROPN'), ('tras', 'ADP'), ('inició', 'VERB'), ('tratamiento', 'NOUN'), ('BCG', 'PROPN'), ('intravesical', 'ADJ'), ('.', 'PUNCT'), ('La', 'DET'), ('RTU', 'PROPN'), ('control', 'NOUN'), ('tras', 'ADP'), ('finalizar', 'VERB'), ('tratamiento', 'NOUN'), ('BCG', 'PROPN'), ('detectó', 'VERB'), ('presencia', 'NOUN'), ('múltiples', 'ADJ'), ('focos', 'NOUN'), ('carcinoma', 'ADJ'), ('vejiga', 'ADJ'), ('confirmándose', 'VERB'), ('diagnóstico', 'NOUN'), ('carcinoma', 'NOUN'), ('urotelial', 'ADJ'), ('invadía', 'VERB'), ('capa', 'NOUN'), ('muscular', 'ADJ'), ('(', 'PUNCT'), ('pT2', 'PROPN'), ('G3', 'PROPN'), (')', 'PUNCT'), ('.', 'PUNCT'), ('En', 'ADP'), ('Julio', 'PROPN'), ('2006', 'NUM'), ('sometida', 'ADJ'), ('cistectomía', 'NOUN'), ('radical', 'ADJ'), ('derivación', 'ADJ'), ('urinaria', 'ADJ'), ('mediante', 'ADP'), ('ureterosigmoidostomía', 'DET'), ('tipo', 'NOUN'), ('Mainz', 'PROPN'), ('II', 'PROPN'), ('.', 'PUNCT'), ('La', 'DET'), ('anatomía', 'NOUN'), ('patológica', 'ADJ'), ('demostró', 'VERB'), ('carcinoma', 'NOUN'), ('urotelial', 'ADJ'), ('alto', 'ADJ'), ('grado', 'NOUN'), ('invasión', 'NOUN'), ('capa', 'NOUN'), ('muscular', 'ADJ'), ('afectación', 'NOUN'), ('ganglios', 'ADJ'), ('linfáticos', 'ADJ'), ('resecados', 'ADJ'), (',', 'PUNCT'), ('trataba', 'VERB'), ('pT2a', 'PROPN'), ('N1', 'PROPN'), ('.', 'PUNCT'), ('No', 'ADV'), ('detectaron', 'VERB'), ('metástasis', 'NOUN'), ('distancia', 'NOUN'), ('.', 'PUNCT'), ('Dos', 'NUM'), ('semanas', 'NOUN'), ('después', 'ADV'), ('intervención', 'NOUN'), (',', 'PUNCT'), ('acudió', 'VERB'), ('desorientación', 'NOUN'), ('tendencia', 'NOUN'), ('sueño', 'NOUN'), ('contexto', 'NOUN'), ('cuadro', 'VERB'), ('compatible', 'ADJ'), ('infección', 'NOUN'), ('vías', 'NOUN'), ('urinarias', 'ADJ'), ('.', 'PUNCT'), ('Tras', 'ADP'), ('24', 'NUM'), ('horas', 'NOUN'), ('observación', 'NOUN'), (',', 'PUNCT'), ('hidratación', 'NOUN'), ('intravenosa', 'ADJ'), ('antibioterapia', 'ADJ'), ('recuperó', 'VERB'), ('pudo', 'AUX'), ('ser', 'AUX'), ('dada', 'VERB'), ('alta', 'ADJ'), ('antibiótico', 'ADJ'), ('oral', 'ADJ'), ('.', 'PUNCT'), ('Diez', 'NUM'), ('días', 'NOUN'), ('después', 'ADV'), ('acudió', 'VERB'), ('nuevo', 'ADJ'), ('hospital', 'NOUN'), ('aparición', 'NOUN'), ('dispraxia', 'ADJ'), (',', 'PUNCT'), ('tendencia', 'NOUN'), ('sueño', 'NOUN'), (',', 'PUNCT'), ('lenguaje', 'NOUN'), ('incoherente', 'ADJ'), ('obnubilación', 'NOUN'), ('.', 'PUNCT'), ('Durante', 'ADP'), ('episodio', 'NOUN'), ('presenta', 'VERB'), ('además', 'ADV'), ('pico', 'NOUN'), ('febril', 'ADJ'), ('38,5ºC', 'PROPN'), ('.', 'PUNCT'), ('La', 'DET'), ('bioquímica', 'NOUN'), ('hemograma', 'NOUN'), ('normales', 'ADJ'), ('(', 'PUNCT'), ('leucocitosis', 'NOUN'), ('neutrofilia', 'ADJ'), (')', 'PUNCT'), ('.', 'PUNCT'), ('Se', 'PRON'), ('realizó', 'VERB'), ('ecografía', 'NOUN'), ('abdominal', 'ADJ'), ('identificó', 'VERB'), ('hidronefrosis', 'NOUN'), ('bilateral', 'ADJ'), ('moderada', 'ADJ'), ('TAC', 'PROPN'), ('cerebral', 'ADJ'), ('normal', 'ADJ'), ('.', 'PUNCT'), ('Durante', 'ADP'), ('ingreso', 'NOUN'), (',', 'PUNCT'), ('tras', 'ADP'), ('inicio', 'NOUN'), ('tratamiento', 'NOUN'), ('antibiótico', 'ADJ'), ('amplio', 'ADJ'), ('espectro', 'NOUN'), ('fluidoterapia', 'ADJ'), (',', 'PUNCT'), ('cuadro', 'NOUN'), ('confusional', 'ADJ'), ('solucionándose', 'ADJ'), ('recuperación', 'NOUN'), ('completa', 'ADJ'), ('.', 'PUNCT'), ('A', 'ADP'), ('pocos', 'DET'), ('días', 'NOUN'), (',', 'PUNCT'), ('paciente', 'ADJ'), ('volvió', 'AUX'), ('presentar', 'VERB'), ('deterioro', 'NOUN'), ('cognitivo', 'ADJ'), ('.', 'PUNCT'), ('En', 'ADP'), ('ocasión', 'NOUN'), ('inicio', 'NOUN'), ('síntomas', 'NOUN'), ('centrales', 'ADJ'), ('sido', 'AUX'), ('similar', 'ADJ'), (',', 'PUNCT'), ('dispraxia', 'NOUN'), (',', 'PUNCT'), ('dificultad', 'NOUN'), ('repentina', 'ADJ'), ('realizar', 'VERB'), ('tareas', 'NOUN'), ('cotidianas', 'ADJ'), (',', 'PUNCT'), ('somnolencia', 'NOUN'), ('obnubilación', 'NOUN'), (',', 'PUNCT'), ('embargo', 'NOUN'), ('ocasión', 'NOUN'), ('acudió', 'VERB'), ('hospital', 'NOUN'), ('situación', 'NOUN'), ('coma', 'NOUN'), (',', 'PUNCT'), ('Glasgow', 'PROPN'), ('8', 'NUM'), ('.', 'PUNCT'), ('Estaba', 'AUX'), ('afebril', 'ADJ'), ('.', 'PUNCT'), ('En', 'ADP'), ('analítica', 'ADJ'), ('destacaba', 'VERB'), ('únicamente', 'ADV'), ('moderada', 'ADJ'), ('hiperglucemia', 'NOUN'), ('ligera', 'ADJ'), ('elevación', 'NOUN'), ('transaminasas', 'ADJ'), ('.', 'PUNCT'), ('Se', 'PRON'), ('realizó', 'VERB'), ('electroencefalograma', 'NOUN'), ('observaban', 'VERB'), ('unas', 'DET'), ('ondas', 'NOUN'), ('lentas', 'ADJ'), ('áreas', 'NOUN'), ('ambos', 'NUM'), ('hemisferios', 'NOUN'), (',', 'PUNCT'), ('hallazgos', 'NOUN'), ('característicos', 'ADJ'), ('encefalopatía', 'NOUN'), ('metabólica', 'ADJ'), ('.', 'PUNCT'), ('Un', 'DET'), ('TAC', 'PROPN'), ('cerebral', 'ADJ'), ('mostró', 'VERB'), ('anomalías', 'NOUN'), ('estructurales', 'ADJ'), ('.', 'PUNCT'), ('De', 'ADP'), ('forma', 'NOUN'), ('similar', 'ADJ'), ('ingreso', 'NOUN'), ('previo', 'ADJ'), (',', 'PUNCT'), ('tras', 'ADP'), ('varios', 'DET'), ('días', 'NOUN'), ('hospitalizada', 'ADJ'), ('fluidoterapia', 'ADJ'), ('soporte', 'ADJ'), ('dieta', 'NOUN'), ('absoluta', 'ADJ'), (',', 'PUNCT'), ('paciente', 'ADJ'), ('experimenta', 'VERB'), ('progresiva', 'ADJ'), ('mejoría', 'NOUN'), ('recuperación', 'NOUN'), ('completa', 'ADJ'), ('clínica', 'ADJ'), ('.', 'PUNCT'), ('Tres', 'NUM'), ('semanas', 'NOUN'), ('después', 'ADV'), (',', 'PUNCT'), ('paciente', 'ADJ'), ('vuelve', 'NOUN'), ('notar', 'VERB'), ('síntomas', 'NOUN'), ('dispraxia', 'ADJ'), ('tendencia', 'NOUN'), ('sueño', 'NOUN'), ('instauración', 'NOUN'), ('progresiva', 'ADJ'), ('.', 'PUNCT'), ('Acude', 'VERB'), ('urgencias', 'NOUN'), ('evaluada', 'VERB'), ('encontrarse', 'NOUN'), ('alteraciones', 'NOUN'), ('exploración', 'NOUN'), ('pruebas', 'NOUN'), ('analíticas', 'ADJ'), ('imagen', 'NOUN'), ('remite', 'VERB'), ('domicilio', 'NOUN'), (',', 'PUNCT'), ('existía', 'VERB'), ('fiebre', 'NOUN'), ('ninguna', 'DET'), ('clínica', 'NOUN'), ('sugestiva', 'ADJ'), ('infección', 'NOUN'), ('.', 'PUNCT'), ('A', 'ADP'), ('24', 'NUM'), ('horas', 'NOUN'), ('acude', 'VERB'), ('alteración', 'NOUN'), ('severa', 'ADJ'), ('nivel', 'NOUN'), ('conciencia', 'NOUN'), ('Glasgow', 'PROPN'), ('6', 'NUM'), ('.', 'PUNCT'), ('En', 'ADP'), ('ocasión', 'NOUN'), ('paciente', 'ADJ'), ('acudía', 'VERB'), ('tras', 'ADP'), ('haber', 'AUX'), ('iniciado', 'VERB'), ('15', 'NUM'), ('días', 'NOUN'), (',', 'PUNCT'), ('primer', 'ADJ'), ('ciclo', 'NOUN'), ('quimioterapia', 'ADJ'), ('adyuvante', 'ADJ'), ('esquema', 'NOUN'), ('taxol', 'NOUN'), ('175', 'NUM'), ('mg/m2', 'NUM'), ('carboplatino', 'ADJ'), ('AUC', 'PROPN'), ('5', 'NUM'), ('.', 'PUNCT'), ('Por', 'ADP'), ('ello', 'PRON'), (',', 'PUNCT'), ('presentaba', 'VERB'), ('leucopenia', 'NOUN'), ('neutropenia', 'ADJ'), ('atribuible', 'ADJ'), ('mielotoxicidad', 'NOUN'), ('postquimioterapia', 'ADJ'), ('.', 'PUNCT'), ('Todos', 'DET'), ('demás', 'DET'), ('parámetros', 'NOUN'), ('electrolíticos', 'ADJ'), (',', 'PUNCT'), ('incluyendo', 'VERB'), ('calcemia', 'NOUN'), (',', 'PUNCT'), ('rigurosamente', 'ADV'), ('normales', 'ADJ'), ('.', 'PUNCT'), ('La', 'DET'), ('gasometría', 'NOUN'), ('venosa', 'ADJ'), ('demostraba', 'VERB'), ('pH', 'PROPN'), ('7.44', 'PROPN'), ('.', 'PUNCT'), ('El', 'DET'), ('TAC', 'PROPN'), ('cerebral', 'ADJ'), ('radiografía', 'NOUN'), ('tórax', 'NOUN'), ('normales', 'ADJ'), ('.', 'PUNCT'), ('Ante', 'ADP'), ('presencia', 'VERB'), ('episodios', 'NOUN'), ('repetidos', 'ADJ'), ('síndrome', 'NOUN'), ('confusional', 'ADJ'), ('probable', 'ADJ'), ('causa', 'NOUN'), ('metabólica', 'ADJ'), (',', 'PUNCT'), ('3', 'NUM'), ('meses', 'NOUN'), ('cistectomía', 'NOUN'), (',', 'PUNCT'), ('consideró', 'VERB'), ('podría', 'AUX'), ('ser', 'AUX'), ('complicación', 'NOUN'), ('metabólica', 'ADJ'), ('derivación', 'NOUN'), ('.', 'PUNCT'), ('Tras', 'ADP'), ('haberse', 'AUX'), ('descartado', 'VERB'), ('tratara', 'VERB'), ('acidosis', 'NOUN'), ('metabólica', 'ADJ'), ('decidió', 'VERB'), ('solicitar', 'VERB'), ('niveles', 'NOUN'), ('amonio', 'ADJ'), ('sangre', 'NOUN'), (',', 'PUNCT'), ('demostraron', 'VERB'), ('amonemia', 'NOUN'), ('400', 'NUM'), ('microgramos/dl', 'PROPN'), ('(', 'PUNCT'), ('normal', 'ADJ'), ('17-80', 'NUM'), (')', 'PUNCT'), ('.', 'PUNCT'), ('Ante', 'ADP'), ('diagnóstico', 'NOUN'), ('encefalopatía', 'NOUN'), ('hiperamonémica', 'ADJ'), ('causa', 'NOUN'), ('no-hepática', 'ADJ'), ('inició', 'VERB'), ('fluidoterapia', 'NOUN'), (',', 'PUNCT'), ('dieta', 'NOUN'), ('absoluta', 'ADJ'), (',', 'PUNCT'), ('enemas', 'ADJ'), ('lactulosa', 'ADJ'), ('gravedad', 'NOUN'), ('clínica', 'ADJ'), ('inició', 'VERB'), ('hemodiálisis', 'NOUN'), ('.', 'PUNCT'), ('Tras', 'ADP'), ('3', 'NUM'), ('sesiones', 'NOUN'), ('hemodiálisis', 'ADJ'), ('paciente', 'ADJ'), ('experimentó', 'VERB'), ('recuperación', 'NOUN'), ('neurológica', 'ADJ'), ('paralela', 'ADJ'), ('corrección', 'NOUN'), ('niveles', 'NOUN'), ('amonio', 'ADJ'), ('disminuyeron', 'VERB'), ('normalizarse', 'NOUN'), ('.', 'PUNCT'), ('Posteriormente', 'ADV'), ('realizó', 'VERB'), ('reconversión', 'NOUN'), ('quirúrgica', 'ADJ'), ('ureterosigmoidostomía', 'VERB'), ('conducto', 'NOUN'), ('ileal', 'ADJ'), ('.', 'PUNCT'), ('Actualmente', 'ADV'), ('paciente', 'ADJ'), ('continúa', 'VERB'), ('tratamiento', 'NOUN'), ('quimioterápico', 'ADJ'), ('adyuvante', 'ADJ'), ('vuelto', 'AUX'), ('presentar', 'VERB'), ('nuevos', 'ADJ'), ('episodios', 'NOUN'), ('confusionales', 'ADJ'), ('.', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "text = st.tag(nltk.word_tokenize(prueba))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect acronym with patterns and heuristic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acron_detect(concept):\n",
    "    if ((len(concept) >= 2 and len(concept) <= 10) and sum(x.isupper() for x in concept) >= 1 and any(x.isalpha() for x in concept) and sum(x.isdigit() for x in concept) <= 1) and \\\n",
    "    (sum(c.isspace() for c in concept) <= 1):\n",
    "        print(concept, \"is an acronym\")\n",
    "#     else:\n",
    "#         print(concept, \"is NOT and acronym\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = train_raw.iloc[0]['texto_POS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se is an acronym\n",
      "Durante is an acronym\n",
      "La is an acronym\n",
      "Se is an acronym\n",
      "En is an acronym\n",
      "Las is an acronym\n",
      "Se is an acronym\n",
      "Con is an acronym\n",
      "Los is an acronym\n",
      "El is an acronym\n",
      "No is an acronym\n",
      "El is an acronym\n",
      "DAKO is an acronym\n"
     ]
    }
   ],
   "source": [
    "for x in tokens:\n",
    "    acron_detect(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = [lambda concept: sum(x.isdigit() for x in concept) <= 1, # could have one digit\n",
    "        lambda concept: any(x.isalpha() for x in concept),  # must have at least one letter\n",
    "        lambda concept: sum(x.isupper() for x in concept) >= 1,  # must have at least one uppercase\n",
    "        lambda concept: sum(x.isspace() for x in concept) <= 1,  # could have just one white space\n",
    "        lambda concept: (len(concept) >= 2 and len(concept) <= 10), # must be more than 2 characters and at least 10 characters\n",
    "         \n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [p for p in [r('DAKO') for r in rules]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('DAKO', 'PROPN')\n"
     ]
    }
   ],
   "source": [
    "for token in tokens:\n",
    "    if all(rule(token[0]) for rule in rules) and token[1] == 'PROPN':\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#patron = r'\\(([A-Z]{2,8})\\)'\n",
    "#patron1 = r'\\s[A-Z]{1,3}\\s'\n",
    "#patron2 = r'\\s[a-z]{1,3}\\s'\n",
    "patron3 = r'[A-Z]{2,8}'\n",
    "patron4 = r'\\s[a-z]{1,2}\\s'\n",
    "patron5 = r'[a-z]+\\-[A-Z]{1,8}'\n",
    "patron6 = r'[a-z]+\\/[a-z]+'\n",
    "patron7 = r'[A-Z]?[a-z]{1,4}[A-Z]+[a-z]*[1-9]*'\n",
    "patron8 = r'\\/[a-z]*[A-Z]*'\n",
    "\n",
    "\n",
    "# create a list with them\n",
    "regexes = [ patron3, patron4, patron5, patron6, patron7,patron8]\n",
    "for i in regexes:\n",
    "    generic_re = re.compile(\"%s|%s|%s|%s|%s|%s\" % (patron3, patron4, patron5, patron6, patron7,patron8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get Short Formns with a regex in each text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw['abrev'] = train_raw['texto'].map(lambda x: generic_re.findall(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
