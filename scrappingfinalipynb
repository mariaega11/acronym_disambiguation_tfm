{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import requests\n",
    "\n",
    "from sys import argv\n",
    "from bs4 import BeautifulSoup\n",
    "from math import ceil "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_arguments(parser):\n",
    "    concepto = vars(parser.parse_args(argv[1:]))[\"c\"]\n",
    "    return concepto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(concepto):\n",
    "\n",
    "    # URL de origen que se \n",
    "    url = \"https://pubmed.ncbi.nlm.nih.gov/?term={}\".format(concepto)\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    num_registros = soup.find('div', class_=\"results-amount\").find('span').text.replace(\",\", \"\")\n",
    "\n",
    "    print(\"Numero de articulos: {}\".format(num_registros))\n",
    "\n",
    "    num_paginas = ceil(int(num_registros)/10)\n",
    "\n",
    "    #Bucle generando una lista con todos los articulos\n",
    "    lista_articulos = list()\n",
    "    for i in range(1,num_paginas+1):\n",
    "        url_busqueda = url + \"&page={}\".format(i)\n",
    "        page = requests.get(url_busqueda)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "        for articulo in soup.find_all('article', class_=\"full-docsum\"):\n",
    "            lista_articulos.append(articulo.find('a', href=True, class_='docsum-title')['href'])\n",
    "\n",
    "    #Bucle en el que se mete en cada articulo y obtiene el abstract\n",
    "    informacion = list()\n",
    "    for url_articulo in lista_articulos:\n",
    "        page = requests.get(\"https://pubmed.ncbi.nlm.nih.gov/\" + url_articulo)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "        try:\n",
    "            informacion.append(soup.find('div', {\"id\": \"enc-abstract\"}).text.replace(\"\\n\", \" \"))\n",
    "\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "    print(\"Numero de abstract obtenidos: {} para la palabra: {}\".format(len(informacion), conceto))\n",
    "    return informacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de articulos: 519925\n"
     ]
    }
   ],
   "source": [
    "search('PCR')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
