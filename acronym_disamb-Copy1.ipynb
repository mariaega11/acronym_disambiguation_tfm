{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3094,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import collections\n",
    "#from gensim.parsing.preprocessing import remove_stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import itertools \n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "\n",
    "from nltk import ngrams\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3095,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_texts(path):\n",
    "    data = []\n",
    "    file_name = os.listdir(path)\n",
    "\n",
    "    for name in file_name:\n",
    "        if name.endswith('.txt'):\n",
    "            with open(path + name,encoding=\"utf8\") as f:\n",
    "                text = f.read()\n",
    "                data.append({'nombre':name.replace('.txt',''), 'texto':text})\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3096,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def filter_byindex(x,y):\n",
    "#     #selectors = [x for x in col2]\n",
    "#     return list(itertools.compress(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3097,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_len(x,y):\n",
    "    if x==y:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3098,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lf(i,j,k):\n",
    "    if pd.isnull(k):\n",
    "        regex_lf = re.compile(r'((?:\\w+\\W+){1,'+str(len(i))+'})\\(\\s'+i[0]+'.*\\)')\n",
    "        return regex_lf.findall(j)\n",
    "    else:\n",
    "        return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3099,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_filter(doc, word, n):\n",
    "    tokens = doc.split()\n",
    "    all_ngrams = ngrams(tokens, n)\n",
    "    filtered_ngrams = [x for x in all_ngrams if word in x]\n",
    "    return filtered_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_longform(tokens, acro, margin = 2, i =1):\n",
    "#     long_form = ''\n",
    "#     #Looking for before\n",
    "#     for word in tokens[index-margin-len(acro):index]:\n",
    "#         #if first letter of word is equal to first letter os acronym\n",
    "#         if word[0] == acro[i].lower():\n",
    "#             long_form += word + ' '\n",
    "#             i += 1\n",
    "#             if i == len(acro):\n",
    "#                 break\n",
    "#         elif (i == 1) and (word[0] == acro[i-1].lower()):\n",
    "#             long_form = word + ' '\n",
    "#             i = 1\n",
    "#             if i == len(acro):\n",
    "#                 break\n",
    "#     long_form = long_form.rstrip()\n",
    "#     return long_form\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_longform(tokens, acro, long):\n",
    "    acro = acro.lower()\n",
    "    long_form = ''\n",
    "    margin = 2\n",
    "    i =0\n",
    "    #Looking for before\n",
    "    if acro not in tokens:\n",
    "        return -1\n",
    "    if pd.isna(long):\n",
    "        index = tokens.index(acro)\n",
    "        for word in tokens[index-margin-len(acro):index]:\n",
    "            #if first letter of word is equal to first letter os acronym\n",
    "            if word[0] == acro[i].lower():\n",
    "                long_form += word + ' '\n",
    "                i += 1\n",
    "                if i == len(acro):\n",
    "                    break\n",
    "            elif (i == 1) and (word[0] == acro[i-1].lower()):\n",
    "                long_form = word + ' '\n",
    "                i = 1\n",
    "                if i == len(acro):\n",
    "                    break\n",
    "        long_form = long_form.rstrip()\n",
    "        return long_form\n",
    "    else:\n",
    "        return long\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainning\n",
    "\n",
    "318 clinical cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = read_texts(\"../datasets/trainning_set/training_set.raw_text/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = train_raw.rename(columns = {'nombre': 'doc_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1130-05582012000300005-1</td>\n",
       "      <td>Acude a nuestras consultas a un paciente que p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0212-71992005000400009-1</td>\n",
       "      <td>Se trataba de un varón de 27 años de edad, que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0004-06142008000700015-2</td>\n",
       "      <td>Varón de 33 años fumador de un paquete de ciga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0210-56912006000800008-1</td>\n",
       "      <td>Hombre de 42 años, bebedor de más de 100 g de ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0376-78922009000300010-1</td>\n",
       "      <td>Paciente de 18 años de edad que 5 meses antes ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      doc_id  \\\n",
       "0  S1130-05582012000300005-1   \n",
       "1  S0212-71992005000400009-1   \n",
       "2  S0004-06142008000700015-2   \n",
       "3  S0210-56912006000800008-1   \n",
       "4  S0376-78922009000300010-1   \n",
       "\n",
       "                                               texto  \n",
       "0  Acude a nuestras consultas a un paciente que p...  \n",
       "1  Se trataba de un varón de 27 años de edad, que...  \n",
       "2  Varón de 33 años fumador de un paquete de ciga...  \n",
       "3  Hombre de 42 años, bebedor de más de 100 g de ...  \n",
       "4  Paciente de 18 años de edad que 5 meses antes ...  "
      ]
     },
     "execution_count": 3104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318, 2)"
      ]
     },
     "execution_count": 3105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sub-track 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Found abbreviations (Short Forms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3106,
   "metadata": {},
   "outputs": [],
   "source": [
    "patron3 = r'[A-Z]{2,8}' #Letras mayúsculas entre 2 y 8. Probar (\\s|\\()[A-Z]{2,8}\n",
    "patron4 = r'\\s[a-z]{1,2}\\s' #Entre 2 y 3 letras minusculas entre espacios\n",
    "patron5 = r'\\b[aA-zZ]{1,4}\\-[aA-zZ]{1,4}\\b' #mayúsuclas o minúsculas entre guiones\n",
    "#patron6 = r'[1-9]\\s*[aA-zZ]{1,4}\\/\\b[aA-zZ]{1,4}\\b' #Palabras divididas por / solo cuando las palabras no exceden de 4 caracteres\n",
    "patron6 = r'\\b\\w{2}\\b\\/'\n",
    "patron7 = r'\\/\\b\\w{2}\\b'\n",
    "patron8 = r'[aA-zZ]{1,4}[A-Z]+[a-z]*[1-4]*'\n",
    "#patron8 = r'\\/[a-z]*[A-Z]*'\n",
    "\n",
    "\n",
    "# create a list with them\n",
    "regexes = [ patron3, patron4, patron5, patron6, patron7]\n",
    "for i in regexes:\n",
    "    generic_re = re.compile(\"%s|%s|%s|%s|%s|%s\" % (patron3, patron4, patron5, patron6, patron7, patron8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('stopwords')\n",
    "swords = list(set(stopwords.words('spanish')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add words to stopwords lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3108,
   "metadata": {},
   "outputs": [],
   "source": [
    "swords = swords + ['I','II','III','VI','VII','VIII','IX', 'X', 'x']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Short Formns with a regex in each text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw['abrev'] = train_raw['texto'].map(lambda x: generic_re.findall(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate mesurement units separate by \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_raw['abrev'] = train_raw['abrev'].apply(lambda x: [a.split(\"/\") for a in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_raw['abrev'] = train_raw['abrev'].apply(lambda x: [item for sublist in x for item in sublist])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get offsets of the Short Forms founded in the text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw['offse'] = train_raw['texto'].map(lambda x: [(m.start(0), m.end(0)) for m in re.finditer(generic_re, x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove whitespaces\n",
    "train_raw['abrev'] = train_raw['abrev'].apply(lambda x: [i.strip() for i in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter Short Forms to delete ones which are stopwords, get their index too for filter offsets lists later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_raw['abrev_index'] = train_raw['abrev'].apply(lambda x: [x.index(i) for i in x if i not in swords])\n",
    "train_raw['abrev_index'] = train_raw['abrev'].apply(lambda x: [i for i,j in enumerate(x) if j not in swords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw['abrev'] = train_raw['abrev'].apply(lambda x: [i for i in x if i not in swords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3116,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw['abrev'] = train_raw['abrev'].apply(lambda x: [a.replace('/',\"\") for a in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter offsets lists by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3117,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw['offse'] = train_raw.apply(lambda x: [x['offse'][i] for i in x['abrev_index']], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>texto</th>\n",
       "      <th>abrev</th>\n",
       "      <th>offse</th>\n",
       "      <th>abrev_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1130-05582012000300005-1</td>\n",
       "      <td>Acude a nuestras consultas a un paciente que p...</td>\n",
       "      <td>[RM, PAAF]</td>\n",
       "      <td>[(789, 791), (1006, 1010)]</td>\n",
       "      <td>[24, 31]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0212-71992005000400009-1</td>\n",
       "      <td>Se trataba de un varón de 27 años de edad, que...</td>\n",
       "      <td>[mm, mm, mg, mg, mg, mg, LDH, UI, GOT, UI, GPT...</td>\n",
       "      <td>[(1056, 1059), (1079, 1082), (1247, 1250), (12...</td>\n",
       "      <td>[36, 37, 44, 47, 48, 49, 50, 51, 52, 53, 54, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0004-06142008000700015-2</td>\n",
       "      <td>Varón de 33 años fumador de un paquete de ciga...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0210-56912006000800008-1</td>\n",
       "      <td>Hombre de 42 años, bebedor de más de 100 g de ...</td>\n",
       "      <td>[g, mg, dl, dl, AST, ALT, GGT, UI, dl, TAC, mg...</td>\n",
       "      <td>[(40, 43), (654, 657), (670, 673), (697, 700),...</td>\n",
       "      <td>[3, 23, 24, 25, 26, 27, 28, 29, 30, 37, 64, 65...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0376-78922009000300010-1</td>\n",
       "      <td>Paciente de 18 años de edad que 5 meses antes ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      doc_id  \\\n",
       "0  S1130-05582012000300005-1   \n",
       "1  S0212-71992005000400009-1   \n",
       "2  S0004-06142008000700015-2   \n",
       "3  S0210-56912006000800008-1   \n",
       "4  S0376-78922009000300010-1   \n",
       "\n",
       "                                               texto  \\\n",
       "0  Acude a nuestras consultas a un paciente que p...   \n",
       "1  Se trataba de un varón de 27 años de edad, que...   \n",
       "2  Varón de 33 años fumador de un paquete de ciga...   \n",
       "3  Hombre de 42 años, bebedor de más de 100 g de ...   \n",
       "4  Paciente de 18 años de edad que 5 meses antes ...   \n",
       "\n",
       "                                               abrev  \\\n",
       "0                                         [RM, PAAF]   \n",
       "1  [mm, mm, mg, mg, mg, mg, LDH, UI, GOT, UI, GPT...   \n",
       "2                                                 []   \n",
       "3  [g, mg, dl, dl, AST, ALT, GGT, UI, dl, TAC, mg...   \n",
       "4                                                 []   \n",
       "\n",
       "                                               offse  \\\n",
       "0                         [(789, 791), (1006, 1010)]   \n",
       "1  [(1056, 1059), (1079, 1082), (1247, 1250), (12...   \n",
       "2                                                 []   \n",
       "3  [(40, 43), (654, 657), (670, 673), (697, 700),...   \n",
       "4                                                 []   \n",
       "\n",
       "                                         abrev_index  \n",
       "0                                           [24, 31]  \n",
       "1  [36, 37, 44, 47, 48, 49, 50, 51, 52, 53, 54, 5...  \n",
       "2                                                 []  \n",
       "3  [3, 23, 24, 25, 26, 27, 28, 29, 30, 37, 64, 65...  \n",
       "4                                                 []  "
      ]
     },
     "execution_count": 3118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check abrev and offse columns has the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw['abrev_len'] =train_raw['abrev'].str.len()\n",
    "train_raw['offse_len'] =train_raw['offse'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>texto</th>\n",
       "      <th>abrev</th>\n",
       "      <th>offse</th>\n",
       "      <th>abrev_index</th>\n",
       "      <th>abrev_len</th>\n",
       "      <th>offse_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1130-05582012000300005-1</td>\n",
       "      <td>Acude a nuestras consultas a un paciente que p...</td>\n",
       "      <td>[RM, PAAF]</td>\n",
       "      <td>[(789, 791), (1006, 1010)]</td>\n",
       "      <td>[24, 31]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0212-71992005000400009-1</td>\n",
       "      <td>Se trataba de un varón de 27 años de edad, que...</td>\n",
       "      <td>[mm, mm, mg, mg, mg, mg, LDH, UI, GOT, UI, GPT...</td>\n",
       "      <td>[(1056, 1059), (1079, 1082), (1247, 1250), (12...</td>\n",
       "      <td>[36, 37, 44, 47, 48, 49, 50, 51, 52, 53, 54, 5...</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0004-06142008000700015-2</td>\n",
       "      <td>Varón de 33 años fumador de un paquete de ciga...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0210-56912006000800008-1</td>\n",
       "      <td>Hombre de 42 años, bebedor de más de 100 g de ...</td>\n",
       "      <td>[g, mg, dl, dl, AST, ALT, GGT, UI, dl, TAC, mg...</td>\n",
       "      <td>[(40, 43), (654, 657), (670, 673), (697, 700),...</td>\n",
       "      <td>[3, 23, 24, 25, 26, 27, 28, 29, 30, 37, 64, 65...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0376-78922009000300010-1</td>\n",
       "      <td>Paciente de 18 años de edad que 5 meses antes ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      doc_id  \\\n",
       "0  S1130-05582012000300005-1   \n",
       "1  S0212-71992005000400009-1   \n",
       "2  S0004-06142008000700015-2   \n",
       "3  S0210-56912006000800008-1   \n",
       "4  S0376-78922009000300010-1   \n",
       "\n",
       "                                               texto  \\\n",
       "0  Acude a nuestras consultas a un paciente que p...   \n",
       "1  Se trataba de un varón de 27 años de edad, que...   \n",
       "2  Varón de 33 años fumador de un paquete de ciga...   \n",
       "3  Hombre de 42 años, bebedor de más de 100 g de ...   \n",
       "4  Paciente de 18 años de edad que 5 meses antes ...   \n",
       "\n",
       "                                               abrev  \\\n",
       "0                                         [RM, PAAF]   \n",
       "1  [mm, mm, mg, mg, mg, mg, LDH, UI, GOT, UI, GPT...   \n",
       "2                                                 []   \n",
       "3  [g, mg, dl, dl, AST, ALT, GGT, UI, dl, TAC, mg...   \n",
       "4                                                 []   \n",
       "\n",
       "                                               offse  \\\n",
       "0                         [(789, 791), (1006, 1010)]   \n",
       "1  [(1056, 1059), (1079, 1082), (1247, 1250), (12...   \n",
       "2                                                 []   \n",
       "3  [(40, 43), (654, 657), (670, 673), (697, 700),...   \n",
       "4                                                 []   \n",
       "\n",
       "                                         abrev_index  abrev_len  offse_len  \n",
       "0                                           [24, 31]          2          2  \n",
       "1  [36, 37, 44, 47, 48, 49, 50, 51, 52, 53, 54, 5...         34         34  \n",
       "2                                                 []          0          0  \n",
       "3  [3, 23, 24, 25, 26, 27, 28, 29, 30, 37, 64, 65...         22         22  \n",
       "4                                                 []          0          0  "
      ]
     },
     "execution_count": 3120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check both lists have the same lenght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3121,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw['len_check'] = train_raw.apply(lambda row: check_len(row['abrev_len'],row['offse_len']),axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete rows with different lenghts (check it later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318, 8)"
      ]
     },
     "execution_count": 3122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318, 8)"
      ]
     },
     "execution_count": 3123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw[train_raw['len_check'] != 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_raw = train_raw[train_raw['len_check'] != 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove string punctuation, lowecase, tokenize and remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw['texto_clean'] = train_raw['texto'].str.replace('[^\\w\\s]',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3126,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw['texto_clean'] = train_raw['texto_clean'].apply(lambda x: unidecode.unidecode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3127,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw['texto_clean'] = train_raw['texto_clean'].str.split().map(lambda x: ' '.join([w for w in x if w not in swords]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3128,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw['tokens'] = train_raw['texto_clean'].map(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>texto</th>\n",
       "      <th>abrev</th>\n",
       "      <th>offse</th>\n",
       "      <th>abrev_index</th>\n",
       "      <th>abrev_len</th>\n",
       "      <th>offse_len</th>\n",
       "      <th>len_check</th>\n",
       "      <th>texto_clean</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1130-05582012000300005-1</td>\n",
       "      <td>Acude a nuestras consultas a un paciente que p...</td>\n",
       "      <td>[RM, PAAF]</td>\n",
       "      <td>[(789, 791), (1006, 1010)]</td>\n",
       "      <td>[24, 31]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Acude consultas paciente presenta tumoracion c...</td>\n",
       "      <td>[Acude, consultas, paciente, presenta, tumorac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0212-71992005000400009-1</td>\n",
       "      <td>Se trataba de un varón de 27 años de edad, que...</td>\n",
       "      <td>[mm, mm, mg, mg, mg, mg, LDH, UI, GOT, UI, GPT...</td>\n",
       "      <td>[(1056, 1059), (1079, 1082), (1247, 1250), (12...</td>\n",
       "      <td>[36, 37, 44, 47, 48, 49, 50, 51, 52, 53, 54, 5...</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>Se trataba varon 27 anos edad habia sufrido ne...</td>\n",
       "      <td>[Se, trataba, varon, 27, anos, edad, habia, su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0004-06142008000700015-2</td>\n",
       "      <td>Varón de 33 años fumador de un paquete de ciga...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Varon 33 anos fumador paquete cigarrillos dia ...</td>\n",
       "      <td>[Varon, 33, anos, fumador, paquete, cigarrillo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0210-56912006000800008-1</td>\n",
       "      <td>Hombre de 42 años, bebedor de más de 100 g de ...</td>\n",
       "      <td>[g, mg, dl, dl, AST, ALT, GGT, UI, dl, TAC, mg...</td>\n",
       "      <td>[(40, 43), (654, 657), (670, 673), (697, 700),...</td>\n",
       "      <td>[3, 23, 24, 25, 26, 27, 28, 29, 30, 37, 64, 65...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>Hombre 42 anos bebedor mas 100 g etanol dia an...</td>\n",
       "      <td>[Hombre, 42, anos, bebedor, mas, 100, g, etano...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0376-78922009000300010-1</td>\n",
       "      <td>Paciente de 18 años de edad que 5 meses antes ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Paciente 18 anos edad 5 meses habia sido victi...</td>\n",
       "      <td>[Paciente, 18, anos, edad, 5, meses, habia, si...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      doc_id  \\\n",
       "0  S1130-05582012000300005-1   \n",
       "1  S0212-71992005000400009-1   \n",
       "2  S0004-06142008000700015-2   \n",
       "3  S0210-56912006000800008-1   \n",
       "4  S0376-78922009000300010-1   \n",
       "\n",
       "                                               texto  \\\n",
       "0  Acude a nuestras consultas a un paciente que p...   \n",
       "1  Se trataba de un varón de 27 años de edad, que...   \n",
       "2  Varón de 33 años fumador de un paquete de ciga...   \n",
       "3  Hombre de 42 años, bebedor de más de 100 g de ...   \n",
       "4  Paciente de 18 años de edad que 5 meses antes ...   \n",
       "\n",
       "                                               abrev  \\\n",
       "0                                         [RM, PAAF]   \n",
       "1  [mm, mm, mg, mg, mg, mg, LDH, UI, GOT, UI, GPT...   \n",
       "2                                                 []   \n",
       "3  [g, mg, dl, dl, AST, ALT, GGT, UI, dl, TAC, mg...   \n",
       "4                                                 []   \n",
       "\n",
       "                                               offse  \\\n",
       "0                         [(789, 791), (1006, 1010)]   \n",
       "1  [(1056, 1059), (1079, 1082), (1247, 1250), (12...   \n",
       "2                                                 []   \n",
       "3  [(40, 43), (654, 657), (670, 673), (697, 700),...   \n",
       "4                                                 []   \n",
       "\n",
       "                                         abrev_index  abrev_len  offse_len  \\\n",
       "0                                           [24, 31]          2          2   \n",
       "1  [36, 37, 44, 47, 48, 49, 50, 51, 52, 53, 54, 5...         34         34   \n",
       "2                                                 []          0          0   \n",
       "3  [3, 23, 24, 25, 26, 27, 28, 29, 30, 37, 64, 65...         22         22   \n",
       "4                                                 []          0          0   \n",
       "\n",
       "   len_check                                        texto_clean  \\\n",
       "0          0  Acude consultas paciente presenta tumoracion c...   \n",
       "1          0  Se trataba varon 27 anos edad habia sufrido ne...   \n",
       "2          0  Varon 33 anos fumador paquete cigarrillos dia ...   \n",
       "3          0  Hombre 42 anos bebedor mas 100 g etanol dia an...   \n",
       "4          0  Paciente 18 anos edad 5 meses habia sido victi...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [Acude, consultas, paciente, presenta, tumorac...  \n",
       "1  [Se, trataba, varon, 27, anos, edad, habia, su...  \n",
       "2  [Varon, 33, anos, fumador, paquete, cigarrillo...  \n",
       "3  [Hombre, 42, anos, bebedor, mas, 100, g, etano...  \n",
       "4  [Paciente, 18, anos, edad, 5, meses, habia, si...  "
      ]
     },
     "execution_count": 3129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get abreviations and offsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove punctuation from abreviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in punctuation:\n",
    "#     train_raw['abrev'] = train_raw[train_raw['abrev'].notnull()]['abrev'].apply(lambda x: [a.replace(i,\"\") for a in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3131,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw['zip'] = train_raw.apply(lambda row: list(zip(row['abrev'], row['offse'])), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>texto</th>\n",
       "      <th>abrev</th>\n",
       "      <th>offse</th>\n",
       "      <th>abrev_index</th>\n",
       "      <th>abrev_len</th>\n",
       "      <th>offse_len</th>\n",
       "      <th>len_check</th>\n",
       "      <th>texto_clean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1130-05582012000300005-1</td>\n",
       "      <td>Acude a nuestras consultas a un paciente que p...</td>\n",
       "      <td>[RM, PAAF]</td>\n",
       "      <td>[(789, 791), (1006, 1010)]</td>\n",
       "      <td>[24, 31]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Acude consultas paciente presenta tumoracion c...</td>\n",
       "      <td>[Acude, consultas, paciente, presenta, tumorac...</td>\n",
       "      <td>[(RM, (789, 791)), (PAAF, (1006, 1010))]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0212-71992005000400009-1</td>\n",
       "      <td>Se trataba de un varón de 27 años de edad, que...</td>\n",
       "      <td>[mm, mm, mg, mg, mg, mg, LDH, UI, GOT, UI, GPT...</td>\n",
       "      <td>[(1056, 1059), (1079, 1082), (1247, 1250), (12...</td>\n",
       "      <td>[36, 37, 44, 47, 48, 49, 50, 51, 52, 53, 54, 5...</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>Se trataba varon 27 anos edad habia sufrido ne...</td>\n",
       "      <td>[Se, trataba, varon, 27, anos, edad, habia, su...</td>\n",
       "      <td>[(mm, (1056, 1059)), (mm, (1079, 1082)), (mg, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0004-06142008000700015-2</td>\n",
       "      <td>Varón de 33 años fumador de un paquete de ciga...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Varon 33 anos fumador paquete cigarrillos dia ...</td>\n",
       "      <td>[Varon, 33, anos, fumador, paquete, cigarrillo...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0210-56912006000800008-1</td>\n",
       "      <td>Hombre de 42 años, bebedor de más de 100 g de ...</td>\n",
       "      <td>[g, mg, dl, dl, AST, ALT, GGT, UI, dl, TAC, mg...</td>\n",
       "      <td>[(40, 43), (654, 657), (670, 673), (697, 700),...</td>\n",
       "      <td>[3, 23, 24, 25, 26, 27, 28, 29, 30, 37, 64, 65...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>Hombre 42 anos bebedor mas 100 g etanol dia an...</td>\n",
       "      <td>[Hombre, 42, anos, bebedor, mas, 100, g, etano...</td>\n",
       "      <td>[(g, (40, 43)), (mg, (654, 657)), (dl, (670, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0376-78922009000300010-1</td>\n",
       "      <td>Paciente de 18 años de edad que 5 meses antes ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Paciente 18 anos edad 5 meses habia sido victi...</td>\n",
       "      <td>[Paciente, 18, anos, edad, 5, meses, habia, si...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      doc_id  \\\n",
       "0  S1130-05582012000300005-1   \n",
       "1  S0212-71992005000400009-1   \n",
       "2  S0004-06142008000700015-2   \n",
       "3  S0210-56912006000800008-1   \n",
       "4  S0376-78922009000300010-1   \n",
       "\n",
       "                                               texto  \\\n",
       "0  Acude a nuestras consultas a un paciente que p...   \n",
       "1  Se trataba de un varón de 27 años de edad, que...   \n",
       "2  Varón de 33 años fumador de un paquete de ciga...   \n",
       "3  Hombre de 42 años, bebedor de más de 100 g de ...   \n",
       "4  Paciente de 18 años de edad que 5 meses antes ...   \n",
       "\n",
       "                                               abrev  \\\n",
       "0                                         [RM, PAAF]   \n",
       "1  [mm, mm, mg, mg, mg, mg, LDH, UI, GOT, UI, GPT...   \n",
       "2                                                 []   \n",
       "3  [g, mg, dl, dl, AST, ALT, GGT, UI, dl, TAC, mg...   \n",
       "4                                                 []   \n",
       "\n",
       "                                               offse  \\\n",
       "0                         [(789, 791), (1006, 1010)]   \n",
       "1  [(1056, 1059), (1079, 1082), (1247, 1250), (12...   \n",
       "2                                                 []   \n",
       "3  [(40, 43), (654, 657), (670, 673), (697, 700),...   \n",
       "4                                                 []   \n",
       "\n",
       "                                         abrev_index  abrev_len  offse_len  \\\n",
       "0                                           [24, 31]          2          2   \n",
       "1  [36, 37, 44, 47, 48, 49, 50, 51, 52, 53, 54, 5...         34         34   \n",
       "2                                                 []          0          0   \n",
       "3  [3, 23, 24, 25, 26, 27, 28, 29, 30, 37, 64, 65...         22         22   \n",
       "4                                                 []          0          0   \n",
       "\n",
       "   len_check                                        texto_clean  \\\n",
       "0          0  Acude consultas paciente presenta tumoracion c...   \n",
       "1          0  Se trataba varon 27 anos edad habia sufrido ne...   \n",
       "2          0  Varon 33 anos fumador paquete cigarrillos dia ...   \n",
       "3          0  Hombre 42 anos bebedor mas 100 g etanol dia an...   \n",
       "4          0  Paciente 18 anos edad 5 meses habia sido victi...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Acude, consultas, paciente, presenta, tumorac...   \n",
       "1  [Se, trataba, varon, 27, anos, edad, habia, su...   \n",
       "2  [Varon, 33, anos, fumador, paquete, cigarrillo...   \n",
       "3  [Hombre, 42, anos, bebedor, mas, 100, g, etano...   \n",
       "4  [Paciente, 18, anos, edad, 5, meses, habia, si...   \n",
       "\n",
       "                                                 zip  \n",
       "0           [(RM, (789, 791)), (PAAF, (1006, 1010))]  \n",
       "1  [(mm, (1056, 1059)), (mm, (1079, 1082)), (mg, ...  \n",
       "2                                                 []  \n",
       "3  [(g, (40, 43)), (mg, (654, 657)), (dl, (670, 6...  \n",
       "4                                                 []  "
      ]
     },
     "execution_count": 3132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get one row per abbreviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate elements lists in different rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3133,
   "metadata": {},
   "outputs": [],
   "source": [
    "mine = train_raw.explode('zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3201, 11)"
      ]
     },
     "execution_count": 3134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 11)"
      ]
     },
     "execution_count": 3135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mine[mine['zip'].isnull()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3136,
   "metadata": {},
   "outputs": [],
   "source": [
    "mine = mine[['doc_id', 'texto_clean', 'tokens', 'zip']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3137,
   "metadata": {},
   "outputs": [],
   "source": [
    "mine = mine[mine['zip'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3183, 4)"
      ]
     },
     "execution_count": 3138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>texto_clean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1130-05582012000300005-1</td>\n",
       "      <td>Acude consultas paciente presenta tumoracion c...</td>\n",
       "      <td>[Acude, consultas, paciente, presenta, tumorac...</td>\n",
       "      <td>(RM, (789, 791))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1130-05582012000300005-1</td>\n",
       "      <td>Acude consultas paciente presenta tumoracion c...</td>\n",
       "      <td>[Acude, consultas, paciente, presenta, tumorac...</td>\n",
       "      <td>(PAAF, (1006, 1010))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0212-71992005000400009-1</td>\n",
       "      <td>Se trataba varon 27 anos edad habia sufrido ne...</td>\n",
       "      <td>[Se, trataba, varon, 27, anos, edad, habia, su...</td>\n",
       "      <td>(mm, (1056, 1059))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0212-71992005000400009-1</td>\n",
       "      <td>Se trataba varon 27 anos edad habia sufrido ne...</td>\n",
       "      <td>[Se, trataba, varon, 27, anos, edad, habia, su...</td>\n",
       "      <td>(mm, (1079, 1082))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0212-71992005000400009-1</td>\n",
       "      <td>Se trataba varon 27 anos edad habia sufrido ne...</td>\n",
       "      <td>[Se, trataba, varon, 27, anos, edad, habia, su...</td>\n",
       "      <td>(mg, (1247, 1250))</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      doc_id  \\\n",
       "0  S1130-05582012000300005-1   \n",
       "0  S1130-05582012000300005-1   \n",
       "1  S0212-71992005000400009-1   \n",
       "1  S0212-71992005000400009-1   \n",
       "1  S0212-71992005000400009-1   \n",
       "\n",
       "                                         texto_clean  \\\n",
       "0  Acude consultas paciente presenta tumoracion c...   \n",
       "0  Acude consultas paciente presenta tumoracion c...   \n",
       "1  Se trataba varon 27 anos edad habia sufrido ne...   \n",
       "1  Se trataba varon 27 anos edad habia sufrido ne...   \n",
       "1  Se trataba varon 27 anos edad habia sufrido ne...   \n",
       "\n",
       "                                              tokens                   zip  \n",
       "0  [Acude, consultas, paciente, presenta, tumorac...      (RM, (789, 791))  \n",
       "0  [Acude, consultas, paciente, presenta, tumorac...  (PAAF, (1006, 1010))  \n",
       "1  [Se, trataba, varon, 27, anos, edad, habia, su...    (mm, (1056, 1059))  \n",
       "1  [Se, trataba, varon, 27, anos, edad, habia, su...    (mm, (1079, 1082))  \n",
       "1  [Se, trataba, varon, 27, anos, edad, habia, su...    (mg, (1247, 1250))  "
      ]
     },
     "execution_count": 3139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate SF from Offsets in different columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3140,
   "metadata": {},
   "outputs": [],
   "source": [
    "mine['abrev'] = mine.apply(lambda row: row['zip'][0], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3141,
   "metadata": {},
   "outputs": [],
   "source": [
    "mine['offsets'] = mine.apply(lambda row: row['zip'][1], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3142,
   "metadata": {},
   "outputs": [],
   "source": [
    "mine = mine[mine['abrev'] != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>texto_clean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>zip</th>\n",
       "      <th>abrev</th>\n",
       "      <th>offsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1130-05582012000300005-1</td>\n",
       "      <td>Acude consultas paciente presenta tumoracion c...</td>\n",
       "      <td>[Acude, consultas, paciente, presenta, tumorac...</td>\n",
       "      <td>(RM, (789, 791))</td>\n",
       "      <td>RM</td>\n",
       "      <td>(789, 791)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1130-05582012000300005-1</td>\n",
       "      <td>Acude consultas paciente presenta tumoracion c...</td>\n",
       "      <td>[Acude, consultas, paciente, presenta, tumorac...</td>\n",
       "      <td>(PAAF, (1006, 1010))</td>\n",
       "      <td>PAAF</td>\n",
       "      <td>(1006, 1010)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0212-71992005000400009-1</td>\n",
       "      <td>Se trataba varon 27 anos edad habia sufrido ne...</td>\n",
       "      <td>[Se, trataba, varon, 27, anos, edad, habia, su...</td>\n",
       "      <td>(mm, (1056, 1059))</td>\n",
       "      <td>mm</td>\n",
       "      <td>(1056, 1059)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0212-71992005000400009-1</td>\n",
       "      <td>Se trataba varon 27 anos edad habia sufrido ne...</td>\n",
       "      <td>[Se, trataba, varon, 27, anos, edad, habia, su...</td>\n",
       "      <td>(mm, (1079, 1082))</td>\n",
       "      <td>mm</td>\n",
       "      <td>(1079, 1082)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0212-71992005000400009-1</td>\n",
       "      <td>Se trataba varon 27 anos edad habia sufrido ne...</td>\n",
       "      <td>[Se, trataba, varon, 27, anos, edad, habia, su...</td>\n",
       "      <td>(mg, (1247, 1250))</td>\n",
       "      <td>mg</td>\n",
       "      <td>(1247, 1250)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      doc_id  \\\n",
       "0  S1130-05582012000300005-1   \n",
       "0  S1130-05582012000300005-1   \n",
       "1  S0212-71992005000400009-1   \n",
       "1  S0212-71992005000400009-1   \n",
       "1  S0212-71992005000400009-1   \n",
       "\n",
       "                                         texto_clean  \\\n",
       "0  Acude consultas paciente presenta tumoracion c...   \n",
       "0  Acude consultas paciente presenta tumoracion c...   \n",
       "1  Se trataba varon 27 anos edad habia sufrido ne...   \n",
       "1  Se trataba varon 27 anos edad habia sufrido ne...   \n",
       "1  Se trataba varon 27 anos edad habia sufrido ne...   \n",
       "\n",
       "                                              tokens                   zip  \\\n",
       "0  [Acude, consultas, paciente, presenta, tumorac...      (RM, (789, 791))   \n",
       "0  [Acude, consultas, paciente, presenta, tumorac...  (PAAF, (1006, 1010))   \n",
       "1  [Se, trataba, varon, 27, anos, edad, habia, su...    (mm, (1056, 1059))   \n",
       "1  [Se, trataba, varon, 27, anos, edad, habia, su...    (mm, (1079, 1082))   \n",
       "1  [Se, trataba, varon, 27, anos, edad, habia, su...    (mg, (1247, 1250))   \n",
       "\n",
       "  abrev       offsets  \n",
       "0    RM    (789, 791)  \n",
       "0  PAAF  (1006, 1010)  \n",
       "1    mm  (1056, 1059)  \n",
       "1    mm  (1079, 1082)  \n",
       "1    mg  (1247, 1250)  "
      ]
     },
     "execution_count": 3143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate offsets tuples in different columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3144,
   "metadata": {},
   "outputs": [],
   "source": [
    "mine[['startOffset', 'endOffset']] = pd.DataFrame(mine['offsets'].tolist(), index=mine.index) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3145,
   "metadata": {},
   "outputs": [],
   "source": [
    "mine = mine[['doc_id', 'texto_clean', 'tokens', 'abrev', 'startOffset', 'endOffset']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>texto_clean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>abrev</th>\n",
       "      <th>startOffset</th>\n",
       "      <th>endOffset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1130-05582012000300005-1</td>\n",
       "      <td>Acude consultas paciente presenta tumoracion c...</td>\n",
       "      <td>[Acude, consultas, paciente, presenta, tumorac...</td>\n",
       "      <td>RM</td>\n",
       "      <td>789</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1130-05582012000300005-1</td>\n",
       "      <td>Acude consultas paciente presenta tumoracion c...</td>\n",
       "      <td>[Acude, consultas, paciente, presenta, tumorac...</td>\n",
       "      <td>PAAF</td>\n",
       "      <td>1006</td>\n",
       "      <td>1010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0212-71992005000400009-1</td>\n",
       "      <td>Se trataba varon 27 anos edad habia sufrido ne...</td>\n",
       "      <td>[Se, trataba, varon, 27, anos, edad, habia, su...</td>\n",
       "      <td>mm</td>\n",
       "      <td>1056</td>\n",
       "      <td>1059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0212-71992005000400009-1</td>\n",
       "      <td>Se trataba varon 27 anos edad habia sufrido ne...</td>\n",
       "      <td>[Se, trataba, varon, 27, anos, edad, habia, su...</td>\n",
       "      <td>mm</td>\n",
       "      <td>1079</td>\n",
       "      <td>1082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0212-71992005000400009-1</td>\n",
       "      <td>Se trataba varon 27 anos edad habia sufrido ne...</td>\n",
       "      <td>[Se, trataba, varon, 27, anos, edad, habia, su...</td>\n",
       "      <td>mg</td>\n",
       "      <td>1247</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      doc_id  \\\n",
       "0  S1130-05582012000300005-1   \n",
       "0  S1130-05582012000300005-1   \n",
       "1  S0212-71992005000400009-1   \n",
       "1  S0212-71992005000400009-1   \n",
       "1  S0212-71992005000400009-1   \n",
       "\n",
       "                                         texto_clean  \\\n",
       "0  Acude consultas paciente presenta tumoracion c...   \n",
       "0  Acude consultas paciente presenta tumoracion c...   \n",
       "1  Se trataba varon 27 anos edad habia sufrido ne...   \n",
       "1  Se trataba varon 27 anos edad habia sufrido ne...   \n",
       "1  Se trataba varon 27 anos edad habia sufrido ne...   \n",
       "\n",
       "                                              tokens abrev  startOffset  \\\n",
       "0  [Acude, consultas, paciente, presenta, tumorac...    RM          789   \n",
       "0  [Acude, consultas, paciente, presenta, tumorac...  PAAF         1006   \n",
       "1  [Se, trataba, varon, 27, anos, edad, habia, su...    mm         1056   \n",
       "1  [Se, trataba, varon, 27, anos, edad, habia, su...    mm         1079   \n",
       "1  [Se, trataba, varon, 27, anos, edad, habia, su...    mg         1247   \n",
       "\n",
       "   endOffset  \n",
       "0        791  \n",
       "0       1010  \n",
       "1       1059  \n",
       "1       1082  \n",
       "1       1250  "
      ]
     },
     "execution_count": 3146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete null values, and change ttype to integer for offsets columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3183, 6)"
      ]
     },
     "execution_count": 3147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3148,
   "metadata": {},
   "outputs": [],
   "source": [
    "mine.dropna(subset=['startOffset', 'endOffset'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3183, 6)"
      ]
     },
     "execution_count": 3149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3150,
   "metadata": {},
   "outputs": [],
   "source": [
    "mine['startOffset'] = mine['startOffset'].astype(int)\n",
    "mine['endOffset'] = mine['endOffset'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3151,
   "metadata": {},
   "outputs": [],
   "source": [
    "mine = mine[['doc_id', 'texto_clean', 'tokens', 'abrev', 'startOffset', 'endOffset']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3183, 6)"
      ]
     },
     "execution_count": 3152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mine[mine.duplicated(subset=['doc_id', 'texto_clean', 'abrev', 'startOffset', 'endOffset'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3154,
   "metadata": {},
   "outputs": [],
   "source": [
    "mine = mine.drop_duplicates(subset = ['doc_id', 'texto_clean', 'abrev', 'startOffset', 'endOffset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3183, 6)"
      ]
     },
     "execution_count": 3155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>texto_clean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>abrev</th>\n",
       "      <th>startOffset</th>\n",
       "      <th>endOffset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1130-05582012000300005-1</td>\n",
       "      <td>Acude consultas paciente presenta tumoracion c...</td>\n",
       "      <td>[Acude, consultas, paciente, presenta, tumorac...</td>\n",
       "      <td>RM</td>\n",
       "      <td>789</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1130-05582012000300005-1</td>\n",
       "      <td>Acude consultas paciente presenta tumoracion c...</td>\n",
       "      <td>[Acude, consultas, paciente, presenta, tumorac...</td>\n",
       "      <td>PAAF</td>\n",
       "      <td>1006</td>\n",
       "      <td>1010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0212-71992005000400009-1</td>\n",
       "      <td>Se trataba varon 27 anos edad habia sufrido ne...</td>\n",
       "      <td>[Se, trataba, varon, 27, anos, edad, habia, su...</td>\n",
       "      <td>mm</td>\n",
       "      <td>1056</td>\n",
       "      <td>1059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0212-71992005000400009-1</td>\n",
       "      <td>Se trataba varon 27 anos edad habia sufrido ne...</td>\n",
       "      <td>[Se, trataba, varon, 27, anos, edad, habia, su...</td>\n",
       "      <td>mm</td>\n",
       "      <td>1079</td>\n",
       "      <td>1082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0212-71992005000400009-1</td>\n",
       "      <td>Se trataba varon 27 anos edad habia sufrido ne...</td>\n",
       "      <td>[Se, trataba, varon, 27, anos, edad, habia, su...</td>\n",
       "      <td>mg</td>\n",
       "      <td>1247</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      doc_id  \\\n",
       "0  S1130-05582012000300005-1   \n",
       "0  S1130-05582012000300005-1   \n",
       "1  S0212-71992005000400009-1   \n",
       "1  S0212-71992005000400009-1   \n",
       "1  S0212-71992005000400009-1   \n",
       "\n",
       "                                         texto_clean  \\\n",
       "0  Acude consultas paciente presenta tumoracion c...   \n",
       "0  Acude consultas paciente presenta tumoracion c...   \n",
       "1  Se trataba varon 27 anos edad habia sufrido ne...   \n",
       "1  Se trataba varon 27 anos edad habia sufrido ne...   \n",
       "1  Se trataba varon 27 anos edad habia sufrido ne...   \n",
       "\n",
       "                                              tokens abrev  startOffset  \\\n",
       "0  [Acude, consultas, paciente, presenta, tumorac...    RM          789   \n",
       "0  [Acude, consultas, paciente, presenta, tumorac...  PAAF         1006   \n",
       "1  [Se, trataba, varon, 27, anos, edad, habia, su...    mm         1056   \n",
       "1  [Se, trataba, varon, 27, anos, edad, habia, su...    mm         1079   \n",
       "1  [Se, trataba, varon, 27, anos, edad, habia, su...    mg         1247   \n",
       "\n",
       "   endOffset  \n",
       "0        791  \n",
       "0       1010  \n",
       "1       1059  \n",
       "1       1082  \n",
       "1       1250  "
      ]
     },
     "execution_count": 3156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mine['abrev'] = mine['abrev'].apply(lambda x: [a.split(\"/\") for a in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check dataframes for one text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mine[mine['doc_id'] == 'S1130-05582012000300005-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_abbr[train_abbr['doc_id'] == 'S1130-05582012000300005-1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Long Formns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Long Forms in the same text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**measurement units dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3160,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_dic = {\"ml\":\"mililitro\",\n",
    "\"mg\":\"miligramo\",\n",
    "\"g\":\"gramo\",\n",
    "\"l\":\"litro\",\n",
    "\"mcg\":\"microgramo\",\n",
    "\"mmol\":\"milimol\",\n",
    "\"ui\":\"Unidades Internacionales\",\n",
    "\"miles ui\":\"Miles de Unidades Internacionales\",\n",
    "\"millones ui\":\"Millones de Unidades Internacionales\",\n",
    "\"ufc\":\"Unidades Formadoras de Colonias\",\n",
    "\"meq\":\"miliequivalente\",\n",
    "\"ng\":\"manogramo\",\n",
    "\"lf\":\"Unidad Floculante\",\n",
    "\"ufp\":\"Unidad Formadora de Placa\",\n",
    "\"dic\":\"Dosis Infectante Mediana de Cultivo Celular 50% \",\n",
    "\"dit\":\"Dosis Infectante Mediana de Cultivo Tisular 50% \",\n",
    "\"di\":\"Dosis Infectante 50% \",\n",
    "\"mol\":\"Peso Molecular Gramo \",\n",
    "\"eq\":\"Peso Equivalente Gramo \",\n",
    "\"dosis\":\"Dosis\",\n",
    "\"almh\":\"Almohadilla\",\n",
    "\"amp\":\"Ampolla\",\n",
    "\"anl\":\"Anillo\",\n",
    "\"bar\":\"Barra\",\n",
    "\"bolsa\":\"Bolsa\",\n",
    "\"cap\":\"Capsula\",\n",
    "\"car\":\"Caramelo\",\n",
    "\"carp\":\"Carpula\",\n",
    "\"cart\":\"Cartucho\",\n",
    "\"com\":\"Comprimido\",\n",
    "\"dia\":\"Dia\",\n",
    "\"fras\":\"Frasco\",\n",
    "\"fras-amp\":\"Frasco Ampolla \",\n",
    "\"grag\":\"Gragea\",\n",
    "\"gora\":\"Hora\",\n",
    "\"gmp\":\"Implante\",\n",
    "\"jab\":\"Jab¢n\",\n",
    "\"jer\":\"Jeringa Prellenada \",\n",
    "\"uL\":\"Microlitro\",\n",
    "\"ovu\":\"Ovulo\",\n",
    "\"parche\":\"Parche\",\n",
    "\"past\":\"Pastilla\",\n",
    "\"perl\":\"Perla\",\n",
    "\"pil\":\"Pildora\",\n",
    "\"pip\":\"Pipeta\",\n",
    "\"%\":\"Porcentaje\",\n",
    "\"sach\":\"Sachet\",\n",
    "\"sob\":\"Sobre\",\n",
    "\"sup\":\"Supositorio\",\n",
    "\"tab\":\"Tableta\",\n",
    "\"troc\":\"Trocisco\",\n",
    "\"vial\":\"Vial\",\n",
    "\"kg\":\"Kilogramo\",\n",
    "\"gal\":\"Galon\",\n",
    "\"sis\":\"Sistema Terapeutico\",\n",
    "\"mci\":\"miliCuries\",\n",
    "\"mbq\":\"milibequerel\",\n",
    "\"uel\":\"Unidades ELISA \",\n",
    "\"dl\":\"Dosis Letal\",\n",
    "\"u usp\":\"Unidades USP \",\n",
    "\"u\":\"Unidades\",\n",
    "\"rot\":\"Rotacaps\",\n",
    "\"ccid\":\"Dosis Infecciosa en Cultivo de Célula \",\n",
    "\"U\":\"UNIDAD\",\n",
    "\"otros\":\"Otros\",\n",
    "\"µci\":\"mcroCuries\",\n",
    "\"esp\":\"Esporas\",\n",
    "\"mcha\":\"microgramos de HA \",\n",
    "\"gom\":\"Goma\",\n",
    "\"kiu\":\"Unidad Inhibidora de Calicreina \",\n",
    "\"mcel\":\"Millones de Células \",\n",
    "\"du\":\"Unidades de Antigeno D\",\n",
    "\"dil d2\":\"Dil D2\",\n",
    "\"tin.mad.\":\"Tintura Madre\",\n",
    "\"dil d4\":\"Dil D4\",\n",
    "\"dil d5\":\"Dil D5\",\n",
    "\"dil d1\":\"Dil D1\",\n",
    "\"dil d8\":\"Dil D8\",\n",
    "\"dil d3\":\"Dil D3\",\n",
    "\"ou\":\"Unidad de Opacidad \",\n",
    "\"mm\": \"milimetro\",\n",
    "\"dm\": \"decimetro\",\n",
    "\"cm\": \"centimetro\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3161,
   "metadata": {},
   "outputs": [],
   "source": [
    "mine['long_form'] = mine['abrev'].str.lower().map(mu_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mine[mine['doc_id'] == 'S0212-71992005000400009-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>texto_clean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>abrev</th>\n",
       "      <th>startOffset</th>\n",
       "      <th>endOffset</th>\n",
       "      <th>long_form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1130-05582012000300005-1</td>\n",
       "      <td>Acude consultas paciente presenta tumoracion c...</td>\n",
       "      <td>[Acude, consultas, paciente, presenta, tumorac...</td>\n",
       "      <td>RM</td>\n",
       "      <td>789</td>\n",
       "      <td>791</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1130-05582012000300005-1</td>\n",
       "      <td>Acude consultas paciente presenta tumoracion c...</td>\n",
       "      <td>[Acude, consultas, paciente, presenta, tumorac...</td>\n",
       "      <td>PAAF</td>\n",
       "      <td>1006</td>\n",
       "      <td>1010</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0212-71992005000400009-1</td>\n",
       "      <td>Se trataba varon 27 anos edad habia sufrido ne...</td>\n",
       "      <td>[Se, trataba, varon, 27, anos, edad, habia, su...</td>\n",
       "      <td>mm</td>\n",
       "      <td>1056</td>\n",
       "      <td>1059</td>\n",
       "      <td>milimetro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0212-71992005000400009-1</td>\n",
       "      <td>Se trataba varon 27 anos edad habia sufrido ne...</td>\n",
       "      <td>[Se, trataba, varon, 27, anos, edad, habia, su...</td>\n",
       "      <td>mm</td>\n",
       "      <td>1079</td>\n",
       "      <td>1082</td>\n",
       "      <td>milimetro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0212-71992005000400009-1</td>\n",
       "      <td>Se trataba varon 27 anos edad habia sufrido ne...</td>\n",
       "      <td>[Se, trataba, varon, 27, anos, edad, habia, su...</td>\n",
       "      <td>mg</td>\n",
       "      <td>1247</td>\n",
       "      <td>1250</td>\n",
       "      <td>miligramo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      doc_id  \\\n",
       "0  S1130-05582012000300005-1   \n",
       "0  S1130-05582012000300005-1   \n",
       "1  S0212-71992005000400009-1   \n",
       "1  S0212-71992005000400009-1   \n",
       "1  S0212-71992005000400009-1   \n",
       "\n",
       "                                         texto_clean  \\\n",
       "0  Acude consultas paciente presenta tumoracion c...   \n",
       "0  Acude consultas paciente presenta tumoracion c...   \n",
       "1  Se trataba varon 27 anos edad habia sufrido ne...   \n",
       "1  Se trataba varon 27 anos edad habia sufrido ne...   \n",
       "1  Se trataba varon 27 anos edad habia sufrido ne...   \n",
       "\n",
       "                                              tokens abrev  startOffset  \\\n",
       "0  [Acude, consultas, paciente, presenta, tumorac...    RM          789   \n",
       "0  [Acude, consultas, paciente, presenta, tumorac...  PAAF         1006   \n",
       "1  [Se, trataba, varon, 27, anos, edad, habia, su...    mm         1056   \n",
       "1  [Se, trataba, varon, 27, anos, edad, habia, su...    mm         1079   \n",
       "1  [Se, trataba, varon, 27, anos, edad, habia, su...    mg         1247   \n",
       "\n",
       "   endOffset  long_form  \n",
       "0        791        NaN  \n",
       "0       1010        NaN  \n",
       "1       1059  milimetro  \n",
       "1       1082  milimetro  \n",
       "1       1250  miligramo  "
      ]
     },
     "execution_count": 3163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mine_lf = mine[mine['abrev'].str.len() > 1].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get LF before SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mine[mine['doc_id'] == 'S0004-06142005000900013-1'].iloc[0]['tokens']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With get_longform function, words befores SF that starts with SF letters will be detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_longform(tokens, acro, long):\n",
    "    #acro = acro.lower()\n",
    "    long_form = ''\n",
    "    margin = 2\n",
    "    i =0\n",
    "    #Looking for before\n",
    "    if pd.isna(long):\n",
    "        if acro not in tokens:\n",
    "            return -1\n",
    "        else:\n",
    "            index = tokens.index(acro)\n",
    "            for word in tokens[index-margin-len(acro):index]:\n",
    "                #if first letter of word is equal to first letter os acronym\n",
    "                if word[0] == acro[i].lower():\n",
    "                    long_form += word + ' '\n",
    "                    i += 1\n",
    "                    if i == len(acro):\n",
    "                        break\n",
    "                elif (i == 1) and (word[0] == acro[i-1].lower()):\n",
    "                    long_form = word + ' '\n",
    "                    i = 1\n",
    "                    if i == len(acro):\n",
    "                        break\n",
    "            long_form = long_form.rstrip()\n",
    "            #print(re.split(' |-',long_form), len(re.split(' |-',long_form)), len(acro)-1)\n",
    "            if len(re.split(' |-',long_form)) == (len(acro)):\n",
    "                return long_form\n",
    "            elif ((len(re.split(' |-',long_form))+1) == (len(acro))) & (len(re.split(' |-',long_form)) > 1):\n",
    "                return long_form\n",
    "    else:\n",
    "        return long\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_longform_after(tokens, acro, long):\n",
    "    #acro = acro.lower()\n",
    "    long_form = ''\n",
    "    margin = 2\n",
    "    i =0\n",
    "    #Looking for before\n",
    "    if pd.isna(long):\n",
    "        if acro not in tokens:\n",
    "            return -1\n",
    "        else:\n",
    "            index = tokens.index(acro)\n",
    "            for word in tokens[index+1:index+margin+len(acro)]:\n",
    "#                 if tokens[index+1] == '(':\n",
    "#                     print\n",
    "                if word[0] in acro.lower():\n",
    "                    long_form += word + ' '\n",
    "        long_form = long_form.rstrip()\n",
    "        if len(re.split(' |-',long_form)) == (len(acro)):\n",
    "            return long_form\n",
    "        elif ((len(re.split(' |-',long_form))+1) == (len(acro))) & (len(re.split(' |-',long_form)) > 1):\n",
    "            return long_form\n",
    "    else:\n",
    "        return long\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = mine[mine['doc_id'] == 'S0376-78922016000200011-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a.iloc[0]['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a.apply(lambda row: get_longform_after(row['tokens'], row['abrev'], row['long_form']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mine[mine['doc_id'] == 'S1137-66272013000200023-1'].apply(lambda row: get_longform(row['tokens'], row['abrev'], row['long_form']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mine['long_form'] = mine.apply(lambda row: get_longform(row['tokens'], row['abrev'], row['long_form']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3173,
   "metadata": {},
   "outputs": [],
   "source": [
    "mine['long_form'] = mine.apply(lambda row: get_longform_after(row['tokens'], row['abrev'], row['long_form']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>texto_clean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>abrev</th>\n",
       "      <th>startOffset</th>\n",
       "      <th>endOffset</th>\n",
       "      <th>long_form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1130-05582012000300005-1</td>\n",
       "      <td>Acude consultas paciente presenta tumoracion c...</td>\n",
       "      <td>[Acude, consultas, paciente, presenta, tumorac...</td>\n",
       "      <td>RM</td>\n",
       "      <td>789</td>\n",
       "      <td>791</td>\n",
       "      <td>resonancia magnetica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1130-05582012000300005-1</td>\n",
       "      <td>Acude consultas paciente presenta tumoracion c...</td>\n",
       "      <td>[Acude, consultas, paciente, presenta, tumorac...</td>\n",
       "      <td>PAAF</td>\n",
       "      <td>1006</td>\n",
       "      <td>1010</td>\n",
       "      <td>puncion aspiracion aguja fina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0212-71992005000400009-1</td>\n",
       "      <td>Se trataba varon 27 anos edad habia sufrido ne...</td>\n",
       "      <td>[Se, trataba, varon, 27, anos, edad, habia, su...</td>\n",
       "      <td>mm</td>\n",
       "      <td>1056</td>\n",
       "      <td>1059</td>\n",
       "      <td>milimetro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0212-71992005000400009-1</td>\n",
       "      <td>Se trataba varon 27 anos edad habia sufrido ne...</td>\n",
       "      <td>[Se, trataba, varon, 27, anos, edad, habia, su...</td>\n",
       "      <td>mm</td>\n",
       "      <td>1079</td>\n",
       "      <td>1082</td>\n",
       "      <td>milimetro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0212-71992005000400009-1</td>\n",
       "      <td>Se trataba varon 27 anos edad habia sufrido ne...</td>\n",
       "      <td>[Se, trataba, varon, 27, anos, edad, habia, su...</td>\n",
       "      <td>mg</td>\n",
       "      <td>1247</td>\n",
       "      <td>1250</td>\n",
       "      <td>miligramo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      doc_id  \\\n",
       "0  S1130-05582012000300005-1   \n",
       "0  S1130-05582012000300005-1   \n",
       "1  S0212-71992005000400009-1   \n",
       "1  S0212-71992005000400009-1   \n",
       "1  S0212-71992005000400009-1   \n",
       "\n",
       "                                         texto_clean  \\\n",
       "0  Acude consultas paciente presenta tumoracion c...   \n",
       "0  Acude consultas paciente presenta tumoracion c...   \n",
       "1  Se trataba varon 27 anos edad habia sufrido ne...   \n",
       "1  Se trataba varon 27 anos edad habia sufrido ne...   \n",
       "1  Se trataba varon 27 anos edad habia sufrido ne...   \n",
       "\n",
       "                                              tokens abrev  startOffset  \\\n",
       "0  [Acude, consultas, paciente, presenta, tumorac...    RM          789   \n",
       "0  [Acude, consultas, paciente, presenta, tumorac...  PAAF         1006   \n",
       "1  [Se, trataba, varon, 27, anos, edad, habia, su...    mm         1056   \n",
       "1  [Se, trataba, varon, 27, anos, edad, habia, su...    mm         1079   \n",
       "1  [Se, trataba, varon, 27, anos, edad, habia, su...    mg         1247   \n",
       "\n",
       "   endOffset                      long_form  \n",
       "0        791           resonancia magnetica  \n",
       "0       1010  puncion aspiracion aguja fina  \n",
       "1       1059                      milimetro  \n",
       "1       1082                      milimetro  \n",
       "1       1250                      miligramo  "
      ]
     },
     "execution_count": 3174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mine[mine['doc_id'] == 'S1130-05582012000300005-1'].iloc[0]['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3183, 7)"
      ]
     },
     "execution_count": 3176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mine.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of SF and LF in tetxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Short Forms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "695"
      ]
     },
     "execution_count": 3177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mine['abrev'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3178,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mine['abrev'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete rows with SF that are just numbers or number + letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['g', '5U', '70', 'f', 'q', '24', '10', 'h', 'd', 'u', 'l', '1a',\n",
       "       '8h', '45', '90', '80', '67', 'm', '13', '07', '12', '7g', '16',\n",
       "       '34', 'm2', '68', '50', 'i', '20', '83', '4g', '88', '09', '05',\n",
       "       '85', '31', '60', '1b', '40', '71', '32', '76', '15', '3g', '74',\n",
       "       '02', '18', '75', 'C4', '99', '03', '11', '1g', '01', '26', '23',\n",
       "       '08'], dtype=object)"
      ]
     },
     "execution_count": 3180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mine[(mine['abrev'].str.len() <= 2) & (~mine['abrev'].str.isalpha())| (mine['abrev'].str.len() == 1)]['abrev'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3183, 7)"
      ]
     },
     "execution_count": 3181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3020, 7)"
      ]
     },
     "execution_count": 3182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mine[~((mine['abrev'].str.len() <= 2) & (~mine['abrev'].str.isalpha())| (mine['abrev'].str.len() == 1))].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3183,
   "metadata": {},
   "outputs": [],
   "source": [
    "mine = mine[~((mine['abrev'].str.len() <= 2) & (~mine['abrev'].str.isalpha())| (mine['abrev'].str.len() == 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mine['abrev'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Long Forms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 3185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mine['long_form'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mine['long_form'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study -1 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228, 7)"
      ]
     },
     "execution_count": 3187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mine[mine['long_form'] == -1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 3188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mine[mine['long_form'] == -1]['abrev'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete blank space from some letter in SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mine[mine['long_form'] == '']['abrev'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mine[mine['long_form'] == ''].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mine = mine[mine['long_form'] != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Study LF founded or not founded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study SF without LF in the running text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228, 7)"
      ]
     },
     "execution_count": 3192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mine[mine['long_form'] == -1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1437, 7)"
      ]
     },
     "execution_count": 3193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mine[mine['long_form'].isnull()].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how many texts don't have LF for the SF in the same text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1437, 7)"
      ]
     },
     "execution_count": 3194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mine[(mine['abrev'].notnull()) & (mine['long_form'].isnull())].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1437"
      ]
     },
     "execution_count": 3195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lf_null = mine[(mine['abrev'].notnull()) & (mine['long_form'].isnull())].shape[0]\n",
    "lf_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LF has not be found in the same text where the SF is in  47.58% of texts\n"
     ]
    }
   ],
   "source": [
    "print(f\"LF has not be found in the same text where the SF is in {lf_null/mine.shape[0]*100: .2f}% of texts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468"
      ]
     },
     "execution_count": 3197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mine[mine['long_form'].isnull()]['abrev'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AA',\n",
       " 'AAS',\n",
       " 'AB',\n",
       " 'ABI',\n",
       " 'ABVD',\n",
       " 'ACCS',\n",
       " 'ADA',\n",
       " 'ADR',\n",
       " 'AE',\n",
       " 'AFG',\n",
       " 'AFP',\n",
       " 'AGF',\n",
       " 'AI',\n",
       " 'AINES',\n",
       " 'AL',\n",
       " 'ALAT',\n",
       " 'ALK',\n",
       " 'ALP',\n",
       " 'ALT',\n",
       " 'AMA',\n",
       " 'ANA',\n",
       " 'ANAS',\n",
       " 'ANCA',\n",
       " 'ANCAS',\n",
       " 'AOC',\n",
       " 'AP',\n",
       " 'AR',\n",
       " 'ASAT',\n",
       " 'ASIA',\n",
       " 'ASLO',\n",
       " 'ASPEN',\n",
       " 'AST',\n",
       " 'AT',\n",
       " 'ATA',\n",
       " 'ATS',\n",
       " 'AUC',\n",
       " 'AV',\n",
       " 'AVK',\n",
       " 'AVSC',\n",
       " 'BAAR',\n",
       " 'BACTEC',\n",
       " 'BAL',\n",
       " 'BAS',\n",
       " 'BAV',\n",
       " 'BCG',\n",
       " 'BD',\n",
       " 'BEP',\n",
       " 'BH',\n",
       " 'BIODISK',\n",
       " 'BMC',\n",
       " 'BMU',\n",
       " 'BP',\n",
       " 'BPA',\n",
       " 'BQ',\n",
       " 'BT',\n",
       " 'BUN',\n",
       " 'CA',\n",
       " 'CBMF',\n",
       " 'CCR',\n",
       " 'CD',\n",
       " 'CDDP',\n",
       " 'CEA',\n",
       " 'CEC',\n",
       " 'CHCM',\n",
       " 'CHOP',\n",
       " 'CK',\n",
       " 'CKPAN',\n",
       " 'CMHG',\n",
       " 'CMI',\n",
       " 'CMV',\n",
       " 'CO',\n",
       " 'COL',\n",
       " 'COPP',\n",
       " 'CPAP',\n",
       " 'CPK',\n",
       " 'CRE',\n",
       " 'CT',\n",
       " 'CTX',\n",
       " 'CU',\n",
       " 'CV',\n",
       " 'CX',\n",
       " 'CellCe',\n",
       " 'DAI',\n",
       " 'DAKO',\n",
       " 'DFVA',\n",
       " 'DG',\n",
       " 'DHAP',\n",
       " 'DIEP',\n",
       " 'DII',\n",
       " 'DIII',\n",
       " 'DMNID',\n",
       " 'DR',\n",
       " 'DTIC',\n",
       " 'EA',\n",
       " 'EB',\n",
       " 'EBHGA',\n",
       " 'EC',\n",
       " 'ECA',\n",
       " 'ECE',\n",
       " 'ECG',\n",
       " 'ECO',\n",
       " 'ECOT',\n",
       " 'ECS',\n",
       " 'EE',\n",
       " 'EEG',\n",
       " 'EEII',\n",
       " 'EGO',\n",
       " 'EIA',\n",
       " 'EIAI',\n",
       " 'EID',\n",
       " 'EII',\n",
       " 'EKG',\n",
       " 'ELA',\n",
       " 'ELISA',\n",
       " 'EMA',\n",
       " 'EMG',\n",
       " 'EMLA',\n",
       " 'ENA',\n",
       " 'ENG',\n",
       " 'EPOC',\n",
       " 'EPPMA',\n",
       " 'EPR',\n",
       " 'ERCP',\n",
       " 'ESCHAP',\n",
       " 'ESWL',\n",
       " 'EVA',\n",
       " 'FA',\n",
       " 'FAB',\n",
       " 'FACTOR',\n",
       " 'FAL',\n",
       " 'FC',\n",
       " 'FFAA',\n",
       " 'FG',\n",
       " 'FID',\n",
       " 'FL',\n",
       " 'FMP',\n",
       " 'FO',\n",
       " 'FOA',\n",
       " 'FOLFOX',\n",
       " 'FP',\n",
       " 'FR',\n",
       " 'FSH',\n",
       " 'FTP',\n",
       " 'FU',\n",
       " 'FVC',\n",
       " 'GANT',\n",
       " 'GASA',\n",
       " 'GCCA',\n",
       " 'GCS',\n",
       " 'GDC',\n",
       " 'GEFS',\n",
       " 'GEP',\n",
       " 'GER',\n",
       " 'GFAP',\n",
       " 'GGT',\n",
       " 'GIST',\n",
       " 'GLA',\n",
       " 'GOT',\n",
       " 'GPT',\n",
       " 'GRP',\n",
       " 'GT',\n",
       " 'Gy',\n",
       " 'HBPM',\n",
       " 'HC',\n",
       " 'HCG',\n",
       " 'HCM',\n",
       " 'HCT',\n",
       " 'HDA',\n",
       " 'HDF',\n",
       " 'HDFVVC',\n",
       " 'HDL',\n",
       " 'HEA',\n",
       " 'HGO',\n",
       " 'HIT',\n",
       " 'HIV',\n",
       " 'HLA',\n",
       " 'HMB',\n",
       " 'HPB',\n",
       " 'HPC',\n",
       " 'HPTS',\n",
       " 'HPV',\n",
       " 'HSD',\n",
       " 'HTA',\n",
       " 'HTBI',\n",
       " 'HTLV',\n",
       " 'HUCA',\n",
       " 'HV',\n",
       " 'HVS',\n",
       " 'IAM',\n",
       " 'IC',\n",
       " 'ICG',\n",
       " 'ID',\n",
       " 'IED',\n",
       " 'IF',\n",
       " 'IFN',\n",
       " 'IFOVM',\n",
       " 'IHQ',\n",
       " 'IIIC',\n",
       " 'IL',\n",
       " 'IMC',\n",
       " 'INF',\n",
       " 'INR',\n",
       " 'INSS',\n",
       " 'INTCF',\n",
       " 'IR',\n",
       " 'IRC',\n",
       " 'ITI',\n",
       " 'IV',\n",
       " 'IgA',\n",
       " 'IgE',\n",
       " 'IgG',\n",
       " 'IgG4',\n",
       " 'IgM',\n",
       " 'IgS',\n",
       " 'JMY',\n",
       " 'KDOQI',\n",
       " 'KIT',\n",
       " 'KT',\n",
       " 'Kt',\n",
       " 'LACG',\n",
       " 'LCCT',\n",
       " 'LCG',\n",
       " 'LCR',\n",
       " 'LCT',\n",
       " 'LDH',\n",
       " 'LDL',\n",
       " 'LES',\n",
       " 'LH',\n",
       " 'LHRH',\n",
       " 'LII',\n",
       " 'LISOZIMA',\n",
       " 'LKM',\n",
       " 'LLBCP',\n",
       " 'LLE',\n",
       " 'LLI',\n",
       " 'LM',\n",
       " 'LNH',\n",
       " 'LOE',\n",
       " 'LSD',\n",
       " 'LSI',\n",
       " 'LTSV',\n",
       " 'MARS',\n",
       " 'MARSA',\n",
       " 'MAV',\n",
       " 'MAVC',\n",
       " 'MAVD',\n",
       " 'MCT',\n",
       " 'MDP',\n",
       " 'MELAN',\n",
       " 'MESNA',\n",
       " 'MGIT',\n",
       " 'MIB',\n",
       " 'MIBI',\n",
       " 'MMC',\n",
       " 'MMII',\n",
       " 'MOPP',\n",
       " 'MPX',\n",
       " 'MTCF',\n",
       " 'MTS',\n",
       " 'MTT',\n",
       " 'McConkey',\n",
       " 'McGhan',\n",
       " 'MhZ',\n",
       " 'NATO',\n",
       " 'NE',\n",
       " 'NED',\n",
       " 'NIHSS',\n",
       " 'NJ',\n",
       " 'NM',\n",
       " 'NO',\n",
       " 'NPD',\n",
       " 'NPH',\n",
       " 'NPT',\n",
       " 'NVC',\n",
       " 'NYHA',\n",
       " 'OCT',\n",
       " 'OD',\n",
       " 'OI',\n",
       " 'OMIM',\n",
       " 'OMS',\n",
       " 'ONCE',\n",
       " 'ORL',\n",
       " 'ORN',\n",
       " 'ORTHOPAT',\n",
       " 'PA',\n",
       " 'PAAF',\n",
       " 'PARA',\n",
       " 'PAS',\n",
       " 'PCA',\n",
       " 'PCP',\n",
       " 'PCR',\n",
       " 'PCT',\n",
       " 'PEEP',\n",
       " 'PEES',\n",
       " 'PEF',\n",
       " 'PEG',\n",
       " 'PET',\n",
       " 'PIO',\n",
       " 'PLE',\n",
       " 'PLGA',\n",
       " 'PLQ',\n",
       " 'PMN',\n",
       " 'PNJ',\n",
       " 'PO',\n",
       " 'POSITIVO',\n",
       " 'PQ',\n",
       " 'PR',\n",
       " 'PRC',\n",
       " 'PRISM',\n",
       " 'PSA',\n",
       " 'PTH',\n",
       " 'PVC',\n",
       " 'PXE',\n",
       " 'PaGIA',\n",
       " 'QA',\n",
       " 'QG',\n",
       " 'QM',\n",
       " 'QRS',\n",
       " 'QT',\n",
       " 'QUP',\n",
       " 'RBV',\n",
       " 'RCP',\n",
       " 'RD',\n",
       " 'RDW',\n",
       " 'RF',\n",
       " 'RH',\n",
       " 'RM',\n",
       " 'RMN',\n",
       " 'RN',\n",
       " 'RNA',\n",
       " 'RNM',\n",
       " 'RNP',\n",
       " 'ROLE',\n",
       " 'RPMB',\n",
       " 'RPR',\n",
       " 'RT',\n",
       " 'RTU',\n",
       " 'RVS',\n",
       " 'RX',\n",
       " 'SA',\n",
       " 'SC',\n",
       " 'SCACEST',\n",
       " 'SDMO',\n",
       " 'SDRC',\n",
       " 'SHOP',\n",
       " 'SHR',\n",
       " 'SL',\n",
       " 'SLA',\n",
       " 'SMR',\n",
       " 'SNC',\n",
       " 'SNG',\n",
       " 'SPM',\n",
       " 'SPRL',\n",
       " 'SS',\n",
       " 'ST',\n",
       " 'STH',\n",
       " 'STIR',\n",
       " 'STS',\n",
       " 'SaO2',\n",
       " 'SatO2',\n",
       " 'TA',\n",
       " 'TAC',\n",
       " 'TACHT',\n",
       " 'TAD',\n",
       " 'TANITA',\n",
       " 'TAP',\n",
       " 'TAS',\n",
       " 'TB',\n",
       " 'TBC',\n",
       " 'TC',\n",
       " 'TCE',\n",
       " 'TD',\n",
       " 'TENS',\n",
       " 'TEP',\n",
       " 'TG',\n",
       " 'TGB',\n",
       " 'TGO',\n",
       " 'TGP',\n",
       " 'TIC',\n",
       " 'TORCH',\n",
       " 'TP',\n",
       " 'TPMT',\n",
       " 'TPO',\n",
       " 'TR',\n",
       " 'TRIAX',\n",
       " 'TSH',\n",
       " 'TTF',\n",
       " 'TTP',\n",
       " 'TTPA',\n",
       " 'TV',\n",
       " 'TVP',\n",
       " 'TVTLF',\n",
       " 'TdT',\n",
       " 'UCI',\n",
       " 'UCIP',\n",
       " 'UH',\n",
       " 'UICC',\n",
       " 'UIV',\n",
       " 'UL',\n",
       " 'UMI',\n",
       " 'UMO',\n",
       " 'UU',\n",
       " 'Ul',\n",
       " 'VAC',\n",
       " 'VCM',\n",
       " 'VEB',\n",
       " 'VHA',\n",
       " 'VHB',\n",
       " 'VHC',\n",
       " 'VHS',\n",
       " 'VIA',\n",
       " 'VIH',\n",
       " 'VM',\n",
       " 'VMNI',\n",
       " 'VN',\n",
       " 'VSG',\n",
       " 'VVZ',\n",
       " 'XI',\n",
       " 'XII',\n",
       " 'XY',\n",
       " 'YAG',\n",
       " 'YSS',\n",
       " 'ZFY',\n",
       " 'ZN',\n",
       " 'ZZ',\n",
       " 'aFP',\n",
       " 'aVF',\n",
       " 'ac',\n",
       " 'ad',\n",
       " 'antiDNA',\n",
       " 'antiRNA',\n",
       " 'cGy',\n",
       " 'cN2',\n",
       " 'cc',\n",
       " 'cp',\n",
       " 'da',\n",
       " 'et',\n",
       " 'gGT',\n",
       " 'gr',\n",
       " 'iPTH',\n",
       " 'in',\n",
       " 'iv',\n",
       " 'kU',\n",
       " 'lt',\n",
       " 'mFOLFOX',\n",
       " 'mU',\n",
       " 'mUI',\n",
       " 'mV',\n",
       " 'mW',\n",
       " 'mmHg',\n",
       " 'oC',\n",
       " 'of',\n",
       " 'pCO2',\n",
       " 'pH',\n",
       " 'pO2',\n",
       " 'pT1',\n",
       " 'pT2',\n",
       " 'pTa',\n",
       " 'pTaG1',\n",
       " 'pTis',\n",
       " 'pg',\n",
       " 'rDNA',\n",
       " 'sY134',\n",
       " 'si',\n",
       " 'uL',\n",
       " 'ug',\n",
       " 'ul',\n",
       " 'va']"
      ]
     },
     "execution_count": 3198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(mine[mine['long_form'].isnull()]['abrev'].unique().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dictionary with SF and LF pairs founded in the same text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3199,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pairs = mine[(mine['abrev'].notnull()) & (mine['long_form'].notnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3200,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pairs.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>texto_clean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>abrev</th>\n",
       "      <th>startOffset</th>\n",
       "      <th>endOffset</th>\n",
       "      <th>long_form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1130-05582012000300005-1</td>\n",
       "      <td>Acude consultas paciente presenta tumoracion c...</td>\n",
       "      <td>[Acude, consultas, paciente, presenta, tumorac...</td>\n",
       "      <td>RM</td>\n",
       "      <td>789</td>\n",
       "      <td>791</td>\n",
       "      <td>resonancia magnetica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1130-05582012000300005-1</td>\n",
       "      <td>Acude consultas paciente presenta tumoracion c...</td>\n",
       "      <td>[Acude, consultas, paciente, presenta, tumorac...</td>\n",
       "      <td>PAAF</td>\n",
       "      <td>1006</td>\n",
       "      <td>1010</td>\n",
       "      <td>puncion aspiracion aguja fina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0212-71992005000400009-1</td>\n",
       "      <td>Se trataba varon 27 anos edad habia sufrido ne...</td>\n",
       "      <td>[Se, trataba, varon, 27, anos, edad, habia, su...</td>\n",
       "      <td>mm</td>\n",
       "      <td>1056</td>\n",
       "      <td>1059</td>\n",
       "      <td>milimetro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0212-71992005000400009-1</td>\n",
       "      <td>Se trataba varon 27 anos edad habia sufrido ne...</td>\n",
       "      <td>[Se, trataba, varon, 27, anos, edad, habia, su...</td>\n",
       "      <td>mm</td>\n",
       "      <td>1079</td>\n",
       "      <td>1082</td>\n",
       "      <td>milimetro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0212-71992005000400009-1</td>\n",
       "      <td>Se trataba varon 27 anos edad habia sufrido ne...</td>\n",
       "      <td>[Se, trataba, varon, 27, anos, edad, habia, su...</td>\n",
       "      <td>mg</td>\n",
       "      <td>1247</td>\n",
       "      <td>1250</td>\n",
       "      <td>miligramo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      doc_id  \\\n",
       "0  S1130-05582012000300005-1   \n",
       "1  S1130-05582012000300005-1   \n",
       "2  S0212-71992005000400009-1   \n",
       "3  S0212-71992005000400009-1   \n",
       "4  S0212-71992005000400009-1   \n",
       "\n",
       "                                         texto_clean  \\\n",
       "0  Acude consultas paciente presenta tumoracion c...   \n",
       "1  Acude consultas paciente presenta tumoracion c...   \n",
       "2  Se trataba varon 27 anos edad habia sufrido ne...   \n",
       "3  Se trataba varon 27 anos edad habia sufrido ne...   \n",
       "4  Se trataba varon 27 anos edad habia sufrido ne...   \n",
       "\n",
       "                                              tokens abrev  startOffset  \\\n",
       "0  [Acude, consultas, paciente, presenta, tumorac...    RM          789   \n",
       "1  [Acude, consultas, paciente, presenta, tumorac...  PAAF         1006   \n",
       "2  [Se, trataba, varon, 27, anos, edad, habia, su...    mm         1056   \n",
       "3  [Se, trataba, varon, 27, anos, edad, habia, su...    mm         1079   \n",
       "4  [Se, trataba, varon, 27, anos, edad, habia, su...    mg         1247   \n",
       "\n",
       "   endOffset                      long_form  \n",
       "0        791           resonancia magnetica  \n",
       "1       1010  puncion aspiracion aguja fina  \n",
       "2       1059                      milimetro  \n",
       "3       1082                      milimetro  \n",
       "4       1250                      miligramo  "
      ]
     },
     "execution_count": 3201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3202,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_dic = {}\n",
    "for index, row in df_pairs.iterrows():\n",
    "    if (row['long_form'] != -1) & (row['long_form'] != None):\n",
    "        if not row['abrev'] in pairs_dic:\n",
    "            pairs_dic[row['abrev']] = set()\n",
    "        pairs_dic[row['abrev']].add(row['long_form'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RM': {'mostrando region', 'resonancia magnetica'},\n",
       " 'PAAF': {'puncion aspiracion aguja fina'},\n",
       " 'mm': {'milimetro'},\n",
       " 'mg': {'miligramo'},\n",
       " 'UI': {'Unidades Internacionales'},\n",
       " 'VIH': {'virus hepatitis'},\n",
       " 'kg': {'Kilogramo'},\n",
       " 'dl': {'Dosis Letal'},\n",
       " 'TAC': {'abdominal confirmandose trombosis',\n",
       "  'abdominal tumor',\n",
       "  'abdominales ascitis',\n",
       "  'abdomino confirmaron',\n",
       "  'abdomino confirmo',\n",
       "  'abdomino contraste',\n",
       "  'apreciar adyacente',\n",
       "  'aumento atenuacion',\n",
       "  'axial computerizada abdominal',\n",
       "  'cervical abdominopelvico',\n",
       "  'columna abdominal',\n",
       "  'contrastada confirmaron',\n",
       "  'contraste tejido',\n",
       "  'cortes axiales craneocaudales',\n",
       "  'craneal aprecian anormalidades',\n",
       "  'craneal contraste',\n",
       "  'craneal toracico abdominal',\n",
       "  'tomografia axial computadorizada',\n",
       "  'tomografia axial computarizada',\n",
       "  'tomografia axial computerizada',\n",
       "  'toracica afectacion',\n",
       "  'toracico abdominal',\n",
       "  'toraco abdominal',\n",
       "  'toraco abdomino'},\n",
       " 'ng': {'manogramo'},\n",
       " 'APC': {'argon plasma'},\n",
       " 'ml': {'mililitro'},\n",
       " 'cm': {'centimetro'},\n",
       " 'AP': {'acude primaria', 'parte amiloide'},\n",
       " 'dL': {'Dosis Letal'},\n",
       " 'TC': {'columna correspondia',\n",
       "  'correctamente caso',\n",
       "  'cortes coronales',\n",
       "  'craneal tercer',\n",
       "  'tomografia computadorizada',\n",
       "  'tomografia computarizada',\n",
       "  'tomografia computerizada',\n",
       "  'torax confirmo'},\n",
       " 'AVF': {'falta activacion vector'},\n",
       " 'TBF': {'traves bioelectrica'},\n",
       " 'LDH': {'datos hepatica deterioro'},\n",
       " 'mEq': {'miliequivalente'},\n",
       " 'RMN': {'masa nodular', 'resonancia magnetica nuclear'},\n",
       " 'DM': {'decimetro'},\n",
       " 'HTA': {'artrosis adenoma', 'hipotiroidismo tratamiento'},\n",
       " 'LLA': {'llega leucemia aguda'},\n",
       " 'OTFC': {'citrato fentanilo oral transmucosa'},\n",
       " 'FO': {'fondo ojo'},\n",
       " 'PIO': {'presion intraocular'},\n",
       " 'CD': {'citoplasma claro', 'coronaria derecha'},\n",
       " 'mL': {'mililitro'},\n",
       " 'CDI': {'complicada distension'},\n",
       " 'AEO': {'aparatologia extraoral'},\n",
       " 'EVA': {'enfermo variable', 'escala visual analogica'},\n",
       " 'HSA': {'herniacion supracallosa'},\n",
       " 'IMC': {'indice masa corporal', 'm2 ingreso', 'minimos miembros'},\n",
       " 'TCS': {'tejido celular subcutaneo'},\n",
       " 'Kg': {'Kilogramo'},\n",
       " 'ROT': {'Rotacaps'},\n",
       " 'RCP': {'reflejo cutaneoplantar'},\n",
       " 'LCR': {'liquido cefalorraquideo'},\n",
       " 'TSP': {'pesar pulses'},\n",
       " 'RTU': {'recibio tratamiento',\n",
       "  'reseccion transuretral',\n",
       "  'respondia tratamiento'},\n",
       " 'DTM': {'desordenes temporomandibulares'},\n",
       " 'MIRU': {'interspersed repetitive units'},\n",
       " 'OD': {'ojo derecho'},\n",
       " 'OI': {'ojo izquierdo'},\n",
       " 'EMA': {'antigeno membrana epitelial'},\n",
       " 'ALK': {'kinasa linfocitos anaplasicos'},\n",
       " 'PET': {'embargo paciente', 'emision positrones'},\n",
       " 'ANA': {'ac antifosfolipidos normales', 'anticuerpos nucleo'},\n",
       " 'ANCA': {'ac antifosfolipidos normales'},\n",
       " 'PFP': {'pruebas funcion pulmonar'},\n",
       " 'pTa': {'tras tratamiento'},\n",
       " 'AAT': {'analitico aprecia'},\n",
       " 'AA': {'anatomopatologico amiloidosis'},\n",
       " 'RNM': {'mostro masa', 'resonancia nuclear magnetica'},\n",
       " 'ECE': {'enteroscopia capsula endoscopica'},\n",
       " 'CM': {'centimetro'},\n",
       " 'AV': {'agudeza visual'},\n",
       " 'DPAR': {'defecto pupilar aferente relativo'},\n",
       " 'NOT': {'neuropatia optica traumatica'},\n",
       " 'ATM': {'articulacion temporomandibular'},\n",
       " 'IRC': {'renal inicio'},\n",
       " 'AO': {'ambos ojos'},\n",
       " 'MA': {'membrana amniotica'},\n",
       " 'di': {'Dosis Infectante 50% '},\n",
       " 'ACL': {'asociadas celulas'},\n",
       " 'DP': {'diametros papilares'},\n",
       " 'AVI': {'angiografia verde indocianina'},\n",
       " 'DRNS': {'desprendimiento retina neurosensorial'},\n",
       " 'EPR': {'epitelio pigmentario retiniano', 'evidenciandose pequenos'},\n",
       " 'PaO2': {'presion arterial oxigeno'},\n",
       " 'FiO2': {'fraccion inspirada oxigeno'},\n",
       " 'NP': {'nutricion parenteral'},\n",
       " 'NE': {'nutricion enteral'},\n",
       " 'AGE': {'acidos grasos esenciales'},\n",
       " 'DA': {'descendente anterior'},\n",
       " 'TAM': {'tension arterial media'},\n",
       " 'GC': {'gasto cardiaco'},\n",
       " 'cc': {'cristaloides coloides'},\n",
       " 'RVS': {'resistencias vasculares sistemica'},\n",
       " 'RVP': {'resistencias vasculares pulmonar'},\n",
       " 'FAV': {'fistula arteriovenosa'},\n",
       " 'HQR': {'hamartoma quistico retrorrectal'},\n",
       " 'ILA': {'indice liquido amniotico'},\n",
       " 'ECG': {'examen craneal'},\n",
       " 'UCI': {'unidad cuidados intensivos'},\n",
       " 'HCL': {'cuadro limitado'},\n",
       " 'MAVC': {'mejor agudeza visual corregida'},\n",
       " 'EA': {'estrias angioides'},\n",
       " 'OCT': {'observa cuneiforme', 'optica coherencia'},\n",
       " 'CA': {'camara anterior'},\n",
       " 'CVP': {'ciclofosfamida vincristina prednisona'},\n",
       " 'NET': {'erupcion eritematosa'},\n",
       " 'HD': {'duracion habia'},\n",
       " 'EPOC': {'enfermedad pulmonar obstructiva cronica'},\n",
       " 'TFD': {'terapia fotodinamica'},\n",
       " 'AGF': {'aprecia anillo'},\n",
       " 'MID': {'miembro inferior derecho'},\n",
       " 'AGCM': {'acidos grasos cadena media'},\n",
       " 'TAS': {'tension arterial sistolica'},\n",
       " 'TSOH': {'test sangre oculta heces'},\n",
       " 'EF': {'edad familiares'},\n",
       " 'ADN': {'acido desoxirribonucleico'},\n",
       " 'ENA': {'extraibles nucleo'},\n",
       " 'NPT': {'nutricion parenteral'},\n",
       " 'ANOES': {'negativos ecografia abdominal signos'},\n",
       " 'LPP': {'linfoma pulmonar primario'},\n",
       " 'FMO': {'fracaso multiorganico'},\n",
       " 'EFK': {'excrecion fraccional'},\n",
       " 'CPK': {'pues presento'},\n",
       " 'MSD': {'micofenolato mofetilo'},\n",
       " 'NO': {'nervio optico'},\n",
       " 'BA': {'balance articular'},\n",
       " 'BM': {'balance muscular'},\n",
       " 'VSG': {'velocidad sedimentacion globular'},\n",
       " 'IGRA': {'interferon gamma release assays'},\n",
       " 'VPP': {'paciente presentaba'},\n",
       " 'ITB': {'indice tobillo brazo'},\n",
       " 'MMSS': {'muslos miembros superiores'},\n",
       " 'SRY': {'sY84 sY254'},\n",
       " 'NDI': {'detectandose determinados'},\n",
       " 'LPS': {'subtipo lipoma'},\n",
       " 'GRE': {'gadolinio encontrando'},\n",
       " 'LBA': {'lavado broncoalveolar'},\n",
       " 'ECMO': {'mas microbiologicos componente'}}"
      ]
     },
     "execution_count": 3204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12',\n",
       " 'A-P',\n",
       " 'AA',\n",
       " 'AAS',\n",
       " 'AAT',\n",
       " 'ACL',\n",
       " 'AEO',\n",
       " 'AFG',\n",
       " 'AFP',\n",
       " 'AGF',\n",
       " 'AI',\n",
       " 'AINES',\n",
       " 'AL',\n",
       " 'ALAT',\n",
       " 'ALT',\n",
       " 'AMA',\n",
       " 'ANA',\n",
       " 'ANCA',\n",
       " 'ANCAS',\n",
       " 'ANOES',\n",
       " 'AO',\n",
       " 'AP',\n",
       " 'APC',\n",
       " 'ASAT',\n",
       " 'ASLO',\n",
       " 'AST',\n",
       " 'ATM',\n",
       " 'AV',\n",
       " 'AVI',\n",
       " 'AVSC',\n",
       " 'Alfa-feto',\n",
       " 'BA',\n",
       " 'BAL',\n",
       " 'BAS',\n",
       " 'BD',\n",
       " 'BM',\n",
       " 'BMC',\n",
       " 'BMU',\n",
       " 'BPA',\n",
       " 'C-GSF',\n",
       " 'C-Kit',\n",
       " 'CA',\n",
       " 'CD',\n",
       " 'CDI',\n",
       " 'CEA',\n",
       " 'CK',\n",
       " 'CMV',\n",
       " 'COL',\n",
       " 'CPK',\n",
       " 'CT',\n",
       " 'CU',\n",
       " 'CX',\n",
       " 'D-AAT',\n",
       " 'DA',\n",
       " 'DAI',\n",
       " 'DAKO',\n",
       " 'DFVA',\n",
       " 'DG',\n",
       " 'DII',\n",
       " 'DM',\n",
       " 'DP',\n",
       " 'DPAR',\n",
       " 'DR',\n",
       " 'DRNS',\n",
       " 'DTM',\n",
       " 'EA',\n",
       " 'EBHGA',\n",
       " 'ECE',\n",
       " 'ECG',\n",
       " 'ECMO',\n",
       " 'ECS',\n",
       " 'EEII',\n",
       " 'EF',\n",
       " 'EFK',\n",
       " 'EIA',\n",
       " 'EID',\n",
       " 'ELA',\n",
       " 'EMA',\n",
       " 'EMG',\n",
       " 'ENA',\n",
       " 'ENG',\n",
       " 'EPOC',\n",
       " 'EPR',\n",
       " 'ESCHAP',\n",
       " 'EVA',\n",
       " 'FA',\n",
       " 'FAV',\n",
       " 'FID',\n",
       " 'FMO',\n",
       " 'FO',\n",
       " 'FiO2',\n",
       " 'GC',\n",
       " 'GER',\n",
       " 'GGT',\n",
       " 'GOT',\n",
       " 'GPT',\n",
       " 'HBPM',\n",
       " 'HCT',\n",
       " 'HLA',\n",
       " 'HPTS',\n",
       " 'HPV',\n",
       " 'HQR',\n",
       " 'HSA',\n",
       " 'HTA',\n",
       " 'HTBI',\n",
       " 'IAM',\n",
       " 'ICG',\n",
       " 'IF',\n",
       " 'IGRA',\n",
       " 'INSS',\n",
       " 'IgA',\n",
       " 'IgE',\n",
       " 'IgG',\n",
       " 'IgG4',\n",
       " 'IgM',\n",
       " 'LBA',\n",
       " 'LCCT',\n",
       " 'LCR',\n",
       " 'LDH',\n",
       " 'LH',\n",
       " 'LLA',\n",
       " 'LLBCP',\n",
       " 'LLI',\n",
       " 'LNH',\n",
       " 'LPP',\n",
       " 'MA',\n",
       " 'MAVC',\n",
       " 'MELAN',\n",
       " 'MGIT',\n",
       " 'MID',\n",
       " 'MMII',\n",
       " 'MMSS',\n",
       " 'McConkey',\n",
       " 'MhZ',\n",
       " 'N-Cam',\n",
       " 'NE',\n",
       " 'NJ',\n",
       " 'NO',\n",
       " 'NOT',\n",
       " 'NP',\n",
       " 'NPT',\n",
       " 'NVC',\n",
       " 'OCT',\n",
       " 'OD',\n",
       " 'OI',\n",
       " 'ORN',\n",
       " 'P-INF',\n",
       " 'PA',\n",
       " 'PAAF',\n",
       " 'PCA',\n",
       " 'PCP',\n",
       " 'PCR',\n",
       " 'PCT',\n",
       " 'PEEP',\n",
       " 'PEES',\n",
       " 'PEG',\n",
       " 'PET',\n",
       " 'PFP',\n",
       " 'PIO',\n",
       " 'PLGA',\n",
       " 'PNJ',\n",
       " 'PQ',\n",
       " 'PRC',\n",
       " 'PSA',\n",
       " 'PTH',\n",
       " 'PVC',\n",
       " 'PaO2',\n",
       " 'RCP',\n",
       " 'RF',\n",
       " 'RM',\n",
       " 'RMN',\n",
       " 'RN',\n",
       " 'RNM',\n",
       " 'ROT',\n",
       " 'RPMB',\n",
       " 'RT',\n",
       " 'RTU',\n",
       " 'RVP',\n",
       " 'RVS',\n",
       " 'RX',\n",
       " 'SCACEST',\n",
       " 'SDRC',\n",
       " 'SHOP',\n",
       " 'SL',\n",
       " 'SMR',\n",
       " 'SNC',\n",
       " 'SPM',\n",
       " 'SPRL',\n",
       " 'ST',\n",
       " 'STIR',\n",
       " 'Swan-Ganz',\n",
       " 'TAC',\n",
       " 'TAM',\n",
       " 'TANITA',\n",
       " 'TAP',\n",
       " 'TAS',\n",
       " 'TB',\n",
       " 'TBC',\n",
       " 'TBF',\n",
       " 'TC',\n",
       " 'TCS',\n",
       " 'TENS',\n",
       " 'TEP',\n",
       " 'TFD',\n",
       " 'TG',\n",
       " 'TGP',\n",
       " 'TSH',\n",
       " 'TSOH',\n",
       " 'TSP',\n",
       " 'TTP',\n",
       " 'TVTLF',\n",
       " 'UCI',\n",
       " 'UCIP',\n",
       " 'UMI',\n",
       " 'UMO',\n",
       " 'VEB',\n",
       " 'VHB',\n",
       " 'VHC',\n",
       " 'VHS',\n",
       " 'VIH',\n",
       " 'VMNI',\n",
       " 'VSG',\n",
       " 'VVZ',\n",
       " 'XI',\n",
       " 'XII',\n",
       " 'ac',\n",
       " 'alfa-FP',\n",
       " 'alfa-feto',\n",
       " 'anti-ADN',\n",
       " 'anti-CCP',\n",
       " 'anti-DNA',\n",
       " 'anti-TNF',\n",
       " 'anti-VIH',\n",
       " 'anti-Xa',\n",
       " 'antiDNA',\n",
       " 'antiRNA',\n",
       " 'cN2',\n",
       " 'cc',\n",
       " 'cm',\n",
       " 'et',\n",
       " 'gGT',\n",
       " 'hipo-FA',\n",
       " 'iPTH',\n",
       " 'in',\n",
       " 'iv',\n",
       " 'm2',\n",
       " 'mFOLFOX',\n",
       " 'mL',\n",
       " 'mV',\n",
       " 'mg',\n",
       " 'ml',\n",
       " 'mm',\n",
       " 'mmHg',\n",
       " 'no-B',\n",
       " 'pCO2',\n",
       " 'pH',\n",
       " 'pig-tail',\n",
       " 'rt-PA',\n",
       " 'sY134',\n",
       " 'si',\n",
       " 'tru-cut',\n",
       " 'u',\n",
       " 'va']"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(pairs_dic.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2574,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 2574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs_dic.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check text individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [],
   "source": [
    "# texto = train_raw.iloc[4]['texto']\n",
    "# texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2576,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mujer de raza mestiza de 43 años de edad, con antecedente de mamoplastia de aumento realizada en junio de 2009: incisión periareolar, disección transglandular, bolsillo subfascial, colocación de implantes anatómicos de gel cohesivo texturizado de 290 cc, (McGhan® Medical Corporation, Santa Bárbara, California, EE.UU.) En la misma intervención se le realizó también abdominoplastia y liposucción de la zona baja de la espalda. Se colocaron drenajes aspirativos que se retiraron a las 24 horas de la intervención. El postoperatorio cursó sin incidencias y el resultado fue satisfactorio.\\nAl año del procedimiento, la paciente presentó molestias y edema en la mama derecha que cedieron con antinflamatorios no esteroideos a dosis de 120 mg por día durante 7 días. La evolución posterior fue satisfactoria hasta el año 2015, es decir 5 años después de esos síntomas y 6 tras la intervención, cuando la paciente nuevamente presentó molestias y edema en la mama derecha, así como aparición de galactorrea. Se le realizaron estudios de imagen mediante resonancia magnética (RM) documentando la presencia de abundante líquido periprotésico en la mama afectada.\\nEn vista de la situación, se le practicó punción guiada por ultrasonido obteniendo 270 cc de material seroso, sin detritus en su interior, de color amarillo oscuro y sin olor característico. Se remitió muestra para estudio citológico que informó de mastitis crónica con reacción granulomatosa y cultivo negativo. Sin embargo, el aumento paulatino de la mama continuó en los meses posteriores, realizándose 2 nuevas punciones sin éxito. En la segunda punción se envió nuevamente líquido para estudio de malignidad ante la sospecha de un posible carcinoma ductal. Se evaluó nuevamente a la paciente mediante estudios de imagen por ultrasonido y RM sin encontrar anomalías en el parénquima mamario, por lo cual, se optó por la retirada del implante, con capsulectomía y revisión del tejido mamario mediante biopsia transoperatoria. La cirugía se llevó a cabo en conjunto con un cirujano oncólogo, el cual revisó la glándula mamaria y tomó muestras de los diferentes cuadrantes.\\nEl estudio transoperatorio y el definitivo, tanto del tejido mamario enviado como de la cápsula periprotésica resultó negativo para malignidad. Sin embargo el líquido periprotésico evacuado durante la cirugía resultó positivo para células neoplásicas en el estudio citológico. Este líquido se estudió también mediante elaboración de bloque celular y procesado con técnica de histológica e inmunohistoquimia. Esta última obtuvo un resultado positivo para LACG, inmunofenotipo T, positivo para CD 45, CD3, CD 30 y EMA (antígeno de membrana epitelial), negativo para CKAE1/AE3 (citoqueratina), CD 20 y ALK (kinasa de linfocitos anaplásicos) e índice de proliferación 80%,.\\nEl Servicio de Hematología propuso la realización de estudio de tomografía por emisión de positrones (PET), sin embargo la paciente decidió no continuar con los estudios de estadiaje a pesar del diagnóstico final de linfoma, y ha rechazado hasta la fecha seguir ningún tipo de tratamiento, ni siquiera la retirada del implante contralateral. Actualmente (mayo de 2016) se encuentra asintomática.\\n'"
      ]
     },
     "execution_count": 2576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto = train_raw[train_raw['doc_id'] == 'S0376-78922016000200011-1'].iloc[0]['texto']\n",
    "texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2577,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sf = generic_re.findall(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2578,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sf_clean =  [i.strip() for i in sf if i.strip() not in swords]\n",
    "# sf_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2579,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_clean = [a.replace('/',\"\") for a in sf_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2580,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in punctuation:\n",
    "#     sf_clean = [a.replace(i,\"\") for a in sf_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['McGhan',\n",
       " 'EE',\n",
       " 'UU',\n",
       " 'mg',\n",
       " 'RM',\n",
       " 'cc',\n",
       " 'RM',\n",
       " 'LACG',\n",
       " 'CD',\n",
       " 'CD',\n",
       " 'CD',\n",
       " 'EMA',\n",
       " 'CKAE',\n",
       " 'AE',\n",
       " 'CD',\n",
       " 'ALK',\n",
       " 'PET']"
      ]
     },
     "execution_count": 2581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2582,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_clean = texto.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2583,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_clean = ' '.join([w for w in texto_clean if w not in swords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2584,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_clean = texto_clean.replace('[^\\w\\s]',' ').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2585,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['column'] = df['column'].apply(remove_accents)\n",
    "texto_clean = unidecode.unidecode(texto_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2591,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mujer',\n",
       " 'raza',\n",
       " 'mestiza',\n",
       " '43',\n",
       " 'anos',\n",
       " 'edad',\n",
       " ',',\n",
       " 'antecedente',\n",
       " 'mamoplastia',\n",
       " 'aumento',\n",
       " 'realizada',\n",
       " 'junio',\n",
       " '2009',\n",
       " ':',\n",
       " 'incision',\n",
       " 'periareolar',\n",
       " ',',\n",
       " 'diseccion',\n",
       " 'transglandular',\n",
       " ',',\n",
       " 'bolsillo',\n",
       " 'subfascial',\n",
       " ',',\n",
       " 'colocacion',\n",
       " 'implantes',\n",
       " 'anatomicos',\n",
       " 'gel',\n",
       " 'cohesivo',\n",
       " 'texturizado',\n",
       " '290',\n",
       " 'cc',\n",
       " ',',\n",
       " '(',\n",
       " 'mcghan',\n",
       " '(',\n",
       " 'r',\n",
       " ')',\n",
       " 'medical',\n",
       " 'corporation',\n",
       " ',',\n",
       " 'santa',\n",
       " 'barbara',\n",
       " ',',\n",
       " 'california',\n",
       " ',',\n",
       " 'ee.uu',\n",
       " '.',\n",
       " ')',\n",
       " 'en',\n",
       " 'misma',\n",
       " 'intervencion',\n",
       " 'realizo',\n",
       " 'abdominoplastia',\n",
       " 'liposuccion',\n",
       " 'zona',\n",
       " 'baja',\n",
       " 'espalda',\n",
       " '.',\n",
       " 'se',\n",
       " 'colocaron',\n",
       " 'drenajes',\n",
       " 'aspirativos',\n",
       " 'retiraron',\n",
       " '24',\n",
       " 'horas',\n",
       " 'intervencion',\n",
       " '.',\n",
       " 'el',\n",
       " 'postoperatorio',\n",
       " 'curso',\n",
       " 'incidencias',\n",
       " 'resultado',\n",
       " 'satisfactorio',\n",
       " '.',\n",
       " 'al',\n",
       " 'ano',\n",
       " 'procedimiento',\n",
       " ',',\n",
       " 'paciente',\n",
       " 'presento',\n",
       " 'molestias',\n",
       " 'edema',\n",
       " 'mama',\n",
       " 'derecha',\n",
       " 'cedieron',\n",
       " 'antinflamatorios',\n",
       " 'esteroideos',\n",
       " 'dosis',\n",
       " '120',\n",
       " 'mg',\n",
       " 'dia',\n",
       " '7',\n",
       " 'dias',\n",
       " '.',\n",
       " 'la',\n",
       " 'evolucion',\n",
       " 'posterior',\n",
       " 'satisfactoria',\n",
       " 'ano',\n",
       " '2015',\n",
       " ',',\n",
       " 'decir',\n",
       " '5',\n",
       " 'anos',\n",
       " 'despues',\n",
       " 'sintomas',\n",
       " '6',\n",
       " 'tras',\n",
       " 'intervencion',\n",
       " ',',\n",
       " 'paciente',\n",
       " 'nuevamente',\n",
       " 'presento',\n",
       " 'molestias',\n",
       " 'edema',\n",
       " 'mama',\n",
       " 'derecha',\n",
       " ',',\n",
       " 'asi',\n",
       " 'aparicion',\n",
       " 'galactorrea',\n",
       " '.',\n",
       " 'se',\n",
       " 'realizaron',\n",
       " 'estudios',\n",
       " 'imagen',\n",
       " 'mediante',\n",
       " 'resonancia',\n",
       " 'magnetica',\n",
       " '(',\n",
       " 'rm',\n",
       " ')',\n",
       " 'documentando',\n",
       " 'presencia',\n",
       " 'abundante',\n",
       " 'liquido',\n",
       " 'periprotesico',\n",
       " 'mama',\n",
       " 'afectada',\n",
       " '.',\n",
       " 'en',\n",
       " 'vista',\n",
       " 'situacion',\n",
       " ',',\n",
       " 'practico',\n",
       " 'puncion',\n",
       " 'guiada',\n",
       " 'ultrasonido',\n",
       " 'obteniendo',\n",
       " '270',\n",
       " 'cc',\n",
       " 'material',\n",
       " 'seroso',\n",
       " ',',\n",
       " 'detritus',\n",
       " 'interior',\n",
       " ',',\n",
       " 'color',\n",
       " 'amarillo',\n",
       " 'oscuro',\n",
       " 'olor',\n",
       " 'caracteristico',\n",
       " '.',\n",
       " 'se',\n",
       " 'remitio',\n",
       " 'muestra',\n",
       " 'estudio',\n",
       " 'citologico',\n",
       " 'informo',\n",
       " 'mastitis',\n",
       " 'cronica',\n",
       " 'reaccion',\n",
       " 'granulomatosa',\n",
       " 'cultivo',\n",
       " 'negativo',\n",
       " '.',\n",
       " 'sin',\n",
       " 'embargo',\n",
       " ',',\n",
       " 'aumento',\n",
       " 'paulatino',\n",
       " 'mama',\n",
       " 'continuo',\n",
       " 'meses',\n",
       " 'posteriores',\n",
       " ',',\n",
       " 'realizandose',\n",
       " '2',\n",
       " 'nuevas',\n",
       " 'punciones',\n",
       " 'exito',\n",
       " '.',\n",
       " 'en',\n",
       " 'segunda',\n",
       " 'puncion',\n",
       " 'envio',\n",
       " 'nuevamente',\n",
       " 'liquido',\n",
       " 'estudio',\n",
       " 'malignidad',\n",
       " 'sospecha',\n",
       " 'posible',\n",
       " 'carcinoma',\n",
       " 'ductal',\n",
       " '.',\n",
       " 'se',\n",
       " 'evaluo',\n",
       " 'nuevamente',\n",
       " 'paciente',\n",
       " 'mediante',\n",
       " 'estudios',\n",
       " 'imagen',\n",
       " 'ultrasonido',\n",
       " 'rm',\n",
       " 'encontrar',\n",
       " 'anomalias',\n",
       " 'parenquima',\n",
       " 'mamario',\n",
       " ',',\n",
       " 'cual',\n",
       " ',',\n",
       " 'opto',\n",
       " 'retirada',\n",
       " 'implante',\n",
       " ',',\n",
       " 'capsulectomia',\n",
       " 'revision',\n",
       " 'tejido',\n",
       " 'mamario',\n",
       " 'mediante',\n",
       " 'biopsia',\n",
       " 'transoperatoria',\n",
       " '.',\n",
       " 'la',\n",
       " 'cirugia',\n",
       " 'llevo',\n",
       " 'cabo',\n",
       " 'conjunto',\n",
       " 'cirujano',\n",
       " 'oncologo',\n",
       " ',',\n",
       " 'reviso',\n",
       " 'glandula',\n",
       " 'mamaria',\n",
       " 'tomo',\n",
       " 'muestras',\n",
       " 'diferentes',\n",
       " 'cuadrantes',\n",
       " '.',\n",
       " 'el',\n",
       " 'estudio',\n",
       " 'transoperatorio',\n",
       " 'definitivo',\n",
       " ',',\n",
       " 'tejido',\n",
       " 'mamario',\n",
       " 'enviado',\n",
       " 'capsula',\n",
       " 'periprotesica',\n",
       " 'resulto',\n",
       " 'negativo',\n",
       " 'malignidad',\n",
       " '.',\n",
       " 'sin',\n",
       " 'embargo',\n",
       " 'liquido',\n",
       " 'periprotesico',\n",
       " 'evacuado',\n",
       " 'cirugia',\n",
       " 'resulto',\n",
       " 'positivo',\n",
       " 'celulas',\n",
       " 'neoplasicas',\n",
       " 'estudio',\n",
       " 'citologico',\n",
       " '.',\n",
       " 'este',\n",
       " 'liquido',\n",
       " 'estudio',\n",
       " 'mediante',\n",
       " 'elaboracion',\n",
       " 'bloque',\n",
       " 'celular',\n",
       " 'procesado',\n",
       " 'tecnica',\n",
       " 'histologica',\n",
       " 'inmunohistoquimia',\n",
       " '.',\n",
       " 'esta',\n",
       " 'ultima',\n",
       " 'obtuvo',\n",
       " 'resultado',\n",
       " 'positivo',\n",
       " 'lacg',\n",
       " ',',\n",
       " 'inmunofenotipo',\n",
       " 't',\n",
       " ',',\n",
       " 'positivo',\n",
       " 'cd',\n",
       " '45',\n",
       " ',',\n",
       " 'cd3',\n",
       " ',',\n",
       " 'cd',\n",
       " '30',\n",
       " 'ema',\n",
       " '(',\n",
       " 'antigeno',\n",
       " 'membrana',\n",
       " 'epitelial',\n",
       " ')',\n",
       " ',',\n",
       " 'negativo',\n",
       " 'ckae1/ae3',\n",
       " '(',\n",
       " 'citoqueratina',\n",
       " ')',\n",
       " ',',\n",
       " 'cd',\n",
       " '20',\n",
       " 'alk',\n",
       " '(',\n",
       " 'kinasa',\n",
       " 'linfocitos',\n",
       " 'anaplasicos',\n",
       " ')',\n",
       " 'indice',\n",
       " 'proliferacion',\n",
       " '80',\n",
       " '%',\n",
       " ',',\n",
       " '.',\n",
       " 'el',\n",
       " 'servicio',\n",
       " 'hematologia',\n",
       " 'propuso',\n",
       " 'realizacion',\n",
       " 'estudio',\n",
       " 'tomografia',\n",
       " 'emision',\n",
       " 'positrones',\n",
       " '(',\n",
       " 'pet',\n",
       " ')',\n",
       " ',',\n",
       " 'embargo',\n",
       " 'paciente',\n",
       " 'decidio',\n",
       " 'continuar',\n",
       " 'estudios',\n",
       " 'estadiaje',\n",
       " 'pesar',\n",
       " 'diagnostico',\n",
       " 'final',\n",
       " 'linfoma',\n",
       " ',',\n",
       " 'rechazado',\n",
       " 'fecha',\n",
       " 'seguir',\n",
       " 'ningun',\n",
       " 'tipo',\n",
       " 'tratamiento',\n",
       " ',',\n",
       " 'siquiera',\n",
       " 'retirada',\n",
       " 'implante',\n",
       " 'contralateral',\n",
       " '.',\n",
       " 'actualmente',\n",
       " '(',\n",
       " 'mayo',\n",
       " '2016',\n",
       " ')',\n",
       " 'encuentra',\n",
       " 'asintomatica',\n",
       " '.']"
      ]
     },
     "execution_count": 2591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(texto_clean)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2592,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_longform(tokens, acro):\n",
    "    acro = acro.lower()\n",
    "    long_form = ''\n",
    "    margin = 2\n",
    "    i =0\n",
    "    #Looking for before\n",
    "    if acro not in tokens:\n",
    "        return -1\n",
    "    index = tokens.index(acro)\n",
    "    for word in tokens[index-margin-len(acro):index]:\n",
    "        #if first letter of word is equal to first letter os acronym\n",
    "        if word[0] == acro[i].lower():\n",
    "            long_form += word + ' '\n",
    "            i += 1\n",
    "            if i == len(acro):\n",
    "                break\n",
    "        elif (i == 1) and (word[0] == acro[i-1].lower()):\n",
    "            long_form = word + ' '\n",
    "            i = 1\n",
    "            if i == len(acro):\n",
    "                break \n",
    "    long_form = long_form.rstrip()\n",
    "    return long_form\n",
    "    for word in tokens[index:index+margin+len(acro)]:\n",
    "        print(tokens[index:index+margin+len(acro)])\n",
    "#     if len(re.split(' |-',long_form)) == (len(acro)):\n",
    "#         return long_form\n",
    "    #elif (len(re.split(' |-',long_form)) == (len(acro)-1)) & \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2680,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_longform_after(tokens, acro):\n",
    "    acro = acro.lower()\n",
    "    long_form = ''\n",
    "    margin = 2\n",
    "    i =0\n",
    "    #Looking for before\n",
    "    if acro not in tokens:\n",
    "        return -1\n",
    "    index = tokens.index(acro)\n",
    "    for word in tokens[index+1:index+margin+len(acro)]:\n",
    "        if tokens[index+1] == '(':\n",
    "            if word[0] in acro:\n",
    "                long_form += word + ' '\n",
    "    long_form = long_form.rstrip()\n",
    "    return long_form\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2681,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esta es la short form y su forma larga\n",
      " (McGhan,medical corporation)\n",
      "Esta es la short form y su forma larga\n",
      " (EE,-1)\n",
      "Esta es la short form y su forma larga\n",
      " (UU,-1)\n",
      "Esta es la short form y su forma larga\n",
      " (mg,)\n",
      "Esta es la short form y su forma larga\n",
      " (RM,)\n",
      "Esta es la short form y su forma larga\n",
      " (cc,)\n",
      "Esta es la short form y su forma larga\n",
      " (RM,)\n",
      "Esta es la short form y su forma larga\n",
      " (LACG,)\n",
      "Esta es la short form y su forma larga\n",
      " (CD,)\n",
      "Esta es la short form y su forma larga\n",
      " (CD,)\n",
      "Esta es la short form y su forma larga\n",
      " (CD,)\n",
      "Esta es la short form y su forma larga\n",
      " (EMA,antigeno membrana epitelial)\n",
      "Esta es la short form y su forma larga\n",
      " (CKAE,-1)\n",
      "Esta es la short form y su forma larga\n",
      " (AE,-1)\n",
      "Esta es la short form y su forma larga\n",
      " (CD,)\n",
      "Esta es la short form y su forma larga\n",
      " (ALK,kinasa linfocitos anaplasicos)\n",
      "Esta es la short form y su forma larga\n",
      " (PET,)\n"
     ]
    }
   ],
   "source": [
    "for sf in sf_clean:\n",
    "    a = get_longform_after(tokens, sf)\n",
    "    print(f\"Esta es la short form y su forma larga\\n ({sf},{a})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254    Presentamos el caso de un varón de 47 años de ...\n",
       "Name: texto, dtype: object"
      ]
     },
     "execution_count": 2214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw[train_raw['doc_id'] == 'S0211-69952016000300015-1'].iloc[0]['texto']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1976,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mujer',\n",
       " '70',\n",
       " 'años',\n",
       " 'edad',\n",
       " 'acudió',\n",
       " 'hospital',\n",
       " 'referencia',\n",
       " 'tumoración',\n",
       " 'cara',\n",
       " 'lateral',\n",
       " 'derecha',\n",
       " 'lengua',\n",
       " 'estadio',\n",
       " 'clínico',\n",
       " 'T2N0M0',\n",
       " 'La',\n",
       " 'biopsia',\n",
       " 'informó',\n",
       " 'carcinoma',\n",
       " 'epidermoide',\n",
       " 'La',\n",
       " 'modalidad',\n",
       " 'terapéutica',\n",
       " 'decidida',\n",
       " 'hospital',\n",
       " 'radioterapia',\n",
       " 'externa',\n",
       " 'dividida',\n",
       " '30',\n",
       " 'fracciones',\n",
       " '2',\n",
       " 'Gyfracción',\n",
       " 'total',\n",
       " '60',\n",
       " 'Gy',\n",
       " 'ambos',\n",
       " 'campos',\n",
       " 'cervicales',\n",
       " 'El',\n",
       " 'tratamiento',\n",
       " 'completó',\n",
       " 'braquiterapia',\n",
       " 'cuatro',\n",
       " 'agujas',\n",
       " 'Iridium',\n",
       " '196',\n",
       " 'total',\n",
       " '50',\n",
       " 'Gy',\n",
       " 'La',\n",
       " 'enfermedad',\n",
       " 'remitió',\n",
       " 'completo',\n",
       " 'paciente',\n",
       " 'libre',\n",
       " 'misma',\n",
       " 'año',\n",
       " 'momento',\n",
       " 'acudió',\n",
       " 'nuevo',\n",
       " 'especialista',\n",
       " 'presentar',\n",
       " 'síntomas',\n",
       " 'inflamatorios',\n",
       " 'zona',\n",
       " 'radiada',\n",
       " 'dolor',\n",
       " 'fístula',\n",
       " 'ángulo',\n",
       " 'mandibular',\n",
       " 'derecho',\n",
       " 'La',\n",
       " 'exploración',\n",
       " 'física',\n",
       " 'imagen',\n",
       " 'ortopantomografía',\n",
       " 'diagnósticas',\n",
       " 'ORN',\n",
       " 'cuerpo',\n",
       " 'mandibular',\n",
       " 'derecho',\n",
       " 'decidió',\n",
       " 'remitir',\n",
       " 'paciente',\n",
       " 'Servicio',\n",
       " 'Cirugía',\n",
       " 'Oral',\n",
       " 'Maxilofacial',\n",
       " 'Hospital',\n",
       " 'Universitario',\n",
       " 'La',\n",
       " 'Paz',\n",
       " 'El',\n",
       " 'tratamiento',\n",
       " 'inicial',\n",
       " 'consistió',\n",
       " 'curetaje',\n",
       " 'remodelación',\n",
       " 'ósea',\n",
       " 'tratamiento',\n",
       " 'oxígeno',\n",
       " 'hiperbárico',\n",
       " 'Hospital',\n",
       " 'Militar',\n",
       " 'Zaragoza',\n",
       " '17',\n",
       " 'sesiones',\n",
       " 'oxígeno',\n",
       " 'hiperbárico',\n",
       " '100',\n",
       " '25',\n",
       " 'ATA60',\n",
       " 'minutos',\n",
       " 'Pese',\n",
       " 'intentos',\n",
       " 'resolución',\n",
       " 'tratamiento',\n",
       " 'conservador',\n",
       " 'paciente',\n",
       " 'acabó',\n",
       " 'desarrollando',\n",
       " 'fractura',\n",
       " 'patológica',\n",
       " 'llevó',\n",
       " 'realizar',\n",
       " 'mandibulectomía',\n",
       " 'segmentaria',\n",
       " 'derecha',\n",
       " 'reconstrucción',\n",
       " 'colgajo',\n",
       " 'libre',\n",
       " 'microvascularizado',\n",
       " 'peroné',\n",
       " 'Los',\n",
       " 'límites',\n",
       " 'resección',\n",
       " 'ósea',\n",
       " 'determinaron',\n",
       " 'partir',\n",
       " 'cambios',\n",
       " 'radiológicos',\n",
       " 'mostraban',\n",
       " 'hueso',\n",
       " 'necrótico',\n",
       " 'junto',\n",
       " 'imagen',\n",
       " 'macroscópica',\n",
       " 'intraoperatoria',\n",
       " 'El',\n",
       " 'tejido',\n",
       " 'afecto',\n",
       " 'resecó',\n",
       " 'margen',\n",
       " 'hueso',\n",
       " '051',\n",
       " 'cm',\n",
       " 'hueso',\n",
       " 'sangrante',\n",
       " 'extirpación',\n",
       " 'bloque',\n",
       " 'mucosa',\n",
       " 'intraoral',\n",
       " 'piel',\n",
       " 'circunscrita',\n",
       " 'fístula',\n",
       " 'extraoral',\n",
       " 'El',\n",
       " 'defecto',\n",
       " 'óseo',\n",
       " 'tras',\n",
       " 'mandibulectomía',\n",
       " '8',\n",
       " 'cm',\n",
       " 'En',\n",
       " 'seguimiento',\n",
       " 'postoperatorio',\n",
       " 'exodonciaron',\n",
       " 'piezas',\n",
       " '33',\n",
       " '38',\n",
       " 'cariadas',\n",
       " 'enfermedad',\n",
       " 'periodontal',\n",
       " 'periapical',\n",
       " 'producían',\n",
       " 'dolor',\n",
       " 'infecciones',\n",
       " 'locales',\n",
       " 'repetición',\n",
       " 'Tras',\n",
       " 'periodo',\n",
       " 'asintomático',\n",
       " '8',\n",
       " 'meses',\n",
       " 'paciente',\n",
       " 'acudió',\n",
       " 'consultas',\n",
       " 'episodio',\n",
       " 'inflamatorio',\n",
       " 'fistulizado',\n",
       " 'hemimandíbula',\n",
       " 'izquierda',\n",
       " 'radiológicamente',\n",
       " 'correspondía',\n",
       " 'ORN',\n",
       " 'cuerpo',\n",
       " 'mandibular',\n",
       " 'izquierdo',\n",
       " 'Tras',\n",
       " 'intentos',\n",
       " 'tratamiento',\n",
       " 'conservador',\n",
       " 'nuevo',\n",
       " 'cuadro',\n",
       " 'síntomas',\n",
       " 'persistieron',\n",
       " 'mala',\n",
       " 'evolución',\n",
       " 'enfermedad',\n",
       " 'obligó',\n",
       " 'segunda',\n",
       " 'intervención',\n",
       " 'mandibulectomía',\n",
       " 'izquierda',\n",
       " 'segundo',\n",
       " 'peroné',\n",
       " 'microvascularizado',\n",
       " 'isla',\n",
       " 'cutánea',\n",
       " 'En',\n",
       " 'evolutivo',\n",
       " 'temprano',\n",
       " 'paciente',\n",
       " 'desarrolló',\n",
       " 'fístula',\n",
       " 'línea',\n",
       " 'media',\n",
       " 'resolvió',\n",
       " 'retirando',\n",
       " 'placa',\n",
       " 'osteosíntesis',\n",
       " 'unía',\n",
       " 'extremo',\n",
       " 'anterior',\n",
       " 'primer',\n",
       " 'peroné',\n",
       " 'trasplantado',\n",
       " 'región',\n",
       " 'parasinfisaria',\n",
       " 'derecha',\n",
       " 'La',\n",
       " 'evolución',\n",
       " 'final',\n",
       " 'enfermedad',\n",
       " 'sido',\n",
       " 'satisfactoria',\n",
       " 'cicatrización',\n",
       " 'adecuada',\n",
       " 'intra',\n",
       " 'extraoral',\n",
       " 'resolución',\n",
       " 'momento',\n",
       " 'actual']"
      ]
     },
     "execution_count": 1976,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mine[mine['doc_id'] == 'S1130-05582010000200004-1'].iloc[0]['tokens']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
